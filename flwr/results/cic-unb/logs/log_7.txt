INFO flwr 2023-11-06 03:08:51,744 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-06 03:08:51,752 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-06 03:08:51,753 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-06 03:08:51,753 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-06 03:09:04,561 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-06 03:09:04,561 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:22,  2.04it/s] 11%|█         | 154/1394 [00:00<00:03, 346.67it/s] 22%|██▏       | 305/1394 [00:00<00:01, 629.16it/s] 33%|███▎      | 457/1394 [00:00<00:01, 857.98it/s] 43%|████▎     | 604/1394 [00:00<00:00, 1021.53it/s] 53%|█████▎    | 744/1394 [00:00<00:00, 1125.38it/s] 64%|██████▍   | 891/1394 [00:01<00:00, 1220.99it/s] 75%|███████▍  | 1041/1394 [00:01<00:00, 1299.98it/s] 85%|████████▌ | 1185/1394 [00:01<00:00, 1203.48it/s] 94%|█████████▍| 1316/1394 [00:01<00:00, 1106.80it/s]100%|██████████| 1394/1394 [00:01<00:00, 912.21it/s] 
INFO flwr 2023-11-06 03:09:14,342 | server.py:94 | initial parameters (loss, other metrics): 653.7872204184532, {'accuracy': 0.8527057029445404}
INFO flwr 2023-11-06 03:09:14,342 | server.py:104 | FL starting
DEBUG flwr 2023-11-06 03:09:14,483 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 03:18:43,391 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 03:18:43,399 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 653.7872204184532 / accuracy 0.8527057029445404
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 162/1394 [00:00<00:00, 1618.98it/s] 23%|██▎       | 325/1394 [00:00<00:00, 1620.95it/s] 35%|███▌      | 488/1394 [00:00<00:00, 1615.24it/s] 47%|████▋     | 651/1394 [00:00<00:00, 1620.55it/s] 58%|█████▊    | 815/1394 [00:00<00:00, 1626.28it/s] 70%|███████   | 979/1394 [00:00<00:00, 1629.48it/s] 82%|████████▏ | 1144/1394 [00:00<00:00, 1635.30it/s] 94%|█████████▍| 1308/1394 [00:00<00:00, 1630.53it/s]100%|██████████| 1394/1394 [00:00<00:00, 1627.49it/s]
INFO flwr 2023-11-06 03:18:48,236 | server.py:125 | fit progress: (1, 680.5439533889294, {'accuracy': 0.8254356260231885}, 573.8943847530172)
DEBUG flwr 2023-11-06 03:18:48,236 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 03:18:50,741 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 03:18:50,741 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-06 03:18:50,741 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 03:28:15,591 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 680.5439533889294 / accuracy 0.8254356260231885
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 164/1394 [00:00<00:00, 1633.99it/s] 24%|██▎       | 329/1394 [00:00<00:00, 1638.47it/s] 35%|███▌      | 494/1394 [00:00<00:00, 1640.01it/s] 47%|████▋     | 659/1394 [00:00<00:00, 1639.37it/s] 59%|█████▉    | 824/1394 [00:00<00:00, 1641.73it/s] 71%|███████   | 989/1394 [00:00<00:00, 1643.97it/s] 83%|████████▎ | 1154/1394 [00:00<00:00, 1643.55it/s] 95%|█████████▍| 1319/1394 [00:00<00:00, 1643.97it/s]100%|██████████| 1394/1394 [00:00<00:00, 1640.54it/s]
INFO flwr 2023-11-06 03:28:20,217 | server.py:125 | fit progress: (2, 480.2007375359535, {'accuracy': 0.9687605122109842}, 1145.8749695650185)
DEBUG flwr 2023-11-06 03:28:20,217 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 03:28:22,734 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-06 03:28:22,734 | server.py:153 | FL finished in 1148.3925590990111
INFO flwr 2023-11-06 03:28:22,735 | app.py:225 | app_fit: losses_distributed [(1, 798.4477928130253), (2, 755.8955913783208)]
INFO flwr 2023-11-06 03:28:22,735 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-06 03:28:22,735 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-06 03:28:22,735 | app.py:228 | app_fit: losses_centralized [(0, 653.7872204184532), (1, 680.5439533889294), (2, 480.2007375359535)]
INFO flwr 2023-11-06 03:28:22,735 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.8527057029445404), (1, 0.8254356260231885), (2, 0.9687605122109842)]}
Server-side evaluation loss 480.2007375359535 / accuracy 0.9687605122109842
in loss 0.010292082093656063, accuracy: 98.4%
Epoch 4: train loss 0.010964533314108849, accuracy: 96.25%
Epoch 7: train loss 0.010290751233696938, accuracy: 98.4%
Epoch 5: train loss 0.010958372615277767, accuracy: 96.25%
Epoch 8: train loss 0.01028862688690424, accuracy: 98.4%
Epoch 9: train loss 0.010289182886481285, accuracy: 98.4%
Epoch 6: train loss 0.011010462418198586, accuracy: 96.11%
Epoch 7: train loss 0.011051183566451073, accuracy: 95.96%
Epoch 8: train loss 0.010922499001026154, accuracy: 96.39%
Epoch 9: train loss 0.010967299342155457, accuracy: 96.23%
Epoch 10: train loss 0.010127267800271511, accuracy: 98.96%
Epoch 10: train loss 0.010288945399224758, accuracy: 98.4%
Epoch 10: train loss 0.011019840836524963, accuracy: 96.08%
Epoch 10: train loss 0.00979290809482336, accuracy: 99.99%
Epoch 10: train loss 0.009863249026238918, accuracy: 99.76%
Epoch 10: train loss 0.011046776548027992, accuracy: 96.01%
Epoch 10: train loss 0.009954333305358887, accuracy: 99.47%
Acurácia do Cliente: 1 eh: 0.8222959790092171
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.6459557390538609
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.8175148206843927
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.5797116626522847
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.8698589792453484
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.47565891472868216
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.7968488274706867
Starting Client training for 10 epochs
Epoch 1: train loss 0.012487447820603848, accuracy: 91.47%
Epoch 1: train loss 0.014457043260335922, accuracy: 85.08%
Epoch 1: train loss 0.020530035719275475, accuracy: 65.67%
Epoch 1: train loss 0.010245535522699356, accuracy: 98.51%
Epoch 1: train loss 0.010478152893483639, accuracy: 97.74%
Epoch 2: train loss 0.014122006483376026, accuracy: 86.12%
Epoch 2: train loss 0.011487871408462524, accuracy: 94.49%
Epoch 1: train loss 0.013877185992896557, accuracy: 86.89%
Epoch 2: train loss 0.019481172785162926, accuracy: 68.99%
Epoch 3: train loss 0.012843383476138115, accuracy: 90.16%
Epoch 3: train loss 0.011083219200372696, accuracy: 95.83%
Epoch 2: train loss 0.009836822748184204, accuracy: 99.85%
Epoch 2: train loss 0.010018100030720234, accuracy: 99.26%
Epoch 1: train loss 0.011325218714773655, accuracy: 95.08%
Epoch 4: train loss 0.012646815739572048, accuracy: 90.72%
Epoch 4: train loss 0.010700170882046223, accuracy: 97.11%
Epoch 3: train loss 0.019375480711460114, accuracy: 69.32%
Epoch 3: train loss 0.0098219383507967, accuracy: 99.9%
Epoch 3: train loss 0.010001040063798428, accuracy: 99.32%
Epoch 5: train loss 0.012634609825909138, accuracy: 90.88%
Epoch 5: train loss 0.010569585487246513, accuracy: 97.62%
Epoch 2: train loss 0.01181944552809, accuracy: 93.56%
Epoch 4: train loss 0.017703164368867874, accuracy: 74.59%
Epoch 6: train loss 0.01262102834880352, accuracy: 90.9%
Epoch 6: train loss 0.010503817349672318, accuracy: 97.8%
Epoch 4: train loss 0.00982009619474411, accuracy: 99.91%
Epoch 4: train loss 0.01000180933624506, accuracy: 99.33%
Epoch 5: train loss 0.012605054304003716, accuracy: 90.94%
Epoch 7: train loss 0.012274869717657566, accuracy: 91.95%
Epoch 7: train loss 0.010467360727488995, accuracy: 97.82%
Epoch 2: train loss 0.011105255223810673, accuracy: 95.81%
Epoch 3: train loss 0.01159670390188694, accuracy: 94.18%
Epoch 8: train loss 0.011793740093708038, accuracy: 93.47%
Epoch 5: train loss 0.009817799553275108, accuracy: 99.91%
Epoch 6: train loss 0.011914879083633423, accuracy: 93.19%
Epoch 8: train loss 0.010451309382915497, accuracy: 97.87%
Epoch 5: train loss 0.009986171498894691, accuracy: 99.36%
Epoch 9: train loss 0.011529205366969109, accuracy: 94.43%
Epoch 9: train loss 0.01044695544987917, accuracy: 97.88%
Epoch 7: train loss 0.011804248206317425, accuracy: 93.56%
Epoch 6: train loss 0.009809556417167187, accuracy: 99.93%
Epoch 6: train loss 0.009976581670343876, accuracy: 99.39%
Epoch 8: train loss 0.011721977964043617, accuracy: 93.82%
Epoch 4: train loss 0.011222908273339272, accuracy: 95.41%
Epoch 7: train loss 0.009799214079976082, accuracy: 99.96%
Epoch 7: train loss 0.009981436654925346, accuracy: 99.37%
Epoch 3: train loss 0.011014600284397602, accuracy: 96.07%
Epoch 9: train loss 0.01166219636797905, accuracy: 94.01%
Epoch 8: train loss 0.009797663427889347, accuracy: 99.97%
Epoch 8: train loss 0.00998041220009327, accuracy: 99.39%
Epoch 5: train loss 0.010728584602475166, accuracy: 97.03%
Epoch 9: train loss 0.009797638282179832, accuracy: 99.97%
Epoch 9: train loss 0.009985577315092087, accuracy: 99.38%
Epoch 4: train loss 0.010982317849993706, accuracy: 96.17%
Epoch 6: train loss 0.010627144016325474, accuracy: 97.31%
Epoch 7: train loss 0.01063600741326809, accuracy: 97.31%
Epoch 5: train loss 0.01089954562485218, accuracy: 96.45%
Epoch 8: train loss 0.010628681629896164, accuracy: 97.32%
Epoch 6: train loss 0.010983224958181381, accuracy: 96.18%
Epoch 9: train loss 0.010630649514496326, accuracy: 97.33%
Epoch 7: train loss 0.010989079251885414, accuracy: 96.17%
Epoch 8: train loss 0.010960297659039497, accuracy: 96.23%
Epoch 9: train loss 0.010898016393184662, accuracy: 96.44%
Epoch 10: train loss 0.010907582938671112, accuracy: 96.44%
Epoch 10: train loss 0.011632210575044155, accuracy: 94.07%
Epoch 10: train loss 0.010629146359860897, accuracy: 97.34%
Epoch 10: train loss 0.01044853962957859, accuracy: 97.91%
Epoch 10: train loss 0.009798213839530945, accuracy: 99.98%
Epoch 10: train loss 0.01118419598788023, accuracy: 95.45%
Epoch 10: train loss 0.009982977993786335, accuracy: 99.37%
Acurácia do Cliente: 4 eh: 0.9876151904678053
Acurácia do Cliente: 5 eh: 0.4414074772227458
Acurácia do Cliente: 1 eh: 0.9682671391087888
Acurácia do Cliente: 3 eh: 0.9995842139911992
Acurácia do Cliente: 6 eh: 0.9898974036850922
Acurácia do Cliente: 7 eh: 0.435171650055371
Acurácia do Cliente: 2 eh: 0.6377271874233085
