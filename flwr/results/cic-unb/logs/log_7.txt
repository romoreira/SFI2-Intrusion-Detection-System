INFO flwr 2023-11-03 18:59:08,312 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-03 18:59:08,319 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-03 18:59:08,320 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-03 18:59:08,320 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-03 18:59:21,228 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-03 18:59:21,228 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:20,  2.05it/s] 11%|█         | 151/1394 [00:00<00:03, 340.94it/s] 22%|██▏       | 301/1394 [00:00<00:01, 623.23it/s] 32%|███▏      | 450/1394 [00:00<00:01, 846.44it/s] 42%|████▏     | 579/1394 [00:00<00:00, 921.98it/s] 50%|█████     | 701/1394 [00:01<00:00, 950.95it/s] 60%|█████▉    | 834/1394 [00:01<00:00, 1050.62it/s] 69%|██████▉   | 964/1394 [00:01<00:00, 1117.08it/s] 78%|███████▊  | 1089/1394 [00:01<00:00, 1152.68it/s] 90%|████████▉ | 1248/1394 [00:01<00:00, 1276.28it/s]100%|██████████| 1394/1394 [00:01<00:00, 918.94it/s] 
INFO flwr 2023-11-03 18:59:31,168 | server.py:94 | initial parameters (loss, other metrics): 1606.5615150928497, {'accuracy': 0.029893924783027964}
INFO flwr 2023-11-03 18:59:31,168 | server.py:104 | FL starting
DEBUG flwr 2023-11-03 18:59:31,168 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 19:09:02,881 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 19:09:02,889 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1606.5615150928497 / accuracy 0.029893924783027964
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 167/1394 [00:00<00:00, 1667.32it/s] 24%|██▍       | 334/1394 [00:00<00:00, 1667.96it/s] 36%|███▌      | 501/1394 [00:00<00:00, 1667.62it/s] 48%|████▊     | 668/1394 [00:00<00:00, 1668.11it/s] 60%|█████▉    | 835/1394 [00:00<00:00, 1665.90it/s] 72%|███████▏  | 1002/1394 [00:00<00:00, 1666.27it/s] 84%|████████▍ | 1169/1394 [00:00<00:00, 1667.16it/s] 96%|█████████▌| 1336/1394 [00:00<00:00, 1666.83it/s]100%|██████████| 1394/1394 [00:00<00:00, 1667.09it/s]
INFO flwr 2023-11-03 19:09:07,740 | server.py:125 | fit progress: (1, 677.4957549273968, {'accuracy': 0.8270503016303739}, 576.5722865110147)
DEBUG flwr 2023-11-03 19:09:07,740 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 19:09:10,194 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 19:09:10,194 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-03 19:09:10,194 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 19:18:45,839 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 677.4957549273968 / accuracy 0.8270503016303739
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 166/1394 [00:00<00:00, 1653.03it/s] 24%|██▍       | 332/1394 [00:00<00:00, 1648.40it/s] 36%|███▌      | 497/1394 [00:00<00:00, 1644.93it/s] 48%|████▊     | 663/1394 [00:00<00:00, 1647.17it/s] 60%|█████▉    | 830/1394 [00:00<00:00, 1652.29it/s] 71%|███████▏  | 996/1394 [00:00<00:00, 1648.98it/s] 83%|████████▎ | 1161/1394 [00:00<00:00, 1646.35it/s] 95%|█████████▌| 1326/1394 [00:00<00:00, 1642.46it/s]100%|██████████| 1394/1394 [00:00<00:00, 1646.84it/s]
INFO flwr 2023-11-03 19:18:50,758 | server.py:125 | fit progress: (2, 481.79813182353973, {'accuracy': 0.9676392097059945}, 1159.5902721399907)
DEBUG flwr 2023-11-03 19:18:50,758 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 19:18:53,292 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-03 19:18:53,292 | server.py:153 | FL finished in 1162.1242781649926
INFO flwr 2023-11-03 19:18:53,293 | app.py:225 | app_fit: losses_distributed [(1, 816.132899841689), (2, 755.7435325877285)]
INFO flwr 2023-11-03 19:18:53,293 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-03 19:18:53,293 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-03 19:18:53,293 | app.py:228 | app_fit: losses_centralized [(0, 1606.5615150928497), (1, 677.4957549273968), (2, 481.79813182353973)]
INFO flwr 2023-11-03 19:18:53,293 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.029893924783027964), (1, 0.8270503016303739), (2, 0.9676392097059945)]}
Server-side evaluation loss 481.79813182353973 / accuracy 0.9676392097059945
011071065440773964, accuracy: 95.91%
Epoch 6: train loss 0.010312170721590519, accuracy: 98.33%
Epoch 7: train loss 0.010308734141290188, accuracy: 98.35%
Epoch 5: train loss 0.010932602919638157, accuracy: 96.35%
Epoch 8: train loss 0.010297989472746849, accuracy: 98.38%
Epoch 6: train loss 0.010939711704850197, accuracy: 96.34%
Epoch 9: train loss 0.010294714011251926, accuracy: 98.39%
Epoch 7: train loss 0.010989823378622532, accuracy: 96.17%
Epoch 8: train loss 0.010932150296866894, accuracy: 96.34%
Epoch 9: train loss 0.01089160330593586, accuracy: 96.46%
Epoch 10: train loss 0.00979290809482336, accuracy: 99.99%
Epoch 10: train loss 0.011381961405277252, accuracy: 94.86%
Epoch 10: train loss 0.010293451137840748, accuracy: 98.39%
Epoch 10: train loss 0.010923721827566624, accuracy: 96.35%
Epoch 10: train loss 0.01013210043311119, accuracy: 98.95%
Epoch 10: train loss 0.009874519892036915, accuracy: 99.73%
Epoch 10: train loss 0.009961484931409359, accuracy: 99.44%
Acurácia do Cliente: 3 eh: 0.865354630816673
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.827962669484064
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.8272297100311722
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.8289363484087102
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.4179146158411003
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.650936178198669
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.40691029900332226
Starting Client training for 10 epochs
Epoch 1: train loss 0.011485838331282139, accuracy: 94.66%
Epoch 1: train loss 0.01290043629705906, accuracy: 90.16%
Epoch 1: train loss 0.02144377864897251, accuracy: 62.64%
Epoch 1: train loss 0.009907559491693974, accuracy: 99.64%
Epoch 1: train loss 0.011390333995223045, accuracy: 94.86%
Epoch 2: train loss 0.010290462523698807, accuracy: 98.44%
Epoch 2: train loss 0.011339851655066013, accuracy: 94.93%
Epoch 2: train loss 0.019523654133081436, accuracy: 68.73%
Epoch 1: train loss 0.012238779105246067, accuracy: 92.13%
Epoch 3: train loss 0.01020011492073536, accuracy: 98.72%
Epoch 3: train loss 0.01096978597342968, accuracy: 96.25%
Epoch 2: train loss 0.00979381613433361, accuracy: 99.98%
Epoch 2: train loss 0.01013599056750536, accuracy: 98.88%
Epoch 3: train loss 0.01427838858217001, accuracy: 85.51%
Epoch 1: train loss 0.011236533522605896, accuracy: 95.38%
Epoch 4: train loss 0.010177631862461567, accuracy: 98.78%
Epoch 4: train loss 0.010515015572309494, accuracy: 97.77%
Epoch 3: train loss 0.009793652221560478, accuracy: 99.99%
Epoch 3: train loss 0.010105369612574577, accuracy: 99.01%
Epoch 5: train loss 0.010150260291993618, accuracy: 98.88%
Epoch 5: train loss 0.010489187203347683, accuracy: 97.8%
Epoch 2: train loss 0.011060873046517372, accuracy: 95.89%
Epoch 4: train loss 0.012060974724590778, accuracy: 92.64%
Epoch 6: train loss 0.01039322093129158, accuracy: 98.09%
Epoch 6: train loss 0.010135801509022713, accuracy: 98.92%
Epoch 4: train loss 0.009793772362172604, accuracy: 99.98%
Epoch 4: train loss 0.01003451831638813, accuracy: 99.22%
Epoch 5: train loss 0.011830325238406658, accuracy: 93.48%
Epoch 7: train loss 0.010350986383855343, accuracy: 98.17%
Epoch 7: train loss 0.010136440396308899, accuracy: 98.91%
Epoch 3: train loss 0.010952150449156761, accuracy: 96.27%
Epoch 2: train loss 0.01112689170986414, accuracy: 95.75%
Epoch 8: train loss 0.010271627455949783, accuracy: 98.47%
Epoch 6: train loss 0.011742441914975643, accuracy: 93.84%
Epoch 5: train loss 0.009794725105166435, accuracy: 99.98%
Epoch 8: train loss 0.010134033858776093, accuracy: 98.91%
Epoch 5: train loss 0.010006065480411053, accuracy: 99.33%
Epoch 9: train loss 0.010241902433335781, accuracy: 98.55%
Epoch 9: train loss 0.010128824971616268, accuracy: 98.92%
Epoch 7: train loss 0.01167245302349329, accuracy: 94.0%
Epoch 6: train loss 0.01000657957047224, accuracy: 99.28%
Epoch 6: train loss 0.009793759323656559, accuracy: 99.98%
Epoch 4: train loss 0.011001958511769772, accuracy: 96.12%
Epoch 8: train loss 0.011638383381068707, accuracy: 94.16%
Epoch 7: train loss 0.010003022849559784, accuracy: 99.32%
Epoch 7: train loss 0.009794478304684162, accuracy: 99.98%
Epoch 3: train loss 0.011026120744645596, accuracy: 96.04%
Epoch 9: train loss 0.0116078220307827, accuracy: 94.21%
Epoch 8: train loss 0.010013852268457413, accuracy: 99.3%
Epoch 8: train loss 0.009793632663786411, accuracy: 99.98%
Epoch 5: train loss 0.010501895099878311, accuracy: 97.69%
Epoch 9: train loss 0.010016116313636303, accuracy: 99.28%
Epoch 9: train loss 0.009794113226234913, accuracy: 99.98%
Epoch 4: train loss 0.011063714511692524, accuracy: 95.93%
Epoch 6: train loss 0.010345795191824436, accuracy: 98.23%
Epoch 7: train loss 0.010326651856303215, accuracy: 98.27%
Epoch 5: train loss 0.011040250770747662, accuracy: 96.01%
Epoch 8: train loss 0.010322286747395992, accuracy: 98.3%
Epoch 6: train loss 0.011112123727798462, accuracy: 95.77%
Epoch 9: train loss 0.010319952853024006, accuracy: 98.3%
Epoch 7: train loss 0.011049944907426834, accuracy: 95.96%
Epoch 8: train loss 0.011115068569779396, accuracy: 95.77%
Epoch 9: train loss 0.011026861146092415, accuracy: 96.03%
Epoch 10: train loss 0.010005665011703968, accuracy: 99.31%
Epoch 10: train loss 0.010129735805094242, accuracy: 98.94%
Epoch 10: train loss 0.009794594720005989, accuracy: 99.98%
Epoch 10: train loss 0.010230469517409801, accuracy: 98.58%
Epoch 10: train loss 0.01032059546560049, accuracy: 98.31%
Epoch 10: train loss 0.011586537584662437, accuracy: 94.25%
Epoch 10: train loss 0.010944804176688194, accuracy: 96.31%
Acurácia do Cliente: 1 eh: 0.9685586777600861
Acurácia do Cliente: 4 eh: 0.98837823560486
Acurácia do Cliente: 7 eh: 0.436766334440753
Acurácia do Cliente: 6 eh: 0.989321608040201
Acurácia do Cliente: 2 eh: 0.6360670410417057
Acurácia do Cliente: 5 eh: 0.45072782490313124
Acurácia do Cliente: 3 eh: 0.9994109698208655
