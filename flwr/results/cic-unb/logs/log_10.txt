INFO flwr 2023-11-03 20:01:25,832 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-03 20:01:25,840 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-03 20:01:25,840 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-03 20:01:25,840 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-03 20:01:40,742 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-03 20:01:40,742 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:29,  2.02it/s] 10%|█         | 146/1394 [00:00<00:03, 326.24it/s] 18%|█▊        | 253/1394 [00:00<00:02, 506.45it/s] 25%|██▌       | 349/1394 [00:00<00:01, 619.90it/s] 34%|███▎      | 469/1394 [00:00<00:01, 774.53it/s] 45%|████▍     | 624/1394 [00:00<00:00, 987.11it/s] 54%|█████▍    | 751/1394 [00:01<00:00, 1066.44it/s] 65%|██████▌   | 908/1394 [00:01<00:00, 1209.20it/s] 77%|███████▋  | 1071/1394 [00:01<00:00, 1330.48it/s] 89%|████████▊ | 1236/1394 [00:01<00:00, 1422.18it/s]100%|██████████| 1394/1394 [00:01<00:00, 931.47it/s] 
INFO flwr 2023-11-03 20:01:50,698 | server.py:94 | initial parameters (loss, other metrics): 1561.0180557966232, {'accuracy': 0.16857661860016596}
INFO flwr 2023-11-03 20:01:50,698 | server.py:104 | FL starting
DEBUG flwr 2023-11-03 20:01:50,698 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:11:27,354 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 20:11:27,362 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1561.0180557966232 / accuracy 0.16857661860016596
  0%|          | 0/1394 [00:00<?, ?it/s] 11%|█▏        | 159/1394 [00:00<00:00, 1582.50it/s] 23%|██▎       | 320/1394 [00:00<00:00, 1596.46it/s] 35%|███▍      | 481/1394 [00:00<00:00, 1600.03it/s] 46%|████▌     | 644/1394 [00:00<00:00, 1609.84it/s] 58%|█████▊    | 805/1394 [00:00<00:00, 1606.32it/s] 69%|██████▉   | 966/1394 [00:00<00:00, 1604.26it/s] 81%|████████  | 1127/1394 [00:00<00:00, 1604.90it/s] 92%|█████████▏| 1288/1394 [00:00<00:00, 1601.42it/s]100%|██████████| 1394/1394 [00:00<00:00, 1604.11it/s]
INFO flwr 2023-11-03 20:11:32,219 | server.py:125 | fit progress: (1, 701.3545225560665, {'accuracy': 0.8098270951537305}, 581.5210537569947)
DEBUG flwr 2023-11-03 20:11:32,219 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:11:34,756 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 20:11:34,756 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-03 20:11:34,756 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:21:12,410 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 701.3545225560665 / accuracy 0.8098270951537305
  0%|          | 0/1394 [00:00<?, ?it/s] 11%|█▏        | 160/1394 [00:00<00:00, 1592.26it/s] 23%|██▎       | 320/1394 [00:00<00:00, 1595.02it/s] 34%|███▍      | 480/1394 [00:00<00:00, 1592.55it/s] 46%|████▌     | 641/1394 [00:00<00:00, 1598.75it/s] 57%|█████▋    | 801/1394 [00:00<00:00, 1594.94it/s] 69%|██████▉   | 961/1394 [00:00<00:00, 1595.63it/s] 80%|████████  | 1121/1394 [00:00<00:00, 1594.50it/s] 92%|█████████▏| 1281/1394 [00:00<00:00, 1593.95it/s]100%|██████████| 1394/1394 [00:00<00:00, 1594.70it/s]
INFO flwr 2023-11-03 20:21:17,338 | server.py:125 | fit progress: (2, 696.3586995899677, {'accuracy': 0.8135049673700971}, 1166.6401508770068)
DEBUG flwr 2023-11-03 20:21:17,338 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:21:19,853 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-03 20:21:19,853 | server.py:153 | FL finished in 1169.1550452059892
INFO flwr 2023-11-03 20:21:19,853 | app.py:225 | app_fit: losses_distributed [(1, 664.5758086247528), (2, 698.8504531482473)]
INFO flwr 2023-11-03 20:21:19,853 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-03 20:21:19,853 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-03 20:21:19,853 | app.py:228 | app_fit: losses_centralized [(0, 1561.0180557966232), (1, 701.3545225560665), (2, 696.3586995899677)]
INFO flwr 2023-11-03 20:21:19,853 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.16857661860016596), (1, 0.8098270951537305), (2, 0.8135049673700971)]}
Server-side evaluation loss 696.3586995899677 / accuracy 0.8135049673700971
loss 0.011065538972616196, accuracy: 95.93%
Epoch 6: train loss 0.010305861011147499, accuracy: 98.35%
Epoch 7: train loss 0.010301940143108368, accuracy: 98.36%
Epoch 5: train loss 0.010966296307742596, accuracy: 96.25%
Epoch 8: train loss 0.010300987400114536, accuracy: 98.37%
Epoch 6: train loss 0.010999650694429874, accuracy: 96.15%
Epoch 9: train loss 0.010297892615199089, accuracy: 98.38%
Epoch 7: train loss 0.010981559753417969, accuracy: 96.17%
Epoch 8: train loss 0.010968700982630253, accuracy: 96.21%
Epoch 9: train loss 0.010972266085445881, accuracy: 96.24%
Epoch 10: train loss 0.01097725797444582, accuracy: 96.21%
Epoch 10: train loss 0.010122508741915226, accuracy: 98.97%
Epoch 10: train loss 0.010297036729753017, accuracy: 98.38%
Epoch 10: train loss 0.009997954592108727, accuracy: 99.31%
Epoch 10: train loss 0.00996381789445877, accuracy: 99.44%
Epoch 10: train loss 0.009793629869818687, accuracy: 99.98%
Epoch 10: train loss 0.01151092816144228, accuracy: 94.5%
Acurácia do Cliente: 5 eh: 0.5489580060739344
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.8081227153461461
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.8234988392640588
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.609390919158361
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.7329878559463987
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.7939778129952456
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.8678379119689336
Starting Client training for 10 epochs
Epoch 1: train loss 0.017394816502928734, accuracy: 75.45%
Epoch 1: train loss 0.015813132748007774, accuracy: 80.67%
Epoch 1: train loss 0.020440589636564255, accuracy: 65.96%
Epoch 1: train loss 0.01118631474673748, accuracy: 95.52%
Epoch 1: train loss 0.011682475917041302, accuracy: 93.92%
Epoch 2: train loss 0.015510411001741886, accuracy: 81.67%
Epoch 2: train loss 0.01319999247789383, accuracy: 89.02%
Epoch 2: train loss 0.01785297878086567, accuracy: 74.13%
Epoch 1: train loss 0.015319147147238255, accuracy: 82.29%
Epoch 3: train loss 0.011037744581699371, accuracy: 96.07%
Epoch 3: train loss 0.015435478650033474, accuracy: 81.93%
Epoch 2: train loss 0.009837260469794273, accuracy: 99.81%
Epoch 2: train loss 0.010389107279479504, accuracy: 98.08%
Epoch 1: train loss 0.01103284116834402, accuracy: 96.03%
Epoch 4: train loss 0.010382206179201603, accuracy: 98.15%
Epoch 3: train loss 0.013296075165271759, accuracy: 88.77%
Epoch 4: train loss 0.015420963056385517, accuracy: 81.98%
Epoch 3: train loss 0.009820071049034595, accuracy: 99.9%
Epoch 3: train loss 0.01029080618172884, accuracy: 98.4%
Epoch 5: train loss 0.010329335927963257, accuracy: 98.28%
Epoch 5: train loss 0.015384779311716557, accuracy: 82.09%
Epoch 2: train loss 0.015126124955713749, accuracy: 82.91%
Epoch 4: train loss 0.012511873617768288, accuracy: 91.35%
Epoch 6: train loss 0.015319756232202053, accuracy: 82.32%
Epoch 6: train loss 0.010320538654923439, accuracy: 98.29%
Epoch 4: train loss 0.00981614738702774, accuracy: 99.9%
Epoch 4: train loss 0.010287717916071415, accuracy: 98.39%
Epoch 5: train loss 0.012135859578847885, accuracy: 92.5%
Epoch 7: train loss 0.01519784051924944, accuracy: 82.66%
Epoch 7: train loss 0.010325092822313309, accuracy: 98.31%
Epoch 2: train loss 0.011147353798151016, accuracy: 95.67%
Epoch 6: train loss 0.011905194260179996, accuracy: 93.27%
Epoch 3: train loss 0.015011497773230076, accuracy: 83.29%
Epoch 8: train loss 0.014892647974193096, accuracy: 83.7%
Epoch 8: train loss 0.010314414277672768, accuracy: 98.32%
Epoch 5: train loss 0.01028494257479906, accuracy: 98.42%
Epoch 5: train loss 0.009818153455853462, accuracy: 99.9%
Epoch 9: train loss 0.014494511298835278, accuracy: 84.97%
Epoch 9: train loss 0.010309120640158653, accuracy: 98.32%
Epoch 7: train loss 0.011827724985778332, accuracy: 93.44%
Epoch 6: train loss 0.009820840321481228, accuracy: 99.91%
Epoch 6: train loss 0.010275311768054962, accuracy: 98.43%
Epoch 8: train loss 0.01176413893699646, accuracy: 93.68%
Epoch 4: train loss 0.014966754242777824, accuracy: 83.43%
Epoch 7: train loss 0.009818961843848228, accuracy: 99.91%
Epoch 7: train loss 0.010243580676615238, accuracy: 98.56%
Epoch 3: train loss 0.010914772748947144, accuracy: 96.41%
Epoch 9: train loss 0.011718230322003365, accuracy: 93.85%
Epoch 8: train loss 0.009816634468734264, accuracy: 99.91%
Epoch 8: train loss 0.010272449813783169, accuracy: 98.46%
Epoch 5: train loss 0.014941240660846233, accuracy: 83.53%
Epoch 9: train loss 0.009818190708756447, accuracy: 99.9%
Epoch 9: train loss 0.010280638933181763, accuracy: 98.44%
Epoch 4: train loss 0.01104820892214775, accuracy: 95.93%
Epoch 6: train loss 0.014899973757565022, accuracy: 83.64%
Epoch 7: train loss 0.014789012260735035, accuracy: 84.02%
Epoch 5: train loss 0.011028035543859005, accuracy: 96.05%
Epoch 8: train loss 0.014663307927548885, accuracy: 84.4%
Epoch 6: train loss 0.010927152819931507, accuracy: 96.38%
Epoch 9: train loss 0.014647958800196648, accuracy: 84.45%
Epoch 7: train loss 0.010857298970222473, accuracy: 96.59%
Epoch 8: train loss 0.01079064141958952, accuracy: 96.81%
Epoch 9: train loss 0.010848896577954292, accuracy: 96.63%
Epoch 10: train loss 0.011666778475046158, accuracy: 94.02%
Epoch 10: train loss 0.010842923074960709, accuracy: 96.64%
Epoch 10: train loss 0.01030999980866909, accuracy: 98.35%
Epoch 10: train loss 0.009814689867198467, accuracy: 99.91%
Epoch 10: train loss 0.014548921026289463, accuracy: 84.77%
Epoch 10: train loss 0.013951919041574001, accuracy: 86.85%
Epoch 10: train loss 0.010281193070113659, accuracy: 98.42%
Acurácia do Cliente: 2 eh: 0.8038861861384995
Acurácia do Cliente: 6 eh: 0.758427554438861
Acurácia do Cliente: 7 eh: 0.6739756367663344
Acurácia do Cliente: 5 eh: 0.5411735958390058
Acurácia do Cliente: 3 eh: 0.8385364332490212
Acurácia do Cliente: 4 eh: 0.8075952339026824
Acurácia do Cliente: 1 eh: 0.8120697001637102
