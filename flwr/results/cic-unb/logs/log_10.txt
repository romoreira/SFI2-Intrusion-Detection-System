INFO flwr 2023-11-06 04:11:02,517 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-06 04:11:02,525 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-06 04:11:02,526 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-06 04:11:02,526 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-06 04:11:16,025 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-06 04:11:16,026 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:36,  2.00it/s]  6%|▋         | 89/1394 [00:00<00:06, 196.89it/s] 13%|█▎        | 182/1394 [00:00<00:03, 373.20it/s] 23%|██▎       | 324/1394 [00:00<00:01, 640.40it/s] 33%|███▎      | 460/1394 [00:00<00:01, 831.39it/s] 43%|████▎     | 594/1394 [00:01<00:00, 970.54it/s] 54%|█████▎    | 748/1394 [00:01<00:00, 1130.40it/s] 65%|██████▌   | 913/1394 [00:01<00:00, 1278.80it/s] 77%|███████▋  | 1080/1394 [00:01<00:00, 1392.11it/s] 90%|████████▉ | 1248/1394 [00:01<00:00, 1474.90it/s]100%|██████████| 1394/1394 [00:01<00:00, 934.82it/s] 
INFO flwr 2023-11-06 04:11:25,857 | server.py:94 | initial parameters (loss, other metrics): 1414.0513831973076, {'accuracy': 0.23881500751272677}
INFO flwr 2023-11-06 04:11:25,858 | server.py:104 | FL starting
DEBUG flwr 2023-11-06 04:11:25,858 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 04:20:59,560 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 04:20:59,568 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1414.0513831973076 / accuracy 0.23881500751272677
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 164/1394 [00:00<00:00, 1637.37it/s] 24%|██▎       | 329/1394 [00:00<00:00, 1638.65it/s] 35%|███▌      | 493/1394 [00:00<00:00, 1636.23it/s] 47%|████▋     | 660/1394 [00:00<00:00, 1647.67it/s] 59%|█████▉    | 827/1394 [00:00<00:00, 1655.00it/s] 71%|███████▏  | 994/1394 [00:00<00:00, 1658.84it/s] 83%|████████▎ | 1161/1394 [00:00<00:00, 1662.09it/s] 95%|█████████▌| 1328/1394 [00:00<00:00, 1663.18it/s]100%|██████████| 1394/1394 [00:00<00:00, 1656.29it/s]
INFO flwr 2023-11-06 04:21:04,434 | server.py:125 | fit progress: (1, 479.63098561763763, {'accuracy': 0.96923145926308}, 578.5761529609445)
DEBUG flwr 2023-11-06 04:21:04,434 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 04:21:06,809 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 04:21:06,810 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-06 04:21:06,810 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 04:30:39,246 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 479.63098561763763 / accuracy 0.96923145926308
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 166/1394 [00:00<00:00, 1653.80it/s] 24%|██▍       | 335/1394 [00:00<00:00, 1670.21it/s] 36%|███▌      | 503/1394 [00:00<00:00, 1667.63it/s] 48%|████▊     | 671/1394 [00:00<00:00, 1670.22it/s] 60%|██████    | 839/1394 [00:00<00:00, 1670.66it/s] 72%|███████▏  | 1007/1394 [00:00<00:00, 1666.77it/s] 84%|████████▍ | 1174/1394 [00:00<00:00, 1662.00it/s] 96%|█████████▌| 1341/1394 [00:00<00:00, 1662.80it/s]100%|██████████| 1394/1394 [00:00<00:00, 1664.58it/s]
INFO flwr 2023-11-06 04:30:44,109 | server.py:125 | fit progress: (2, 480.34325328469276, {'accuracy': 0.9686708080105851}, 1158.251380282978)
DEBUG flwr 2023-11-06 04:30:44,109 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 04:30:46,601 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-06 04:30:46,601 | server.py:153 | FL finished in 1160.7436470399844
INFO flwr 2023-11-06 04:30:46,602 | app.py:225 | app_fit: losses_distributed [(1, 753.7588498142804), (2, 754.2345033738823)]
INFO flwr 2023-11-06 04:30:46,602 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-06 04:30:46,602 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-06 04:30:46,602 | app.py:228 | app_fit: losses_centralized [(0, 1414.0513831973076), (1, 479.63098561763763), (2, 480.34325328469276)]
INFO flwr 2023-11-06 04:30:46,602 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.23881500751272677), (1, 0.96923145926308), (2, 0.9686708080105851)]}
Server-side evaluation loss 480.34325328469276 / accuracy 0.9686708080105851
0392441414296627, accuracy: 98.08%
Epoch 4: train loss 0.010954746976494789, accuracy: 96.29%
Epoch 7: train loss 0.010392092168331146, accuracy: 98.08%
Epoch 5: train loss 0.011022145859897137, accuracy: 96.08%
Epoch 8: train loss 0.010391751304268837, accuracy: 98.08%
Epoch 9: train loss 0.010390912182629108, accuracy: 98.08%
Epoch 6: train loss 0.010965575464069843, accuracy: 96.25%
Epoch 7: train loss 0.011113520711660385, accuracy: 95.75%
Epoch 8: train loss 0.01117330975830555, accuracy: 95.57%
Epoch 9: train loss 0.010964181274175644, accuracy: 96.27%
Epoch 10: train loss 0.010849151760339737, accuracy: 96.63%
Epoch 10: train loss 0.009792317636311054, accuracy: 99.99%
Epoch 10: train loss 0.01149609312415123, accuracy: 94.53%
Epoch 10: train loss 0.010390876792371273, accuracy: 98.08%
Epoch 10: train loss 0.009962041862308979, accuracy: 99.45%
Epoch 10: train loss 0.010142837651073933, accuracy: 98.88%
Epoch 10: train loss 0.010255743749439716, accuracy: 98.51%
Acurácia do Cliente: 5 eh: 0.4445142597828743
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9865586664318835
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.43751937984496125
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.9907349246231156
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9993416721527321
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.6376694432013397
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.9691417550626809
Starting Client training for 10 epochs
Epoch 1: train loss 0.010215198621153831, accuracy: 98.64%
Epoch 1: train loss 0.010179735720157623, accuracy: 98.82%
Epoch 1: train loss 0.020230943337082863, accuracy: 66.59%
Epoch 1: train loss 0.009798728860914707, accuracy: 99.97%
Epoch 1: train loss 0.01062757708132267, accuracy: 97.32%
Epoch 2: train loss 0.010205291211605072, accuracy: 98.66%
Epoch 2: train loss 0.01014754455536604, accuracy: 98.89%
Epoch 1: train loss 0.010782266035676003, accuracy: 96.82%
Epoch 2: train loss 0.01948533207178116, accuracy: 68.97%
Epoch 3: train loss 0.010203498415648937, accuracy: 98.68%
Epoch 3: train loss 0.010138854384422302, accuracy: 98.91%
Epoch 2: train loss 0.009983127005398273, accuracy: 99.38%
Epoch 2: train loss 0.009792942553758621, accuracy: 99.99%
Epoch 1: train loss 0.011085201054811478, accuracy: 95.87%
Epoch 4: train loss 0.010200845077633858, accuracy: 98.68%
Epoch 3: train loss 0.019388779997825623, accuracy: 69.28%
Epoch 4: train loss 0.010135196149349213, accuracy: 98.91%
Epoch 3: train loss 0.009973272681236267, accuracy: 99.4%
Epoch 5: train loss 0.01020002644509077, accuracy: 98.69%
Epoch 3: train loss 0.00979265570640564, accuracy: 99.99%
Epoch 5: train loss 0.010134028270840645, accuracy: 98.91%
Epoch 2: train loss 0.010684026405215263, accuracy: 97.13%
Epoch 4: train loss 0.018332263454794884, accuracy: 72.64%
Epoch 6: train loss 0.010194825008511543, accuracy: 98.7%
Epoch 6: train loss 0.010131334885954857, accuracy: 98.92%
Epoch 4: train loss 0.009973772801458836, accuracy: 99.4%
Epoch 4: train loss 0.009792500175535679, accuracy: 99.99%
Epoch 5: train loss 0.012721599079668522, accuracy: 90.51%
Epoch 7: train loss 0.010190228000283241, accuracy: 98.73%
Epoch 7: train loss 0.010129161179065704, accuracy: 98.92%
Epoch 2: train loss 0.011036240495741367, accuracy: 96.01%
Epoch 3: train loss 0.010606304742395878, accuracy: 97.39%
Epoch 8: train loss 0.010189536958932877, accuracy: 98.73%
Epoch 5: train loss 0.00997445359826088, accuracy: 99.41%
Epoch 6: train loss 0.011738963425159454, accuracy: 93.75%
Epoch 8: train loss 0.010128285735845566, accuracy: 98.93%
Epoch 5: train loss 0.009792433120310307, accuracy: 99.99%
Epoch 9: train loss 0.010189022868871689, accuracy: 98.73%
Epoch 9: train loss 0.010125750675797462, accuracy: 98.92%
Epoch 7: train loss 0.01165030337870121, accuracy: 94.02%
Epoch 6: train loss 0.009970548562705517, accuracy: 99.42%
Epoch 6: train loss 0.00979239959269762, accuracy: 99.99%
Epoch 4: train loss 0.010600465349853039, accuracy: 97.4%
Epoch 8: train loss 0.011616144329309464, accuracy: 94.16%
Epoch 7: train loss 0.009977402165532112, accuracy: 99.39%
Epoch 7: train loss 0.009792370721697807, accuracy: 99.99%
Epoch 3: train loss 0.010928978212177753, accuracy: 96.36%
Epoch 9: train loss 0.011610688641667366, accuracy: 94.2%
Epoch 8: train loss 0.009981516748666763, accuracy: 99.38%
Epoch 5: train loss 0.010598907247185707, accuracy: 97.41%
Epoch 8: train loss 0.009792359545826912, accuracy: 99.99%
Epoch 9: train loss 0.00997166894376278, accuracy: 99.42%
Epoch 9: train loss 0.00979235116392374, accuracy: 99.99%
Epoch 4: train loss 0.010882212780416012, accuracy: 96.5%
Epoch 6: train loss 0.010572558268904686, accuracy: 97.5%
Epoch 7: train loss 0.010501695796847343, accuracy: 97.72%
Epoch 5: train loss 0.010929632000625134, accuracy: 96.38%
Epoch 8: train loss 0.01049493532627821, accuracy: 97.74%
Epoch 6: train loss 0.010855431668460369, accuracy: 96.59%
Epoch 9: train loss 0.010494732297956944, accuracy: 97.75%
Epoch 7: train loss 0.010857568122446537, accuracy: 96.58%
Epoch 8: train loss 0.010911624878644943, accuracy: 96.42%
Epoch 9: train loss 0.01087244600057602, accuracy: 96.55%
Epoch 10: train loss 0.010857945308089256, accuracy: 96.57%
Epoch 10: train loss 0.010124627500772476, accuracy: 98.93%
Epoch 10: train loss 0.009792326018214226, accuracy: 99.99%
Epoch 10: train loss 0.009974573738873005, accuracy: 99.41%
Epoch 10: train loss 0.011597222648561, accuracy: 94.23%
Epoch 10: train loss 0.010494605638086796, accuracy: 97.75%
Epoch 10: train loss 0.010189353488385677, accuracy: 98.73%
Acurácia do Cliente: 3 eh: 0.9997574581615328
Acurácia do Cliente: 6 eh: 0.9907349246231156
Acurácia do Cliente: 1 eh: 0.9691417550626809
Acurácia do Cliente: 2 eh: 0.6376694432013397
Acurácia do Cliente: 4 eh: 0.986617362211657
Acurácia do Cliente: 5 eh: 0.4445142597828743
Acurácia do Cliente: 7 eh: 0.4374307862679956
