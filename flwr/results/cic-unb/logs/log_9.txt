INFO flwr 2023-11-04 01:47:53,846 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=4, round_timeout=None)
INFO flwr 2023-11-04 01:47:53,854 | app.py:175 | Flower ECE: gRPC server running (4 rounds), SSL is disabled
INFO flwr 2023-11-04 01:47:53,854 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-04 01:47:53,854 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-04 01:48:05,966 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-04 01:48:05,967 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:41,  1.99it/s] 10%|▉         | 139/1394 [00:00<00:04, 306.01it/s] 20%|██        | 284/1394 [00:00<00:01, 580.11it/s] 28%|██▊       | 395/1394 [00:00<00:01, 668.53it/s] 36%|███▌      | 496/1394 [00:00<00:01, 719.31it/s] 45%|████▌     | 633/1394 [00:01<00:00, 885.42it/s] 53%|█████▎    | 743/1394 [00:01<00:00, 925.45it/s] 64%|██████▎   | 886/1394 [00:01<00:00, 1062.94it/s] 75%|███████▌  | 1046/1394 [00:01<00:00, 1211.86it/s] 87%|████████▋ | 1206/1394 [00:01<00:00, 1321.79it/s] 98%|█████████▊| 1367/1394 [00:01<00:00, 1404.63it/s]100%|██████████| 1394/1394 [00:01<00:00, 883.78it/s] 
INFO flwr 2023-11-04 01:48:16,676 | server.py:94 | initial parameters (loss, other metrics): 1562.4709362983704, {'accuracy': 0.04471754389899307}
INFO flwr 2023-11-04 01:48:16,677 | server.py:104 | FL starting
DEBUG flwr 2023-11-04 01:48:16,677 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 01:57:33,421 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-04 01:57:33,429 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1562.4709362983704 / accuracy 0.04471754389899307
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 161/1394 [00:00<00:00, 1608.43it/s] 23%|██▎       | 326/1394 [00:00<00:00, 1628.35it/s] 35%|███▌      | 492/1394 [00:00<00:00, 1639.80it/s] 47%|████▋     | 657/1394 [00:00<00:00, 1640.83it/s] 59%|█████▉    | 823/1394 [00:00<00:00, 1644.41it/s] 71%|███████   | 988/1394 [00:00<00:00, 1645.08it/s] 83%|████████▎ | 1153/1394 [00:00<00:00, 1646.45it/s] 95%|█████████▍| 1318/1394 [00:00<00:00, 1644.60it/s]100%|██████████| 1394/1394 [00:00<00:00, 1641.70it/s]
INFO flwr 2023-11-04 01:57:38,089 | server.py:125 | fit progress: (1, 548.3117753863335, {'accuracy': 0.9198268708932296}, 561.4124658720102)
DEBUG flwr 2023-11-04 01:57:38,089 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 01:57:40,483 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-04 01:57:40,483 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-04 01:57:40,483 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 02:06:56,915 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 548.3117753863335 / accuracy 0.9198268708932296
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 165/1394 [00:00<00:00, 1645.99it/s] 24%|██▎       | 331/1394 [00:00<00:00, 1648.73it/s] 36%|███▌      | 496/1394 [00:00<00:00, 1649.21it/s] 47%|████▋     | 661/1394 [00:00<00:00, 1649.36it/s] 59%|█████▉    | 827/1394 [00:00<00:00, 1650.28it/s] 71%|███████   | 993/1394 [00:00<00:00, 1652.45it/s] 83%|████████▎ | 1159/1394 [00:00<00:00, 1650.10it/s] 95%|█████████▌| 1325/1394 [00:00<00:00, 1650.92it/s]100%|██████████| 1394/1394 [00:00<00:00, 1650.33it/s]
INFO flwr 2023-11-04 02:07:01,551 | server.py:125 | fit progress: (2, 480.7866080105305, {'accuracy': 0.9682222870085891}, 1124.8745518070064)
DEBUG flwr 2023-11-04 02:07:01,551 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 02:07:03,988 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
DEBUG flwr 2023-11-04 02:07:03,988 | server.py:222 | fit_round 3: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 02:16:18,885 | server.py:236 | fit_round 3 received 7 results and 0 failures
Server-side evaluation loss 480.7866080105305 / accuracy 0.9682222870085891
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 167/1394 [00:00<00:00, 1661.67it/s] 24%|██▍       | 334/1394 [00:00<00:00, 1661.96it/s] 36%|███▌      | 501/1394 [00:00<00:00, 1665.53it/s] 48%|████▊     | 668/1394 [00:00<00:00, 1665.91it/s] 60%|█████▉    | 835/1394 [00:00<00:00, 1665.93it/s] 72%|███████▏  | 1002/1394 [00:00<00:00, 1664.62it/s] 84%|████████▍ | 1169/1394 [00:00<00:00, 1664.54it/s] 96%|█████████▌| 1336/1394 [00:00<00:00, 1665.76it/s]100%|██████████| 1394/1394 [00:00<00:00, 1665.46it/s]
INFO flwr 2023-11-04 02:16:23,500 | server.py:125 | fit progress: (3, 480.7140708863735, {'accuracy': 0.9684241214594873}, 1686.8235765359714)
DEBUG flwr 2023-11-04 02:16:23,500 | server.py:173 | evaluate_round 3: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 02:16:25,939 | server.py:187 | evaluate_round 3 received 7 results and 0 failures
DEBUG flwr 2023-11-04 02:16:25,940 | server.py:222 | fit_round 4: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 02:25:44,785 | server.py:236 | fit_round 4 received 7 results and 0 failures
Server-side evaluation loss 480.7140708863735 / accuracy 0.9684241214594873
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 166/1394 [00:00<00:00, 1651.13it/s] 24%|██▍       | 332/1394 [00:00<00:00, 1649.03it/s] 36%|███▌      | 498/1394 [00:00<00:00, 1650.95it/s] 48%|████▊     | 664/1394 [00:00<00:00, 1651.91it/s] 60%|█████▉    | 830/1394 [00:00<00:00, 1652.07it/s] 71%|███████▏  | 996/1394 [00:00<00:00, 1651.63it/s] 83%|████████▎ | 1162/1394 [00:00<00:00, 1649.02it/s] 95%|█████████▌| 1328/1394 [00:00<00:00, 1649.78it/s]100%|██████████| 1394/1394 [00:00<00:00, 1650.73it/s]
INFO flwr 2023-11-04 02:25:49,350 | server.py:125 | fit progress: (4, 480.5412391126156, {'accuracy': 0.9685362517099864}, 2252.673242868972)
DEBUG flwr 2023-11-04 02:25:49,350 | server.py:173 | evaluate_round 4: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 02:25:51,715 | server.py:187 | evaluate_round 4 received 7 results and 0 failures
INFO flwr 2023-11-04 02:25:51,716 | server.py:153 | FL finished in 2255.038937030011
INFO flwr 2023-11-04 02:25:51,716 | app.py:225 | app_fit: losses_distributed [(1, 769.6994725671826), (2, 743.270142131773), (3, 752.1311010072219), (4, 756.3244304958563)]
INFO flwr 2023-11-04 02:25:51,716 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-04 02:25:51,716 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-04 02:25:51,716 | app.py:228 | app_fit: losses_centralized [(0, 1562.4709362983704), (1, 548.3117753863335), (2, 480.7866080105305), (3, 480.7140708863735), (4, 480.5412391126156)]
INFO flwr 2023-11-04 02:25:51,716 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.04471754389899307), (1, 0.9198268708932296), (2, 0.9682222870085891), (3, 0.9684241214594873), (4, 0.9685362517099864)]}
Server-side evaluation loss 480.5412391126156 / accuracy 0.9685362517099864
4, accuracy: 99.41%
Epoch 5: train loss 0.010625112801790237, accuracy: 97.32%
Epoch 5: train loss 0.010290541686117649, accuracy: 98.41%
Epoch 2: train loss 0.010751352645456791, accuracy: 96.91%
Epoch 4: train loss 0.011702650226652622, accuracy: 93.88%
Epoch 6: train loss 0.010437903925776482, accuracy: 97.93%
Epoch 6: train loss 0.010292507708072662, accuracy: 98.36%
Epoch 4: train loss 0.009792634285986423, accuracy: 99.99%
Epoch 5: train loss 0.0116097591817379, accuracy: 94.22%
Epoch 4: train loss 0.009968609549105167, accuracy: 99.42%
Epoch 7: train loss 0.010425979271531105, accuracy: 97.95%
Epoch 7: train loss 0.010293046943843365, accuracy: 98.4%
Epoch 3: train loss 0.010739034973084927, accuracy: 96.96%
Epoch 6: train loss 0.011579814366996288, accuracy: 94.29%
Epoch 2: train loss 0.011088441126048565, accuracy: 95.83%
Epoch 8: train loss 0.010418176651000977, accuracy: 97.98%
Epoch 5: train loss 0.009792591445147991, accuracy: 99.99%
Epoch 5: train loss 0.00996733084321022, accuracy: 99.43%
Epoch 8: train loss 0.01029020082205534, accuracy: 98.4%
Epoch 9: train loss 0.010413212701678276, accuracy: 98.01%
Epoch 7: train loss 0.011559151113033295, accuracy: 94.34%
Epoch 9: train loss 0.010293310508131981, accuracy: 98.38%
Epoch 6: train loss 0.009792582131922245, accuracy: 99.99%
Epoch 6: train loss 0.009969350881874561, accuracy: 99.44%
Epoch 8: train loss 0.011546957306563854, accuracy: 94.36%
Epoch 4: train loss 0.01073891669511795, accuracy: 96.98%
Epoch 7: train loss 0.009966862387955189, accuracy: 99.43%
Epoch 7: train loss 0.009792561642825603, accuracy: 99.99%
Epoch 9: train loss 0.011546588502824306, accuracy: 94.39%
Epoch 3: train loss 0.011089139617979527, accuracy: 95.86%
Epoch 8: train loss 0.009968585334718227, accuracy: 99.43%
Epoch 8: train loss 0.009792561642825603, accuracy: 99.99%
Epoch 5: train loss 0.010725761763751507, accuracy: 97.0%
Epoch 9: train loss 0.009965814650058746, accuracy: 99.43%
Epoch 9: train loss 0.009792550466954708, accuracy: 99.99%
Epoch 6: train loss 0.010700640268623829, accuracy: 97.07%
Epoch 4: train loss 0.011163205839693546, accuracy: 95.6%
Epoch 7: train loss 0.01063971221446991, accuracy: 97.26%
Epoch 5: train loss 0.011186915449798107, accuracy: 95.56%
Epoch 8: train loss 0.010647851042449474, accuracy: 97.27%
Epoch 9: train loss 0.010641328990459442, accuracy: 97.27%
Epoch 6: train loss 0.011064252816140652, accuracy: 95.92%
Epoch 7: train loss 0.01092318445444107, accuracy: 96.36%
Epoch 8: train loss 0.011062245815992355, accuracy: 95.92%
Epoch 9: train loss 0.01091973576694727, accuracy: 96.37%
Epoch 10: train loss 0.011536248959600925, accuracy: 94.4%
Epoch 10: train loss 0.010367699898779392, accuracy: 98.11%
Epoch 10: train loss 0.010283700190484524, accuracy: 98.39%
Epoch 10: train loss 0.009792549535632133, accuracy: 99.99%
Epoch 10: train loss 0.009965267032384872, accuracy: 99.43%
Epoch 10: train loss 0.010864675976336002, accuracy: 96.52%
Epoch 10: train loss 0.010644275695085526, accuracy: 97.26%
Acurácia do Cliente: 1 eh: 0.969343589513579
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.9864426298157454
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.6553680472347736
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.4303875968992248
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9880847567059928
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.4497504101651133
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9986486954713973
Starting Client training for 10 epochs
Epoch 1: train loss 0.011245631612837315, accuracy: 95.4%
Epoch 1: train loss 0.011044657789170742, accuracy: 95.94%
Epoch 1: train loss 0.02238948829472065, accuracy: 59.64%
Epoch 1: train loss 0.011607869528234005, accuracy: 94.18%
Epoch 1: train loss 0.009871807880699635, accuracy: 99.74%
Epoch 2: train loss 0.010618248023092747, accuracy: 97.37%
Epoch 2: train loss 0.010565130971372128, accuracy: 97.46%
Epoch 1: train loss 0.011082512326538563, accuracy: 95.88%
Epoch 2: train loss 0.017629235982894897, accuracy: 74.79%
Epoch 3: train loss 0.01050160638988018, accuracy: 97.72%
Epoch 3: train loss 0.010354076512157917, accuracy: 98.15%
Epoch 2: train loss 0.010604296810925007, accuracy: 97.41%
Epoch 2: train loss 0.009796353988349438, accuracy: 99.98%
Epoch 1: train loss 0.011197599582374096, accuracy: 95.51%
Epoch 4: train loss 0.010362178087234497, accuracy: 98.13%
Epoch 3: train loss 0.014306621626019478, accuracy: 85.6%
Epoch 4: train loss 0.01031317375600338, accuracy: 98.28%
Epoch 3: train loss 0.009792782366275787, accuracy: 99.99%
Epoch 3: train loss 0.010297303088009357, accuracy: 98.37%
Epoch 5: train loss 0.010339347645640373, accuracy: 98.19%
Epoch 5: train loss 0.010187217965722084, accuracy: 98.72%
Epoch 4: train loss 0.013163846917450428, accuracy: 89.14%
Epoch 2: train loss 0.010642110370099545, accuracy: 97.25%
Epoch 6: train loss 0.010281242430210114, accuracy: 98.45%
Epoch 6: train loss 0.010188521817326546, accuracy: 98.76%
Epoch 4: train loss 0.010200263932347298, accuracy: 98.66%
Epoch 4: train loss 0.009792647324502468, accuracy: 99.99%
Epoch 5: train loss 0.01201446820050478, accuracy: 92.85%
Epoch 7: train loss 0.01023741066455841, accuracy: 98.56%
Epoch 7: train loss 0.010184899903833866, accuracy: 98.75%
Epoch 2: train loss 0.010971654206514359, accuracy: 96.22%
Epoch 6: train loss 0.01172303780913353, accuracy: 93.84%
Epoch 8: train loss 0.010234302841126919, accuracy: 98.6%
Epoch 5: train loss 0.010137507691979408, accuracy: 98.89%
Epoch 3: train loss 0.010621747002005577, accuracy: 97.33%
Epoch 5: train loss 0.009792570024728775, accuracy: 99.99%
Epoch 8: train loss 0.010162537917494774, accuracy: 98.81%
Epoch 9: train loss 0.01022441778331995, accuracy: 98.61%
Epoch 9: train loss 0.010149749927222729, accuracy: 98.83%
Epoch 7: train loss 0.011655748821794987, accuracy: 94.07%
Epoch 6: train loss 0.010114401578903198, accuracy: 98.96%
Epoch 6: train loss 0.00979255698621273, accuracy: 99.99%
Epoch 8: train loss 0.011640934273600578, accuracy: 94.12%
Epoch 4: train loss 0.010621767491102219, accuracy: 97.34%
Epoch 7: train loss 0.010093572549521923, accuracy: 99.0%
Epoch 7: train loss 0.009792551398277283, accuracy: 99.99%
Epoch 9: train loss 0.011613374575972557, accuracy: 94.17%
Epoch 3: train loss 0.01086907647550106, accuracy: 96.52%
Epoch 8: train loss 0.009792550466954708, accuracy: 99.99%
Epoch 8: train loss 0.010087094269692898, accuracy: 99.04%
Epoch 5: train loss 0.01062135212123394, accuracy: 97.33%
Epoch 9: train loss 0.009792549535632133, accuracy: 99.99%
Epoch 9: train loss 0.010108137503266335, accuracy: 98.99%
Epoch 6: train loss 0.010620730929076672, accuracy: 97.34%
Epoch 4: train loss 0.010880839079618454, accuracy: 96.53%
Epoch 7: train loss 0.01062343642115593, accuracy: 97.34%
Epoch 5: train loss 0.01091482862830162, accuracy: 96.4%
Epoch 8: train loss 0.010620640590786934, accuracy: 97.35%
Epoch 9: train loss 0.010618630796670914, accuracy: 97.34%
Epoch 6: train loss 0.010918228887021542, accuracy: 96.41%
Epoch 7: train loss 0.010934589430689812, accuracy: 96.36%
Epoch 8: train loss 0.010866053402423859, accuracy: 96.57%
Epoch 9: train loss 0.010897073894739151, accuracy: 96.47%
Epoch 10: train loss 0.010908649303019047, accuracy: 96.41%
Epoch 10: train loss 0.011613725684583187, accuracy: 94.2%
Epoch 10: train loss 0.010120580904185772, accuracy: 98.94%
Epoch 10: train loss 0.010151154361665249, accuracy: 98.84%
Epoch 10: train loss 0.010230516083538532, accuracy: 98.6%
Epoch 10: train loss 0.009792549535632133, accuracy: 99.99%
Epoch 10: train loss 0.010605012997984886, accuracy: 97.39%
Acurácia do Cliente: 4 eh: 0.9882608440453131
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.43158361018826136
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.6420002598489989
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.4497504101651133
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.9693660155636787
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.9875942211055276
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9996881604933994
Starting Client training for 10 epochs
Epoch 1: train loss 0.01100839115679264, accuracy: 96.17%
Epoch 1: train loss 0.010664867237210274, accuracy: 97.26%
Epoch 1: train loss 0.026234110817313194, accuracy: 47.44%
Epoch 1: train loss 0.013721676543354988, accuracy: 87.43%
Epoch 1: train loss 0.0098973847925663, accuracy: 99.65%
Epoch 2: train loss 0.01097039133310318, accuracy: 96.22%
Epoch 2: train loss 0.010299512185156345, accuracy: 98.41%
Epoch 2: train loss 0.0261879563331604, accuracy: 47.46%
Epoch 1: train loss 0.011160568334162235, accuracy: 95.66%
Epoch 3: train loss 0.010766246356070042, accuracy: 96.89%
Epoch 3: train loss 0.010283945128321648, accuracy: 98.46%
Epoch 2: train loss 0.012832248583436012, accuracy: 90.27%
Epoch 2: train loss 0.009798298589885235, accuracy: 99.98%
Epoch 3: train loss 0.025545533746480942, accuracy: 49.45%
Epoch 4: train loss 0.010517366230487823, accuracy: 97.69%
Epoch 1: train loss 0.011762643232941628, accuracy: 93.72%
Epoch 4: train loss 0.010282963514328003, accuracy: 98.47%
Epoch 3: train loss 0.011712189763784409, accuracy: 93.82%
Epoch 3: train loss 0.00979255698621273, accuracy: 99.99%
Epoch 5: train loss 0.010492926463484764, accuracy: 97.76%
Epoch 5: train loss 0.01027519442141056, accuracy: 98.45%
Epoch 2: train loss 0.010778154246509075, accuracy: 96.85%
Epoch 4: train loss 0.023282427340745926, accuracy: 56.83%
Epoch 6: train loss 0.010437125340104103, accuracy: 97.9%
Epoch 6: train loss 0.010267706587910652, accuracy: 98.48%
Epoch 4: train loss 0.010795029811561108, accuracy: 96.7%
Epoch 4: train loss 0.009792550466954708, accuracy: 99.99%
Epoch 5: train loss 0.018859678879380226, accuracy: 71.07%
Epoch 7: train loss 0.010340709239244461, accuracy: 98.19%
Epoch 7: train loss 0.010236253961920738, accuracy: 98.61%
Epoch 5: train loss 0.010357440449297428, accuracy: 98.18%
Epoch 6: train loss 0.01367354765534401, accuracy: 87.68%
Epoch 8: train loss 0.010347764007747173, accuracy: 98.22%
Epoch 3: train loss 0.010636352002620697, accuracy: 97.29%
Epoch 5: train loss 0.009792550466954708, accuracy: 99.99%
Epoch 2: train loss 0.010940167121589184, accuracy: 96.32%
Epoch 8: train loss 0.010168983601033688, accuracy: 98.8%
Epoch 9: train loss 0.010238626971840858, accuracy: 98.55%
Epoch 9: train loss 0.010170997120440006, accuracy: 98.8%
Epoch 7: train loss 0.01344422996044159, accuracy: 88.38%
Epoch 6: train loss 0.010241303592920303, accuracy: 98.62%
Epoch 6: train loss 0.00979254674166441, accuracy: 99.99%
Epoch 4: train loss 0.010623008012771606, accuracy: 97.34%
Epoch 8: train loss 0.013246542774140835, accuracy: 88.92%
Epoch 7: train loss 0.010221639648079872, accuracy: 98.63%
Epoch 7: train loss 0.00979254674166441, accuracy: 99.99%
Epoch 9: train loss 0.013163857161998749, accuracy: 89.23%
Epoch 3: train loss 0.010890061035752296, accuracy: 96.48%
Epoch 8: train loss 0.00979254674166441, accuracy: 99.99%
Epoch 8: train loss 0.01017164345830679, accuracy: 98.79%
Epoch 5: train loss 0.01061965525150299, accuracy: 97.34%
Epoch 9: train loss 0.00979254674166441, accuracy: 99.99%
Epoch 9: train loss 0.010171142406761646, accuracy: 98.78%
Epoch 6: train loss 0.01062359195202589, accuracy: 97.34%
Epoch 4: train loss 0.010871421545743942, accuracy: 96.54%
Epoch 7: train loss 0.010622983798384666, accuracy: 97.35%
Epoch 5: train loss 0.010814713314175606, accuracy: 96.73%
Epoch 8: train loss 0.010621517896652222, accuracy: 97.34%
Epoch 9: train loss 0.010623302310705185, accuracy: 97.34%
Epoch 6: train loss 0.010865414515137672, accuracy: 96.56%
Epoch 7: train loss 0.01085338182747364, accuracy: 96.58%
Epoch 8: train loss 0.010892592370510101, accuracy: 96.46%
Epoch 9: train loss 0.010805709287524223, accuracy: 96.74%
Epoch 10: train loss 0.010170642286539078, accuracy: 98.74%
Epoch 10: train loss 0.013088948093354702, accuracy: 89.41%
Epoch 10: train loss 0.010165181942284107, accuracy: 98.83%
Epoch 10: train loss 0.010622793808579445, accuracy: 97.35%
Epoch 10: train loss 0.010232153348624706, accuracy: 98.58%
Epoch 10: train loss 0.010789142921566963, accuracy: 96.81%
Epoch 10: train loss 0.00979254674166441, accuracy: 99.99%
Acurácia do Cliente: 1 eh: 0.9693660155636787
Acurácia do Cliente: 4 eh: 0.9882608440453131
Acurácia do Cliente: 5 eh: 0.4497504101651133
Acurácia do Cliente: 3 eh: 0.9998267558296663
Acurácia do Cliente: 2 eh: 0.6356339593769399
Acurácia do Cliente: 7 eh: 0.43158361018826136
Acurácia do Cliente: 6 eh: 0.9875942211055276
