INFO flwr 2023-11-06 03:50:24,048 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-06 03:50:24,056 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-06 03:50:24,056 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-06 03:50:24,056 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-06 03:50:37,188 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-06 03:50:37,189 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<12:04,  1.92it/s] 11%|█         | 149/1394 [00:00<00:03, 320.42it/s] 21%|██▏       | 297/1394 [00:00<00:01, 593.03it/s] 32%|███▏      | 445/1394 [00:00<00:01, 814.20it/s] 42%|████▏     | 591/1394 [00:00<00:00, 984.10it/s] 53%|█████▎    | 737/1394 [00:01<00:00, 1113.13it/s] 63%|██████▎   | 884/1394 [00:01<00:00, 1212.58it/s] 74%|███████▎  | 1025/1394 [00:01<00:00, 1177.59it/s] 83%|████████▎ | 1157/1394 [00:01<00:00, 1134.36it/s] 94%|█████████▎| 1306/1394 [00:01<00:00, 1227.75it/s]100%|██████████| 1394/1394 [00:01<00:00, 905.60it/s] 
INFO flwr 2023-11-06 03:50:46,591 | server.py:94 | initial parameters (loss, other metrics): 1143.967032134533, {'accuracy': 0.3690430804422417}
INFO flwr 2023-11-06 03:50:46,591 | server.py:104 | FL starting
DEBUG flwr 2023-11-06 03:50:46,706 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 04:00:11,652 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 04:00:11,661 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1143.967032134533 / accuracy 0.3690430804422417
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 164/1394 [00:00<00:00, 1631.05it/s] 24%|██▎       | 328/1394 [00:00<00:00, 1617.08it/s] 35%|███▌      | 491/1394 [00:00<00:00, 1620.87it/s] 47%|████▋     | 654/1394 [00:00<00:00, 1617.38it/s] 59%|█████▊    | 817/1394 [00:00<00:00, 1620.78it/s] 70%|███████   | 982/1394 [00:00<00:00, 1629.25it/s] 82%|████████▏ | 1147/1394 [00:00<00:00, 1634.60it/s] 94%|█████████▍| 1313/1394 [00:00<00:00, 1640.68it/s]100%|██████████| 1394/1394 [00:00<00:00, 1631.94it/s]
INFO flwr 2023-11-06 04:00:16,512 | server.py:125 | fit progress: (1, 497.98076033592224, {'accuracy': 0.9558655334036016}, 569.9210226960131)
DEBUG flwr 2023-11-06 04:00:16,512 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 04:00:19,035 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 04:00:19,035 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-06 04:00:19,035 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 04:09:45,451 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 497.98076033592224 / accuracy 0.9558655334036016
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 164/1394 [00:00<00:00, 1634.36it/s] 24%|██▎       | 328/1394 [00:00<00:00, 1637.27it/s] 35%|███▌      | 492/1394 [00:00<00:00, 1635.55it/s] 47%|████▋     | 657/1394 [00:00<00:00, 1639.44it/s] 59%|█████▉    | 822/1394 [00:00<00:00, 1642.87it/s] 71%|███████   | 987/1394 [00:00<00:00, 1640.06it/s] 83%|████████▎ | 1152/1394 [00:00<00:00, 1637.41it/s] 94%|█████████▍| 1316/1394 [00:00<00:00, 1636.63it/s]100%|██████████| 1394/1394 [00:00<00:00, 1637.26it/s]
INFO flwr 2023-11-06 04:09:50,201 | server.py:125 | fit progress: (2, 489.58309492468834, {'accuracy': 0.9620102711309457}, 1143.6099401380052)
DEBUG flwr 2023-11-06 04:09:50,201 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 04:09:52,714 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-06 04:09:52,714 | server.py:153 | FL finished in 1146.1227652780362
INFO flwr 2023-11-06 04:09:52,714 | app.py:225 | app_fit: losses_distributed [(1, 632.0279181369748), (2, 646.493585541601)]
INFO flwr 2023-11-06 04:09:52,714 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-06 04:09:52,714 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-06 04:09:52,714 | app.py:228 | app_fit: losses_centralized [(0, 1143.967032134533), (1, 497.98076033592224), (2, 489.58309492468834)]
INFO flwr 2023-11-06 04:09:52,714 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.3690430804422417), (1, 0.9558655334036016), (2, 0.9620102711309457)]}
Server-side evaluation loss 489.58309492468834 / accuracy 0.9620102711309457
 loss 0.011186334304511547, accuracy: 95.54%
Epoch 6: train loss 0.010297887027263641, accuracy: 98.38%
Epoch 7: train loss 0.010293479077517986, accuracy: 98.39%
Epoch 5: train loss 0.011177154257893562, accuracy: 95.55%
Epoch 8: train loss 0.01029441598802805, accuracy: 98.4%
Epoch 6: train loss 0.011155873537063599, accuracy: 95.65%
Epoch 9: train loss 0.010294816456735134, accuracy: 98.39%
Epoch 7: train loss 0.011166855692863464, accuracy: 95.59%
Epoch 8: train loss 0.01115384791046381, accuracy: 95.65%
Epoch 9: train loss 0.011158518493175507, accuracy: 95.6%
Epoch 10: train loss 0.010293724946677685, accuracy: 98.39%
Epoch 10: train loss 0.01093409862369299, accuracy: 96.26%
Epoch 10: train loss 0.01012214832007885, accuracy: 98.97%
Epoch 10: train loss 0.009962442331016064, accuracy: 99.44%
Epoch 10: train loss 0.009861193597316742, accuracy: 99.77%
Epoch 10: train loss 0.009793028235435486, accuracy: 99.99%
Epoch 10: train loss 0.011163455434143543, accuracy: 95.63%
Acurácia do Cliente: 1 eh: 0.955596420802404
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.5546828638251824
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.9295435510887772
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.800190555932497
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9781019368698244
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.6406644518272425
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9725890708458061
Starting Client training for 10 epochs
Epoch 1: train loss 0.011535871773958206, accuracy: 94.52%
Epoch 1: train loss 0.011281732469797134, accuracy: 95.21%
Epoch 1: train loss 0.020518068224191666, accuracy: 65.61%
Epoch 1: train loss 0.01069270446896553, accuracy: 97.18%
Epoch 1: train loss 0.010099363513290882, accuracy: 99.0%
Epoch 2: train loss 0.011203964240849018, accuracy: 95.5%
Epoch 2: train loss 0.010534425266087055, accuracy: 97.64%
Epoch 1: train loss 0.011614128947257996, accuracy: 94.18%
Epoch 2: train loss 0.019877886399626732, accuracy: 67.82%
Epoch 3: train loss 0.011073986068367958, accuracy: 95.84%
Epoch 3: train loss 0.010268257930874825, accuracy: 98.49%
Epoch 2: train loss 0.010016504675149918, accuracy: 99.29%
Epoch 2: train loss 0.009801222011446953, accuracy: 99.96%
Epoch 1: train loss 0.011259760707616806, accuracy: 95.3%
Epoch 4: train loss 0.01096857525408268, accuracy: 96.19%
Epoch 4: train loss 0.010188225656747818, accuracy: 98.74%
Epoch 3: train loss 0.01886095106601715, accuracy: 71.09%
Epoch 3: train loss 0.010005481541156769, accuracy: 99.3%
Epoch 3: train loss 0.00979840848594904, accuracy: 99.97%
Epoch 5: train loss 0.01093691773712635, accuracy: 96.4%
Epoch 5: train loss 0.010175128467381, accuracy: 98.78%
Epoch 2: train loss 0.01137311477214098, accuracy: 94.92%
Epoch 4: train loss 0.01838357374072075, accuracy: 72.54%
Epoch 6: train loss 0.01091836392879486, accuracy: 96.33%
Epoch 6: train loss 0.010142713785171509, accuracy: 98.9%
Epoch 4: train loss 0.0099854851141572, accuracy: 99.37%
Epoch 4: train loss 0.009793031960725784, accuracy: 99.99%
Epoch 5: train loss 0.018292564898729324, accuracy: 72.73%
Epoch 7: train loss 0.010933068580925465, accuracy: 96.39%
Epoch 7: train loss 0.01012894231826067, accuracy: 98.95%
Epoch 2: train loss 0.011144790798425674, accuracy: 95.66%
Epoch 3: train loss 0.011261027306318283, accuracy: 95.36%
Epoch 8: train loss 0.010747365653514862, accuracy: 96.94%
Epoch 5: train loss 0.00979303102940321, accuracy: 99.99%
Epoch 8: train loss 0.010123436339199543, accuracy: 98.96%
Epoch 5: train loss 0.009989150799810886, accuracy: 99.36%
Epoch 6: train loss 0.018101908266544342, accuracy: 73.37%
Epoch 9: train loss 0.010499631054699421, accuracy: 97.68%
Epoch 9: train loss 0.010121346451342106, accuracy: 98.96%
Epoch 7: train loss 0.014130514115095139, accuracy: 86.04%
Epoch 6: train loss 0.009793030098080635, accuracy: 99.99%
Epoch 6: train loss 0.00998613890260458, accuracy: 99.37%
Epoch 4: train loss 0.011123922653496265, accuracy: 95.72%
Epoch 8: train loss 0.011842704378068447, accuracy: 93.49%
Epoch 7: train loss 0.009988420642912388, accuracy: 99.36%
Epoch 7: train loss 0.00979303102940321, accuracy: 99.99%
Epoch 3: train loss 0.011094866320490837, accuracy: 95.79%
Epoch 9: train loss 0.011656179092824459, accuracy: 94.04%
Epoch 8: train loss 0.009980383329093456, accuracy: 99.38%
Epoch 8: train loss 0.009793028235435486, accuracy: 99.99%
Epoch 5: train loss 0.010995899327099323, accuracy: 96.19%
Epoch 9: train loss 0.009989210404455662, accuracy: 99.36%
Epoch 9: train loss 0.009793028235435486, accuracy: 99.99%
Epoch 4: train loss 0.011037400923669338, accuracy: 96.01%
Epoch 6: train loss 0.010997061617672443, accuracy: 96.14%
Epoch 7: train loss 0.01114765927195549, accuracy: 95.64%
Epoch 5: train loss 0.011033953167498112, accuracy: 96.0%
Epoch 8: train loss 0.011077460832893848, accuracy: 95.86%
Epoch 9: train loss 0.011057235300540924, accuracy: 95.94%
Epoch 6: train loss 0.01098566222935915, accuracy: 96.18%
Epoch 7: train loss 0.011024494655430317, accuracy: 96.05%
Epoch 8: train loss 0.010936098173260689, accuracy: 96.33%
Epoch 9: train loss 0.010973608121275902, accuracy: 96.2%
Epoch 10: train loss 0.011034502647817135, accuracy: 96.02%
Epoch 10: train loss 0.009793028235435486, accuracy: 99.99%
Epoch 10: train loss 0.009991551749408245, accuracy: 99.35%
Epoch 10: train loss 0.011619754135608673, accuracy: 94.15%
Epoch 10: train loss 0.011038543656468391, accuracy: 96.01%
Epoch 10: train loss 0.010121908970177174, accuracy: 98.96%
Epoch 10: train loss 0.010443449020385742, accuracy: 97.9%
Acurácia do Cliente: 2 eh: 0.7615019272134083
Acurácia do Cliente: 6 eh: 0.9572340871021775
Acurácia do Cliente: 5 eh: 0.5751387579851294
Acurácia do Cliente: 7 eh: 0.6721594684385382
Acurácia do Cliente: 1 eh: 0.9629521652351372
Acurácia do Cliente: 3 eh: 0.9895360521118465
Acurácia do Cliente: 4 eh: 0.980395609555673
