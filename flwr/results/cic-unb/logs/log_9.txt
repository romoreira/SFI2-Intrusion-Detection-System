INFO flwr 2023-11-03 19:40:41,508 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-03 19:40:41,519 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-03 19:40:41,519 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-03 19:40:41,519 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-03 19:40:54,790 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-03 19:40:54,791 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:05,  2.09it/s] 11%|█         | 152/1394 [00:00<00:03, 348.64it/s] 22%|██▏       | 302/1394 [00:00<00:01, 633.03it/s] 30%|███       | 419/1394 [00:00<00:01, 759.16it/s] 38%|███▊      | 533/1394 [00:00<00:01, 860.46it/s] 49%|████▊     | 678/1394 [00:00<00:00, 1022.73it/s] 59%|█████▊    | 818/1394 [00:01<00:00, 1129.09it/s] 69%|██████▉   | 962/1394 [00:01<00:00, 1216.79it/s] 80%|████████  | 1122/1394 [00:01<00:00, 1327.11it/s] 93%|█████████▎| 1290/1394 [00:01<00:00, 1428.95it/s]100%|██████████| 1394/1394 [00:01<00:00, 961.30it/s] 
INFO flwr 2023-11-03 19:41:04,323 | server.py:94 | initial parameters (loss, other metrics): 761.995908677578, {'accuracy': 0.8393846291852616}
INFO flwr 2023-11-03 19:41:04,323 | server.py:104 | FL starting
DEBUG flwr 2023-11-03 19:41:04,323 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 19:50:25,022 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 19:50:25,030 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 761.995908677578 / accuracy 0.8393846291852616
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 166/1394 [00:00<00:00, 1657.21it/s] 24%|██▍       | 332/1394 [00:00<00:00, 1652.51it/s] 36%|███▌      | 499/1394 [00:00<00:00, 1659.92it/s] 48%|████▊     | 666/1394 [00:00<00:00, 1662.68it/s] 60%|█████▉    | 834/1394 [00:00<00:00, 1666.63it/s] 72%|███████▏  | 1001/1394 [00:00<00:00, 1658.79it/s] 84%|████████▍ | 1168/1394 [00:00<00:00, 1660.70it/s] 96%|█████████▌| 1335/1394 [00:00<00:00, 1659.63it/s]100%|██████████| 1394/1394 [00:00<00:00, 1660.10it/s]
INFO flwr 2023-11-03 19:50:29,744 | server.py:125 | fit progress: (1, 695.0753654241562, {'accuracy': 0.8144244354241887}, 565.4212405279977)
DEBUG flwr 2023-11-03 19:50:29,745 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 19:50:32,193 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 19:50:32,193 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-03 19:50:32,193 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:00:08,848 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 695.0753654241562 / accuracy 0.8144244354241887
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 167/1394 [00:00<00:00, 1661.60it/s] 24%|██▍       | 334/1394 [00:00<00:00, 1666.43it/s] 36%|███▌      | 501/1394 [00:00<00:00, 1664.71it/s] 48%|████▊     | 668/1394 [00:00<00:00, 1664.10it/s] 60%|█████▉    | 835/1394 [00:00<00:00, 1659.07it/s] 72%|███████▏  | 1002/1394 [00:00<00:00, 1662.61it/s] 84%|████████▍ | 1169/1394 [00:00<00:00, 1654.57it/s] 96%|█████████▌| 1335/1394 [00:00<00:00, 1655.71it/s]100%|██████████| 1394/1394 [00:00<00:00, 1658.78it/s]
INFO flwr 2023-11-03 20:00:13,465 | server.py:125 | fit progress: (2, 680.4799518287182, {'accuracy': 0.8251216613217914}, 1149.1417389689886)
DEBUG flwr 2023-11-03 20:00:13,465 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:00:15,911 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-03 20:00:15,911 | server.py:153 | FL finished in 1151.5879660279898
INFO flwr 2023-11-03 20:00:15,911 | app.py:225 | app_fit: losses_distributed [(1, 702.7812213411762), (2, 819.4129842145386)]
INFO flwr 2023-11-03 20:00:15,911 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-03 20:00:15,911 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-03 20:00:15,911 | app.py:228 | app_fit: losses_centralized [(0, 761.995908677578), (1, 695.0753654241562), (2, 680.4799518287182)]
INFO flwr 2023-11-03 20:00:15,911 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.8393846291852616), (1, 0.8144244354241887), (2, 0.8251216613217914)]}
Server-side evaluation loss 680.4799518287182 / accuracy 0.8251216613217914
loss 0.010295175947248936, accuracy: 98.38%
Epoch 4: train loss 0.010995625518262386, accuracy: 96.17%
Epoch 7: train loss 0.010294140316545963, accuracy: 98.39%
Epoch 5: train loss 0.010974237695336342, accuracy: 96.22%
Epoch 8: train loss 0.010291474871337414, accuracy: 98.39%
Epoch 9: train loss 0.010291095823049545, accuracy: 98.4%
Epoch 6: train loss 0.010885977186262608, accuracy: 96.5%
Epoch 7: train loss 0.010901319794356823, accuracy: 96.46%
Epoch 8: train loss 0.011008813045918941, accuracy: 96.09%
Epoch 9: train loss 0.010958908125758171, accuracy: 96.26%
Epoch 10: train loss 0.010934758000075817, accuracy: 96.32%
Epoch 10: train loss 0.00979254674166441, accuracy: 99.99%
Epoch 10: train loss 0.00985860824584961, accuracy: 99.77%
Epoch 10: train loss 0.010292229242622852, accuracy: 98.39%
Epoch 10: train loss 0.009952982887625694, accuracy: 99.47%
Epoch 10: train loss 0.01012317556887865, accuracy: 98.96%
Epoch 10: train loss 0.011510261334478855, accuracy: 94.48%
Acurácia do Cliente: 5 eh: 0.5754529270080637
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.8141553228229912
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.7470163316582915
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.7989082584962142
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.6903211517165005
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.7849605173882288
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.8407886074633588
Starting Client training for 10 epochs
Epoch 1: train loss 0.014600875787436962, accuracy: 84.61%
Epoch 1: train loss 0.012060672976076603, accuracy: 92.56%
Epoch 1: train loss 0.019436858594417572, accuracy: 69.11%
Epoch 1: train loss 0.011184506118297577, accuracy: 95.57%
Epoch 1: train loss 0.01002947986125946, accuracy: 99.22%
Epoch 2: train loss 0.013011902570724487, accuracy: 89.62%
Epoch 2: train loss 0.010473708622157574, accuracy: 97.79%
Epoch 2: train loss 0.014248788356781006, accuracy: 85.7%
Epoch 1: train loss 0.014196103438735008, accuracy: 85.92%
Epoch 3: train loss 0.011094581335783005, accuracy: 95.8%
Epoch 3: train loss 0.010331247001886368, accuracy: 98.3%
Epoch 2: train loss 0.009797670878469944, accuracy: 99.96%
Epoch 2: train loss 0.010121415369212627, accuracy: 98.96%
Epoch 1: train loss 0.011231476441025734, accuracy: 95.42%
Epoch 3: train loss 0.012006537057459354, accuracy: 92.97%
Epoch 4: train loss 0.01031426340341568, accuracy: 98.3%
Epoch 4: train loss 0.011062263511121273, accuracy: 96.02%
Epoch 3: train loss 0.009795154444873333, accuracy: 99.98%
Epoch 3: train loss 0.0101543590426445, accuracy: 98.82%
Epoch 5: train loss 0.010261844843626022, accuracy: 98.51%
Epoch 5: train loss 0.010546491481363773, accuracy: 97.62%
Epoch 4: train loss 0.011766108684241772, accuracy: 93.69%
Epoch 2: train loss 0.01181688904762268, accuracy: 93.5%
Epoch 6: train loss 0.010184093378484249, accuracy: 98.75%
Epoch 6: train loss 0.010363503359258175, accuracy: 98.15%
Epoch 4: train loss 0.01005107257515192, accuracy: 99.18%
Epoch 4: train loss 0.009793953970074654, accuracy: 99.99%
Epoch 5: train loss 0.011661697179079056, accuracy: 94.04%
Epoch 7: train loss 0.010181647725403309, accuracy: 98.74%
Epoch 7: train loss 0.010358373634517193, accuracy: 98.16%
Epoch 3: train loss 0.011478752829134464, accuracy: 94.61%
Epoch 2: train loss 0.011177713051438332, accuracy: 95.53%
Epoch 6: train loss 0.011622313410043716, accuracy: 94.13%
Epoch 5: train loss 0.009793114848434925, accuracy: 99.99%
Epoch 5: train loss 0.010050436481833458, accuracy: 99.16%
Epoch 8: train loss 0.010178840719163418, accuracy: 98.76%
Epoch 8: train loss 0.010247328318655491, accuracy: 98.53%
Epoch 9: train loss 0.010217750445008278, accuracy: 98.63%
Epoch 9: train loss 0.010178642347455025, accuracy: 98.78%
Epoch 7: train loss 0.01160439569503069, accuracy: 94.17%
Epoch 6: train loss 0.009792761877179146, accuracy: 99.99%
Epoch 6: train loss 0.010107843205332756, accuracy: 98.99%
Epoch 4: train loss 0.011406205594539642, accuracy: 94.84%
Epoch 8: train loss 0.01160050556063652, accuracy: 94.22%
Epoch 7: train loss 0.009792612865567207, accuracy: 99.99%
Epoch 7: train loss 0.010193949565291405, accuracy: 98.72%
Epoch 3: train loss 0.011123915202915668, accuracy: 95.73%
Epoch 9: train loss 0.011592979542911053, accuracy: 94.23%
Epoch 8: train loss 0.009792574681341648, accuracy: 99.99%
Epoch 8: train loss 0.010203728452324867, accuracy: 98.67%
Epoch 5: train loss 0.011333606205880642, accuracy: 95.08%
Epoch 9: train loss 0.00979255884885788, accuracy: 99.99%
Epoch 9: train loss 0.01017941813915968, accuracy: 98.72%
Epoch 4: train loss 0.01106975320726633, accuracy: 95.93%
Epoch 6: train loss 0.01132157351821661, accuracy: 95.13%
Epoch 7: train loss 0.011340293101966381, accuracy: 94.99%
Epoch 5: train loss 0.010999910533428192, accuracy: 96.13%
Epoch 8: train loss 0.011401738971471786, accuracy: 94.88%
Epoch 9: train loss 0.010960214771330357, accuracy: 96.25%
Epoch 6: train loss 0.010884348303079605, accuracy: 96.51%
Epoch 7: train loss 0.010909974575042725, accuracy: 96.42%
Epoch 8: train loss 0.01101461797952652, accuracy: 96.09%
Epoch 9: train loss 0.010967900976538658, accuracy: 96.24%
Epoch 10: train loss 0.010867142118513584, accuracy: 96.57%
Epoch 10: train loss 0.010197591036558151, accuracy: 98.7%
Epoch 10: train loss 0.011582532897591591, accuracy: 94.26%
Epoch 10: train loss 0.010786302387714386, accuracy: 96.85%
Epoch 10: train loss 0.010196610353887081, accuracy: 98.7%
Epoch 10: train loss 0.009792553260922432, accuracy: 99.99%
Epoch 10: train loss 0.010179666802287102, accuracy: 98.75%
Acurácia do Cliente: 2 eh: 0.634406894660103
Acurácia do Cliente: 7 eh: 0.43145071982281286
Acurácia do Cliente: 3 eh: 0.8748830601850248
Acurácia do Cliente: 4 eh: 0.8227974408640019
Acurácia do Cliente: 5 eh: 0.4509721785876357
Acurácia do Cliente: 6 eh: 0.8313442211055276
Acurácia do Cliente: 1 eh: 0.8271400058307731
