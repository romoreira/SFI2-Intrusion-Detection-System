INFO flwr 2023-11-06 02:27:14,071 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-06 02:27:14,079 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-06 02:27:14,079 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-06 02:27:14,079 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-06 02:27:28,184 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-06 02:27:28,184 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:28,  2.02it/s]  9%|▉         | 132/1394 [00:00<00:04, 295.13it/s] 20%|█▉        | 273/1394 [00:00<00:01, 565.04it/s] 27%|██▋       | 381/1394 [00:00<00:01, 696.27it/s] 35%|███▌      | 488/1394 [00:00<00:01, 769.52it/s] 44%|████▍     | 610/1394 [00:01<00:00, 891.21it/s] 54%|█████▍    | 750/1394 [00:01<00:00, 1032.21it/s] 62%|██████▏   | 870/1394 [00:01<00:00, 1077.71it/s] 73%|███████▎  | 1020/1394 [00:01<00:00, 1198.94it/s] 84%|████████▍ | 1177/1394 [00:01<00:00, 1305.53it/s] 96%|█████████▌| 1334/1394 [00:01<00:00, 1382.12it/s]100%|██████████| 1394/1394 [00:01<00:00, 900.04it/s] 
INFO flwr 2023-11-06 02:27:37,273 | server.py:94 | initial parameters (loss, other metrics): 1382.6261456012726, {'accuracy': 0.3834406046063107}
INFO flwr 2023-11-06 02:27:37,273 | server.py:104 | FL starting
DEBUG flwr 2023-11-06 02:27:37,273 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:37:06,694 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 02:37:06,702 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1382.6261456012726 / accuracy 0.3834406046063107
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 162/1394 [00:00<00:00, 1619.84it/s] 23%|██▎       | 326/1394 [00:00<00:00, 1627.38it/s] 35%|███▌      | 489/1394 [00:00<00:00, 1626.17it/s] 47%|████▋     | 652/1394 [00:00<00:00, 1626.55it/s] 59%|█████▊    | 816/1394 [00:00<00:00, 1629.26it/s] 70%|███████   | 980/1394 [00:00<00:00, 1632.01it/s] 82%|████████▏ | 1144/1394 [00:00<00:00, 1632.86it/s] 94%|█████████▍| 1308/1394 [00:00<00:00, 1627.66it/s]100%|██████████| 1394/1394 [00:00<00:00, 1624.98it/s]
INFO flwr 2023-11-06 02:37:11,569 | server.py:125 | fit progress: (1, 480.0368696451187, {'accuracy': 0.968895068511583}, 574.2959668590338)
DEBUG flwr 2023-11-06 02:37:11,569 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:37:13,936 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 02:37:13,936 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-06 02:37:13,936 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:46:42,247 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 480.0368696451187 / accuracy 0.968895068511583
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 163/1394 [00:00<00:00, 1626.94it/s] 24%|██▎       | 328/1394 [00:00<00:00, 1635.69it/s] 35%|███▌      | 493/1394 [00:00<00:00, 1641.92it/s] 47%|████▋     | 659/1394 [00:00<00:00, 1646.47it/s] 59%|█████▉    | 824/1394 [00:00<00:00, 1641.32it/s] 71%|███████   | 989/1394 [00:00<00:00, 1642.39it/s] 83%|████████▎ | 1154/1394 [00:00<00:00, 1642.04it/s] 95%|█████████▍| 1319/1394 [00:00<00:00, 1644.04it/s]100%|██████████| 1394/1394 [00:00<00:00, 1642.66it/s]
INFO flwr 2023-11-06 02:46:46,941 | server.py:125 | fit progress: (2, 483.53801867365837, {'accuracy': 0.9664057769505057}, 1149.6685431789956)
DEBUG flwr 2023-11-06 02:46:46,942 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:46:49,405 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-06 02:46:49,405 | server.py:153 | FL finished in 1152.1320690599969
INFO flwr 2023-11-06 02:46:49,405 | app.py:225 | app_fit: losses_distributed [(1, 758.8734331654312), (2, 759.9656384571874)]
INFO flwr 2023-11-06 02:46:49,405 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-06 02:46:49,405 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-06 02:46:49,405 | app.py:228 | app_fit: losses_centralized [(0, 1382.6261456012726), (1, 480.0368696451187), (2, 483.53801867365837)]
INFO flwr 2023-11-06 02:46:49,405 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.3834406046063107), (1, 0.968895068511583), (2, 0.9664057769505057)]}
Server-side evaluation loss 483.53801867365837 / accuracy 0.9664057769505057
oss 0.010333782061934471, accuracy: 98.27%
Epoch 4: train loss 0.010955392383038998, accuracy: 96.27%
Epoch 7: train loss 0.010327302850782871, accuracy: 98.29%
Epoch 5: train loss 0.010991224087774754, accuracy: 96.17%
Epoch 8: train loss 0.010329024866223335, accuracy: 98.28%
Epoch 9: train loss 0.010324692353606224, accuracy: 98.29%
Epoch 6: train loss 0.01110780518501997, accuracy: 95.79%
Epoch 7: train loss 0.010998242534697056, accuracy: 96.16%
Epoch 8: train loss 0.010988662950694561, accuracy: 96.18%
Epoch 9: train loss 0.010989226400852203, accuracy: 96.17%
Epoch 10: train loss 0.010321198962628841, accuracy: 98.29%
Epoch 10: train loss 0.010887112468481064, accuracy: 96.5%
Epoch 10: train loss 0.01152415107935667, accuracy: 94.49%
Epoch 10: train loss 0.009792796336114407, accuracy: 99.99%
Epoch 10: train loss 0.009953256696462631, accuracy: 99.47%
Epoch 10: train loss 0.0101118553429842, accuracy: 98.97%
Epoch 10: train loss 0.010541410185396671, accuracy: 97.55%
Acurácia do Cliente: 6 eh: 0.989426298157454
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.9681998609584894
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9995842139911992
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.44723705798163854
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.6331798299432663
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.4283942414174972
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9872630157891648
Starting Client training for 10 epochs
Epoch 1: train loss 0.01044507697224617, accuracy: 97.96%
Epoch 1: train loss 0.010432957671582699, accuracy: 97.95%
Epoch 1: train loss 0.027147628366947174, accuracy: 44.42%
Epoch 1: train loss 0.009891044348478317, accuracy: 99.66%
Epoch 1: train loss 0.010333209298551083, accuracy: 98.21%
Epoch 2: train loss 0.010426041670143604, accuracy: 97.94%
Epoch 2: train loss 0.01040301751345396, accuracy: 98.02%
Epoch 2: train loss 0.02712262235581875, accuracy: 44.54%
Epoch 1: train loss 0.010921432636678219, accuracy: 96.35%
Epoch 3: train loss 0.010335524566471577, accuracy: 98.22%
Epoch 3: train loss 0.010428045876324177, accuracy: 98.04%
Epoch 2: train loss 0.009798625484108925, accuracy: 99.98%
Epoch 2: train loss 0.009979496710002422, accuracy: 99.39%
Epoch 3: train loss 0.027093080803751945, accuracy: 44.66%
Epoch 1: train loss 0.015569860115647316, accuracy: 81.53%
Epoch 4: train loss 0.010219133459031582, accuracy: 98.61%
Epoch 4: train loss 0.010419705882668495, accuracy: 98.02%
Epoch 3: train loss 0.009793246164917946, accuracy: 99.99%
Epoch 3: train loss 0.009973750449717045, accuracy: 99.4%
Epoch 5: train loss 0.010196772404015064, accuracy: 98.67%
Epoch 5: train loss 0.010405252687633038, accuracy: 97.97%
Epoch 4: train loss 0.027072682976722717, accuracy: 44.74%
Epoch 2: train loss 0.010819570161402225, accuracy: 96.7%
Epoch 6: train loss 0.010184490121901035, accuracy: 98.72%
Epoch 6: train loss 0.010344317182898521, accuracy: 98.22%
Epoch 4: train loss 0.009973935782909393, accuracy: 99.4%
Epoch 4: train loss 0.009792814962565899, accuracy: 99.99%
Epoch 5: train loss 0.027013510465621948, accuracy: 44.92%
Epoch 7: train loss 0.010177419520914555, accuracy: 98.73%
Epoch 7: train loss 0.010227588936686516, accuracy: 98.55%
Epoch 6: train loss 0.02644813247025013, accuracy: 46.74%
Epoch 5: train loss 0.00997310783714056, accuracy: 99.41%
Epoch 2: train loss 0.014545540325343609, accuracy: 84.77%
Epoch 8: train loss 0.01017356850206852, accuracy: 98.74%
Epoch 5: train loss 0.009792801924049854, accuracy: 99.99%
Epoch 3: train loss 0.010746104642748833, accuracy: 96.92%
Epoch 8: train loss 0.010225697420537472, accuracy: 98.54%
Epoch 9: train loss 0.010171111673116684, accuracy: 98.76%
Epoch 7: train loss 0.02406049147248268, accuracy: 54.35%
Epoch 9: train loss 0.010222173295915127, accuracy: 98.55%
Epoch 6: train loss 0.009972658008337021, accuracy: 99.41%
Epoch 6: train loss 0.009792787954211235, accuracy: 99.99%
Epoch 8: train loss 0.019999470561742783, accuracy: 67.38%
Epoch 4: train loss 0.010738314129412174, accuracy: 97.0%
Epoch 7: train loss 0.009972602128982544, accuracy: 99.42%
Epoch 7: train loss 0.009792787954211235, accuracy: 99.99%
Epoch 9: train loss 0.019486157223582268, accuracy: 68.98%
Epoch 3: train loss 0.014324682764708996, accuracy: 85.53%
Epoch 8: train loss 0.009972846135497093, accuracy: 99.41%
Epoch 8: train loss 0.009792787954211235, accuracy: 99.99%
Epoch 5: train loss 0.010730523616075516, accuracy: 96.99%
Epoch 9: train loss 0.009972147643566132, accuracy: 99.41%
Epoch 9: train loss 0.009792787954211235, accuracy: 99.99%
Epoch 4: train loss 0.014306850731372833, accuracy: 85.57%
Epoch 6: train loss 0.010729278437793255, accuracy: 97.0%
Epoch 7: train loss 0.010731165297329426, accuracy: 96.99%
Epoch 5: train loss 0.014285564422607422, accuracy: 85.62%
Epoch 8: train loss 0.0107292914763093, accuracy: 96.99%
Epoch 9: train loss 0.010674161836504936, accuracy: 97.15%
Epoch 6: train loss 0.014282628893852234, accuracy: 85.63%
Epoch 7: train loss 0.01427752897143364, accuracy: 85.64%
Epoch 8: train loss 0.01426056120544672, accuracy: 85.69%
Epoch 9: train loss 0.014270655810832977, accuracy: 85.7%
Epoch 10: train loss 0.019336991012096405, accuracy: 69.47%
Epoch 10: train loss 0.009792787954211235, accuracy: 99.99%
Epoch 10: train loss 0.010169005952775478, accuracy: 98.79%
Epoch 10: train loss 0.010649634525179863, accuracy: 97.25%
Epoch 10: train loss 0.009970024228096008, accuracy: 99.41%
Epoch 10: train loss 0.01022037398070097, accuracy: 98.57%
Epoch 10: train loss 0.014280019327998161, accuracy: 85.65%
Acurácia do Cliente: 2 eh: 0.635792755987354
Acurácia do Cliente: 3 eh: 0.9901597311250476
Acurácia do Cliente: 7 eh: 0.444031007751938
Acurácia do Cliente: 1 eh: 0.9659124038483102
Acurácia do Cliente: 6 eh: 0.9505339195979899
Acurácia do Cliente: 5 eh: 0.44440953677522954
Acurácia do Cliente: 4 eh: 0.9786347361624699
