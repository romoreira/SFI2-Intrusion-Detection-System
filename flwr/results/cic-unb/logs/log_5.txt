INFO flwr 2023-11-03 18:17:15,094 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-03 18:17:15,102 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-03 18:17:15,102 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-03 18:17:15,102 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-03 18:17:28,193 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-03 18:17:28,194 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:16,  2.06it/s] 11%|█         | 150/1394 [00:00<00:03, 339.81it/s] 22%|██▏       | 301/1394 [00:00<00:01, 625.39it/s] 32%|███▏      | 449/1394 [00:00<00:01, 845.33it/s] 43%|████▎     | 602/1394 [00:00<00:00, 1029.12it/s] 53%|█████▎    | 740/1394 [00:01<00:00, 1036.01it/s] 62%|██████▏   | 867/1394 [00:01<00:00, 1045.28it/s] 72%|███████▏  | 1006/1394 [00:01<00:00, 1136.49it/s] 82%|████████▏ | 1142/1394 [00:01<00:00, 1196.86it/s] 91%|█████████ | 1271/1394 [00:01<00:00, 1200.94it/s]100%|██████████| 1394/1394 [00:01<00:00, 915.98it/s] 
INFO flwr 2023-11-03 18:17:37,488 | server.py:94 | initial parameters (loss, other metrics): 582.9152124524117, {'accuracy': 0.9580408602632818}
INFO flwr 2023-11-03 18:17:37,488 | server.py:104 | FL starting
DEBUG flwr 2023-11-03 18:17:37,488 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 18:27:12,053 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 18:27:12,061 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 582.9152124524117 / accuracy 0.9580408602632818
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 164/1394 [00:00<00:00, 1632.25it/s] 24%|██▎       | 330/1394 [00:00<00:00, 1646.62it/s] 36%|███▌      | 495/1394 [00:00<00:00, 1645.82it/s] 47%|████▋     | 661/1394 [00:00<00:00, 1648.37it/s] 59%|█████▉    | 828/1394 [00:00<00:00, 1653.67it/s] 71%|███████▏  | 994/1394 [00:00<00:00, 1649.37it/s] 83%|████████▎ | 1159/1394 [00:00<00:00, 1644.02it/s] 95%|█████████▌| 1325/1394 [00:00<00:00, 1647.44it/s]100%|██████████| 1394/1394 [00:00<00:00, 1647.46it/s]
INFO flwr 2023-11-03 18:27:16,785 | server.py:125 | fit progress: (1, 480.10406774282455, {'accuracy': 0.9688053643111839}, 579.2968739139906)
DEBUG flwr 2023-11-03 18:27:16,785 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 18:27:19,220 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 18:27:19,220 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-03 18:27:19,220 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 18:36:54,438 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 480.10406774282455 / accuracy 0.9688053643111839
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 164/1394 [00:00<00:00, 1634.18it/s] 24%|██▎       | 329/1394 [00:00<00:00, 1639.94it/s] 35%|███▌      | 494/1394 [00:00<00:00, 1643.21it/s] 47%|████▋     | 659/1394 [00:00<00:00, 1637.09it/s] 59%|█████▉    | 824/1394 [00:00<00:00, 1639.53it/s] 71%|███████   | 988/1394 [00:00<00:00, 1637.48it/s] 83%|████████▎ | 1152/1394 [00:00<00:00, 1638.07it/s] 95%|█████████▍| 1318/1394 [00:00<00:00, 1643.14it/s]100%|██████████| 1394/1394 [00:00<00:00, 1639.20it/s]
INFO flwr 2023-11-03 18:36:59,138 | server.py:125 | fit progress: (2, 476.67975303530693, {'accuracy': 0.9710031172209639}, 1161.6498026640038)
DEBUG flwr 2023-11-03 18:36:59,138 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 18:37:01,713 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-03 18:37:01,713 | server.py:153 | FL finished in 1164.2246717750095
INFO flwr 2023-11-03 18:37:01,713 | app.py:225 | app_fit: losses_distributed [(1, 716.0620434516012), (2, 723.6590367771618)]
INFO flwr 2023-11-03 18:37:01,713 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-03 18:37:01,713 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-03 18:37:01,713 | app.py:228 | app_fit: losses_centralized [(0, 582.9152124524117), (1, 480.10406774282455), (2, 476.67975303530693)]
INFO flwr 2023-11-03 18:37:01,713 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.9580408602632818), (1, 0.9688053643111839), (2, 0.9710031172209639)]}
Server-side evaluation loss 476.67975303530693 / accuracy 0.9710031172209639
.011124185286462307, accuracy: 95.74%
Epoch 6: train loss 0.010293266735970974, accuracy: 98.39%
Epoch 7: train loss 0.01029351819306612, accuracy: 98.4%
Epoch 5: train loss 0.011074506677687168, accuracy: 95.9%
Epoch 8: train loss 0.010292633436620235, accuracy: 98.39%
Epoch 9: train loss 0.0102928401902318, accuracy: 98.4%
Epoch 6: train loss 0.011012050323188305, accuracy: 96.09%
Epoch 7: train loss 0.01104065403342247, accuracy: 96.01%
Epoch 8: train loss 0.010930950753390789, accuracy: 96.35%
Epoch 9: train loss 0.010909081436693668, accuracy: 96.43%
Epoch 10: train loss 0.011497555300593376, accuracy: 94.54%
Epoch 10: train loss 0.010292819701135159, accuracy: 98.39%
Epoch 10: train loss 0.010190698318183422, accuracy: 98.72%
Epoch 10: train loss 0.009792787954211235, accuracy: 99.99%
Epoch 10: train loss 0.010120774619281292, accuracy: 98.97%
Epoch 10: train loss 0.00995284877717495, accuracy: 99.48%
Epoch 10: train loss 0.010914196260273457, accuracy: 96.42%
Acurácia do Cliente: 1 eh: 0.9688726424614833
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.6692699686737595
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.6276049848151639
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.4291915836101883
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9928969890163196
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9861477959734695
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.9500104690117253
Starting Client training for 10 epochs
Epoch 1: train loss 0.011046113446354866, accuracy: 96.02%
Epoch 1: train loss 0.010773861780762672, accuracy: 96.69%
Epoch 1: train loss 0.019760556519031525, accuracy: 67.85%
Epoch 1: train loss 0.010671493597328663, accuracy: 97.16%
Epoch 1: train loss 0.009847547858953476, accuracy: 99.82%
Epoch 2: train loss 0.010516001842916012, accuracy: 97.73%
Epoch 2: train loss 0.010257977992296219, accuracy: 98.51%
Epoch 1: train loss 0.011010709218680859, accuracy: 96.1%
Epoch 2: train loss 0.013629072345793247, accuracy: 87.67%
Epoch 3: train loss 0.010363220237195492, accuracy: 98.16%
Epoch 3: train loss 0.010215191170573235, accuracy: 98.66%
Epoch 2: train loss 0.009793932549655437, accuracy: 99.98%
Epoch 2: train loss 0.01009425800293684, accuracy: 99.03%
Epoch 4: train loss 0.010350937955081463, accuracy: 98.19%
Epoch 1: train loss 0.011077960021793842, accuracy: 95.89%
Epoch 4: train loss 0.01019963901489973, accuracy: 98.72%
Epoch 3: train loss 0.012045495212078094, accuracy: 92.83%
Epoch 3: train loss 0.009793467819690704, accuracy: 99.98%
Epoch 5: train loss 0.010353107936680317, accuracy: 98.17%
Epoch 3: train loss 0.010055472142994404, accuracy: 99.17%
Epoch 5: train loss 0.010189492255449295, accuracy: 98.73%
Epoch 2: train loss 0.010728486813604832, accuracy: 97.0%
Epoch 4: train loss 0.01179575640708208, accuracy: 93.58%
Epoch 6: train loss 0.010359602980315685, accuracy: 98.19%
Epoch 6: train loss 0.01017835270613432, accuracy: 98.77%
Epoch 4: train loss 0.0100397989153862, accuracy: 99.21%
Epoch 4: train loss 0.009793121367692947, accuracy: 99.99%
Epoch 7: train loss 0.010354992002248764, accuracy: 98.23%
Epoch 5: train loss 0.011691473424434662, accuracy: 93.92%
Epoch 7: train loss 0.0101698637008667, accuracy: 98.8%
Epoch 8: train loss 0.010351434350013733, accuracy: 98.2%
Epoch 5: train loss 0.010038877837359905, accuracy: 99.21%
Epoch 2: train loss 0.010966351255774498, accuracy: 96.23%
Epoch 5: train loss 0.009793747216463089, accuracy: 99.98%
Epoch 3: train loss 0.010657114908099174, accuracy: 97.25%
Epoch 6: train loss 0.011669538915157318, accuracy: 94.0%
Epoch 8: train loss 0.010152658447623253, accuracy: 98.86%
Epoch 9: train loss 0.010326344519853592, accuracy: 98.27%
Epoch 9: train loss 0.010145701467990875, accuracy: 98.87%
Epoch 6: train loss 0.01003656629472971, accuracy: 99.22%
Epoch 7: train loss 0.01164979673922062, accuracy: 94.07%
Epoch 6: train loss 0.009793010540306568, accuracy: 99.98%
Epoch 4: train loss 0.010632462799549103, accuracy: 97.3%
Epoch 8: train loss 0.011636316776275635, accuracy: 94.1%
Epoch 7: train loss 0.010033885017037392, accuracy: 99.22%
Epoch 7: train loss 0.009792998433113098, accuracy: 99.99%
Epoch 3: train loss 0.010947666130959988, accuracy: 96.32%
Epoch 9: train loss 0.01162696722894907, accuracy: 94.11%
Epoch 8: train loss 0.010030183009803295, accuracy: 99.23%
Epoch 8: train loss 0.009793207049369812, accuracy: 99.99%
Epoch 5: train loss 0.010646468959748745, accuracy: 97.25%
Epoch 9: train loss 0.010030011646449566, accuracy: 99.23%
Epoch 9: train loss 0.009793802164494991, accuracy: 99.99%
Epoch 6: train loss 0.010663281194865704, accuracy: 97.25%
Epoch 4: train loss 0.010939976200461388, accuracy: 96.33%
Epoch 7: train loss 0.010659649036824703, accuracy: 97.22%
Epoch 5: train loss 0.010940538719296455, accuracy: 96.32%
Epoch 8: train loss 0.010660757310688496, accuracy: 97.23%
Epoch 9: train loss 0.01065765880048275, accuracy: 97.22%
Epoch 6: train loss 0.010936464183032513, accuracy: 96.34%
Epoch 7: train loss 0.010934283025562763, accuracy: 96.34%
Epoch 8: train loss 0.01093059591948986, accuracy: 96.37%
Epoch 9: train loss 0.010912260040640831, accuracy: 96.4%
Epoch 10: train loss 0.010915194638073444, accuracy: 96.41%
Epoch 10: train loss 0.009793197736144066, accuracy: 99.99%
Epoch 10: train loss 0.010656231082975864, accuracy: 97.22%
Epoch 10: train loss 0.011620825156569481, accuracy: 94.13%
Epoch 10: train loss 0.010023054666817188, accuracy: 99.24%
Epoch 10: train loss 0.010144735686480999, accuracy: 98.87%
Epoch 10: train loss 0.010354056023061275, accuracy: 98.22%
Acurácia do Cliente: 5 eh: 0.620414004956889
Acurácia do Cliente: 3 eh: 0.9981982606285299
Acurácia do Cliente: 7 eh: 0.4279955703211517
Acurácia do Cliente: 1 eh: 0.9703976138682694
Acurácia do Cliente: 2 eh: 0.6590781134962683
Acurácia do Cliente: 4 eh: 0.9860891001936961
Acurácia do Cliente: 6 eh: 0.9674413735343383
