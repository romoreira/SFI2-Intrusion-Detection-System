INFO flwr 2023-11-06 02:06:27,472 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-06 02:06:27,483 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-06 02:06:27,483 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-06 02:06:27,483 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-06 02:06:40,488 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-06 02:06:40,488 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<12:19,  1.88it/s]  9%|▉         | 125/1394 [00:00<00:04, 264.46it/s] 15%|█▌        | 211/1394 [00:00<00:02, 402.19it/s] 21%|██▏       | 299/1394 [00:00<00:02, 520.00it/s] 30%|███       | 422/1394 [00:00<00:01, 704.81it/s] 39%|███▉      | 544/1394 [00:01<00:01, 843.53it/s] 48%|████▊     | 673/1394 [00:01<00:00, 967.36it/s] 60%|██████    | 837/1394 [00:01<00:00, 1158.87it/s] 72%|███████▏  | 1008/1394 [00:01<00:00, 1317.53it/s] 85%|████████▍ | 1179/1394 [00:01<00:00, 1430.40it/s] 97%|█████████▋| 1350/1394 [00:01<00:00, 1510.60it/s]100%|██████████| 1394/1394 [00:01<00:00, 892.60it/s] 
INFO flwr 2023-11-06 02:06:50,403 | server.py:94 | initial parameters (loss, other metrics): 1322.619165122509, {'accuracy': 0.21766724226861922}
INFO flwr 2023-11-06 02:06:50,403 | server.py:104 | FL starting
DEBUG flwr 2023-11-06 02:06:50,403 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:16:19,943 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 02:16:19,951 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1322.619165122509 / accuracy 0.21766724226861922
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 168/1394 [00:00<00:00, 1673.74it/s] 24%|██▍       | 337/1394 [00:00<00:00, 1679.13it/s] 36%|███▋      | 507/1394 [00:00<00:00, 1686.29it/s] 48%|████▊     | 676/1394 [00:00<00:00, 1682.94it/s] 61%|██████    | 845/1394 [00:00<00:00, 1683.66it/s] 73%|███████▎  | 1014/1394 [00:00<00:00, 1679.68it/s] 85%|████████▍ | 1182/1394 [00:00<00:00, 1676.48it/s] 97%|█████████▋| 1350/1394 [00:00<00:00, 1676.89it/s]100%|██████████| 1394/1394 [00:00<00:00, 1678.65it/s]
INFO flwr 2023-11-06 02:16:24,851 | server.py:125 | fit progress: (1, 696.0067523121834, {'accuracy': 0.8134825413199973}, 574.447496925015)
DEBUG flwr 2023-11-06 02:16:24,851 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:16:27,378 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 02:16:27,378 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-06 02:16:27,378 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:25:56,424 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 696.0067523121834 / accuracy 0.8134825413199973
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 167/1394 [00:00<00:00, 1661.05it/s] 24%|██▍       | 334/1394 [00:00<00:00, 1665.46it/s] 36%|███▌      | 502/1394 [00:00<00:00, 1671.97it/s] 48%|████▊     | 670/1394 [00:00<00:00, 1673.56it/s] 60%|██████    | 839/1394 [00:00<00:00, 1676.94it/s] 72%|███████▏  | 1007/1394 [00:00<00:00, 1672.69it/s] 84%|████████▍ | 1175/1394 [00:00<00:00, 1674.11it/s] 96%|█████████▋| 1343/1394 [00:00<00:00, 1672.80it/s]100%|██████████| 1394/1394 [00:00<00:00, 1672.74it/s]
INFO flwr 2023-11-06 02:26:01,196 | server.py:125 | fit progress: (2, 687.921392261982, {'accuracy': 0.81978426139804}, 1150.7931673440035)
DEBUG flwr 2023-11-06 02:26:01,196 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:26:03,714 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-06 02:26:03,714 | server.py:153 | FL finished in 1153.3110788299819
INFO flwr 2023-11-06 02:26:03,714 | app.py:225 | app_fit: losses_distributed [(1, 707.893875627279), (2, 718.9983269599858)]
INFO flwr 2023-11-06 02:26:03,714 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-06 02:26:03,714 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-06 02:26:03,715 | app.py:228 | app_fit: losses_centralized [(0, 1322.619165122509), (1, 696.0067523121834), (2, 687.921392261982)]
INFO flwr 2023-11-06 02:26:03,715 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.21766724226861922), (1, 0.8134825413199973), (2, 0.81978426139804)]}
Server-side evaluation loss 687.921392261982 / accuracy 0.81978426139804
4: train loss 0.011725731194019318, accuracy: 93.8%
Epoch 6: train loss 0.010297619737684727, accuracy: 98.38%
Epoch 7: train loss 0.010295230895280838, accuracy: 98.38%
Epoch 5: train loss 0.011699086986482143, accuracy: 93.89%
Epoch 8: train loss 0.010294746607542038, accuracy: 98.4%
Epoch 6: train loss 0.011686798185110092, accuracy: 93.93%
Epoch 9: train loss 0.010291781276464462, accuracy: 98.4%
Epoch 7: train loss 0.011669512838125229, accuracy: 93.99%
Epoch 8: train loss 0.011652922257781029, accuracy: 94.05%
Epoch 9: train loss 0.011747724376618862, accuracy: 93.77%
Epoch 10: train loss 0.011693896725773811, accuracy: 93.92%
Epoch 10: train loss 0.010777009651064873, accuracy: 96.82%
Epoch 10: train loss 0.00979280099272728, accuracy: 99.99%
Epoch 10: train loss 0.010289197787642479, accuracy: 98.4%
Epoch 10: train loss 0.009960362687706947, accuracy: 99.45%
Epoch 10: train loss 0.009859205223619938, accuracy: 99.78%
Epoch 10: train loss 0.01012451108545065, accuracy: 98.96%
Acurácia do Cliente: 2 eh: 0.7882952462069264
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.804836532253331
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.5518902502879883
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.8151196429772825
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.6727796234772979
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.7429857621440537
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.8338934894840788
Starting Client training for 10 epochs
Epoch 1: train loss 0.015939759090542793, accuracy: 80.15%
Epoch 1: train loss 0.01567629911005497, accuracy: 81.08%
Epoch 1: train loss 0.017757445573806763, accuracy: 74.46%
Epoch 1: train loss 0.0109567791223526, accuracy: 96.21%
Epoch 1: train loss 0.011191785335540771, accuracy: 95.52%
Epoch 2: train loss 0.010840357281267643, accuracy: 96.68%
Epoch 2: train loss 0.015357156284153461, accuracy: 82.2%
Epoch 2: train loss 0.013119935989379883, accuracy: 89.27%
Epoch 1: train loss 0.015204417519271374, accuracy: 82.64%
Epoch 3: train loss 0.010418364778161049, accuracy: 97.95%
Epoch 3: train loss 0.014972391538321972, accuracy: 83.39%
Epoch 2: train loss 0.00980534590780735, accuracy: 99.95%
Epoch 2: train loss 0.010244379751384258, accuracy: 98.57%
Epoch 1: train loss 0.011766989715397358, accuracy: 93.68%
Epoch 4: train loss 0.010336282663047314, accuracy: 98.24%
Epoch 3: train loss 0.011996551416814327, accuracy: 92.93%
Epoch 4: train loss 0.014351993799209595, accuracy: 85.43%
Epoch 3: train loss 0.009793000295758247, accuracy: 99.99%
Epoch 3: train loss 0.010231368243694305, accuracy: 98.56%
Epoch 5: train loss 0.010283992625772953, accuracy: 98.4%
Epoch 5: train loss 0.012338976375758648, accuracy: 91.67%
Epoch 4: train loss 0.011868824250996113, accuracy: 93.33%
Epoch 2: train loss 0.014861322939395905, accuracy: 83.78%
Epoch 6: train loss 0.010193142108619213, accuracy: 98.68%
Epoch 6: train loss 0.01125951949506998, accuracy: 95.31%
Epoch 4: train loss 0.01018550805747509, accuracy: 98.75%
Epoch 4: train loss 0.00979282334446907, accuracy: 99.99%
Epoch 5: train loss 0.011803479865193367, accuracy: 93.58%
Epoch 7: train loss 0.010171972215175629, accuracy: 98.75%
Epoch 7: train loss 0.011230994947254658, accuracy: 95.38%
Epoch 2: train loss 0.011620220728218555, accuracy: 94.18%
Epoch 6: train loss 0.01173910778015852, accuracy: 93.73%
Epoch 8: train loss 0.010177204385399818, accuracy: 98.75%
Epoch 5: train loss 0.00979280099272728, accuracy: 99.99%
Epoch 5: train loss 0.010188871994614601, accuracy: 98.73%
Epoch 3: train loss 0.013792694546282291, accuracy: 87.21%
Epoch 8: train loss 0.01123959943652153, accuracy: 95.42%
Epoch 9: train loss 0.010168871842324734, accuracy: 98.77%
Epoch 7: train loss 0.011719043366611004, accuracy: 93.82%
Epoch 9: train loss 0.011234253644943237, accuracy: 95.42%
Epoch 6: train loss 0.010156145319342613, accuracy: 98.83%
Epoch 6: train loss 0.009792796336114407, accuracy: 99.99%
Epoch 8: train loss 0.011704221367835999, accuracy: 93.87%
Epoch 4: train loss 0.011733545921742916, accuracy: 93.81%
Epoch 7: train loss 0.010182279162108898, accuracy: 98.72%
Epoch 7: train loss 0.009792790748178959, accuracy: 99.99%
Epoch 3: train loss 0.011652299202978611, accuracy: 94.06%
Epoch 9: train loss 0.011696385219693184, accuracy: 93.9%
Epoch 8: train loss 0.010107901878654957, accuracy: 98.97%
Epoch 8: train loss 0.009792789816856384, accuracy: 99.99%
Epoch 5: train loss 0.011323373764753342, accuracy: 95.1%
Epoch 9: train loss 0.01005954947322607, accuracy: 99.14%
Epoch 9: train loss 0.009792790748178959, accuracy: 99.99%
Epoch 4: train loss 0.011575116775929928, accuracy: 94.29%
Epoch 6: train loss 0.011304877698421478, accuracy: 95.18%
Epoch 7: train loss 0.011283117346465588, accuracy: 95.23%
Epoch 5: train loss 0.011615418829023838, accuracy: 94.15%
Epoch 8: train loss 0.011287330649793148, accuracy: 95.2%
Epoch 6: train loss 0.011604911647737026, accuracy: 94.21%
Epoch 9: train loss 0.011275101453065872, accuracy: 95.26%
Epoch 7: train loss 0.011599453166127205, accuracy: 94.22%
Epoch 8: train loss 0.011595578864216805, accuracy: 94.22%
Epoch 9: train loss 0.011585627682507038, accuracy: 94.28%
Epoch 10: train loss 0.011639024131000042, accuracy: 94.08%
Epoch 10: train loss 0.011213301680982113, accuracy: 95.41%
Epoch 10: train loss 0.011700686067342758, accuracy: 93.91%
Epoch 10: train loss 0.009792789816856384, accuracy: 99.99%
Epoch 10: train loss 0.011244876310229301, accuracy: 95.39%
Epoch 10: train loss 0.010159838944673538, accuracy: 98.79%
Epoch 10: train loss 0.010076780803501606, accuracy: 99.09%
Acurácia do Cliente: 2 eh: 0.7549623940754429
Acurácia do Cliente: 5 eh: 0.5651900722588753
Acurácia do Cliente: 6 eh: 0.772927135678392
Acurácia do Cliente: 7 eh: 0.7407308970099667
Acurácia do Cliente: 1 eh: 0.8165773362337692
Acurácia do Cliente: 3 eh: 0.8567270711340563
Acurácia do Cliente: 4 eh: 0.8149909021541352
