INFO flwr 2023-11-06 01:24:39,697 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-06 01:24:39,706 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-06 01:24:39,706 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-06 01:24:39,706 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-06 01:24:53,066 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-06 01:24:53,067 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<12:24,  1.87it/s]  7%|▋         | 97/1394 [00:00<00:06, 203.82it/s] 15%|█▌        | 211/1394 [00:00<00:02, 419.92it/s] 26%|██▌       | 362/1394 [00:00<00:01, 689.71it/s] 34%|███▍      | 472/1394 [00:00<00:01, 764.30it/s] 44%|████▍     | 614/1394 [00:01<00:00, 935.90it/s] 56%|█████▌    | 781/1394 [00:01<00:00, 1134.95it/s] 68%|██████▊   | 948/1394 [00:01<00:00, 1283.04it/s] 80%|███████▉  | 1114/1394 [00:01<00:00, 1390.60it/s] 92%|█████████▏| 1281/1394 [00:01<00:00, 1469.53it/s]100%|██████████| 1394/1394 [00:01<00:00, 915.71it/s] 
INFO flwr 2023-11-06 01:25:02,154 | server.py:94 | initial parameters (loss, other metrics): 1072.850140929222, {'accuracy': 0.45506940862505885}
INFO flwr 2023-11-06 01:25:02,154 | server.py:104 | FL starting
DEBUG flwr 2023-11-06 01:25:02,154 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 01:34:34,871 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 01:34:34,879 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1072.850140929222 / accuracy 0.45506940862505885
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 165/1394 [00:00<00:00, 1649.54it/s] 24%|██▍       | 332/1394 [00:00<00:00, 1656.78it/s] 36%|███▌      | 499/1394 [00:00<00:00, 1659.60it/s] 48%|████▊     | 666/1394 [00:00<00:00, 1661.81it/s] 60%|█████▉    | 833/1394 [00:00<00:00, 1662.75it/s] 72%|███████▏  | 1000/1394 [00:00<00:00, 1661.71it/s] 84%|████████▎ | 1167/1394 [00:00<00:00, 1663.14it/s] 96%|█████████▌| 1334/1394 [00:00<00:00, 1661.57it/s]100%|██████████| 1394/1394 [00:00<00:00, 1661.02it/s]
INFO flwr 2023-11-06 01:34:39,688 | server.py:125 | fit progress: (1, 489.7174682319164, {'accuracy': 0.9619429929806463}, 577.5342342989752)
DEBUG flwr 2023-11-06 01:34:39,689 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 01:34:42,157 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 01:34:42,157 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-06 01:34:42,157 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 01:44:13,334 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 489.7174682319164 / accuracy 0.9619429929806463
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 166/1394 [00:00<00:00, 1659.72it/s] 24%|██▍       | 333/1394 [00:00<00:00, 1661.18it/s] 36%|███▌      | 500/1394 [00:00<00:00, 1656.41it/s] 48%|████▊     | 667/1394 [00:00<00:00, 1659.82it/s] 60%|█████▉    | 833/1394 [00:00<00:00, 1653.62it/s] 72%|███████▏  | 1000/1394 [00:00<00:00, 1658.78it/s] 84%|████████▎ | 1167/1394 [00:00<00:00, 1659.44it/s] 96%|█████████▌| 1334/1394 [00:00<00:00, 1661.56it/s]100%|██████████| 1394/1394 [00:00<00:00, 1659.70it/s]
INFO flwr 2023-11-06 01:44:18,408 | server.py:125 | fit progress: (2, 485.8515691459179, {'accuracy': 0.9646341189926219}, 1156.2536545149633)
DEBUG flwr 2023-11-06 01:44:18,408 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 01:44:20,877 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-06 01:44:20,877 | server.py:153 | FL finished in 1158.722944352019
INFO flwr 2023-11-06 01:44:20,877 | app.py:225 | app_fit: losses_distributed [(1, 692.3130170037389), (2, 642.2393470539276)]
INFO flwr 2023-11-06 01:44:20,877 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-06 01:44:20,877 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-06 01:44:20,877 | app.py:228 | app_fit: losses_centralized [(0, 1072.850140929222), (1, 489.7174682319164), (2, 485.8515691459179)]
INFO flwr 2023-11-06 01:44:20,877 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.45506940862505885), (1, 0.9619429929806463), (2, 0.9646341189926219)]}
Server-side evaluation loss 485.8515691459179 / accuracy 0.9646341189926219
oss 0.01106047723442316, accuracy: 95.95%
Epoch 6: train loss 0.010296568274497986, accuracy: 98.39%
Epoch 7: train loss 0.01029475498944521, accuracy: 98.39%
Epoch 5: train loss 0.01106327585875988, accuracy: 95.94%
Epoch 8: train loss 0.010293570347130299, accuracy: 98.39%
Epoch 6: train loss 0.01097611803561449, accuracy: 96.2%
Epoch 9: train loss 0.010291633196175098, accuracy: 98.39%
Epoch 7: train loss 0.011055463925004005, accuracy: 95.97%
Epoch 8: train loss 0.011072936467826366, accuracy: 95.89%
Epoch 9: train loss 0.010967590846121311, accuracy: 96.22%
Epoch 10: train loss 0.010952068492770195, accuracy: 96.31%
Epoch 10: train loss 0.010124240070581436, accuracy: 98.96%
Epoch 10: train loss 0.010013981722295284, accuracy: 99.34%
Epoch 10: train loss 0.010293079540133476, accuracy: 98.39%
Epoch 10: train loss 0.00995326042175293, accuracy: 99.47%
Epoch 10: train loss 0.011503592133522034, accuracy: 94.53%
Epoch 10: train loss 0.009793047793209553, accuracy: 99.99%
Acurácia do Cliente: 6 eh: 0.9200167504187605
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.6903211517165005
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.9619205669305465
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9701825438750954
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9730085582620145
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.6900867606935082
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.6185988061577129
Starting Client training for 10 epochs
Epoch 1: train loss 0.010544683784246445, accuracy: 97.57%
Epoch 1: train loss 0.011791052296757698, accuracy: 93.46%
Epoch 1: train loss 0.019559156149625778, accuracy: 68.73%
Epoch 1: train loss 0.011672001332044601, accuracy: 93.96%
Epoch 1: train loss 0.009865161031484604, accuracy: 99.77%
Epoch 2: train loss 0.010351927950978279, accuracy: 98.22%
Epoch 2: train loss 0.010516381822526455, accuracy: 97.58%
Epoch 2: train loss 0.019498208537697792, accuracy: 68.93%
Epoch 1: train loss 0.01076603215187788, accuracy: 96.86%
Epoch 3: train loss 0.01029966864734888, accuracy: 98.39%
Epoch 3: train loss 0.010201429016888142, accuracy: 98.69%
Epoch 2: train loss 0.009795824997127056, accuracy: 99.97%
Epoch 2: train loss 0.010084511712193489, accuracy: 99.03%
Epoch 1: train loss 0.01132476981729269, accuracy: 95.11%
Epoch 4: train loss 0.010275192558765411, accuracy: 98.44%
Epoch 3: train loss 0.019304389134049416, accuracy: 69.49%
Epoch 4: train loss 0.010166700929403305, accuracy: 98.79%
Epoch 3: train loss 0.009794767014682293, accuracy: 99.98%
Epoch 5: train loss 0.010265164077281952, accuracy: 98.52%
Epoch 3: train loss 0.01002404373139143, accuracy: 99.25%
Epoch 5: train loss 0.010164295323193073, accuracy: 98.8%
Epoch 2: train loss 0.010594166815280914, accuracy: 97.44%
Epoch 4: train loss 0.014660459943115711, accuracy: 84.28%
Epoch 6: train loss 0.01025448925793171, accuracy: 98.52%
Epoch 6: train loss 0.010157118551433086, accuracy: 98.85%
Epoch 4: train loss 0.009794419631361961, accuracy: 99.98%
Epoch 4: train loss 0.010012012906372547, accuracy: 99.28%
Epoch 5: train loss 0.012477765791118145, accuracy: 91.42%
Epoch 7: train loss 0.01025113184005022, accuracy: 98.53%
Epoch 7: train loss 0.010147067718207836, accuracy: 98.85%
Epoch 2: train loss 0.011109656654298306, accuracy: 95.78%
Epoch 3: train loss 0.010509395971894264, accuracy: 97.69%
Epoch 8: train loss 0.010251540690660477, accuracy: 98.53%
Epoch 8: train loss 0.01015100535005331, accuracy: 98.85%
Epoch 6: train loss 0.011957318522036076, accuracy: 93.09%
Epoch 5: train loss 0.009793544188141823, accuracy: 99.98%
Epoch 5: train loss 0.009994607418775558, accuracy: 99.35%
Epoch 9: train loss 0.010234486311674118, accuracy: 98.57%
Epoch 9: train loss 0.010140850208699703, accuracy: 98.87%
Epoch 7: train loss 0.011775038205087185, accuracy: 93.65%
Epoch 6: train loss 0.009998750872910023, accuracy: 99.33%
Epoch 6: train loss 0.009793453849852085, accuracy: 99.98%
Epoch 4: train loss 0.010499279014766216, accuracy: 97.74%
Epoch 8: train loss 0.011662473902106285, accuracy: 94.01%
Epoch 3: train loss 0.01109375525265932, accuracy: 95.84%
Epoch 7: train loss 0.010004309006035328, accuracy: 99.3%
Epoch 7: train loss 0.00979322474449873, accuracy: 99.98%
Epoch 9: train loss 0.011650183238089085, accuracy: 94.04%
Epoch 8: train loss 0.009989777579903603, accuracy: 99.36%
Epoch 8: train loss 0.009793436154723167, accuracy: 99.99%
Epoch 5: train loss 0.010485182516276836, accuracy: 97.77%
Epoch 9: train loss 0.009990445338189602, accuracy: 99.37%
Epoch 9: train loss 0.009792864322662354, accuracy: 99.99%
Epoch 4: train loss 0.011191128753125668, accuracy: 95.51%
Epoch 6: train loss 0.010477383621037006, accuracy: 97.81%
Epoch 7: train loss 0.010471941903233528, accuracy: 97.8%
Epoch 5: train loss 0.011135526932775974, accuracy: 95.71%
Epoch 8: train loss 0.010467935353517532, accuracy: 97.83%
Epoch 6: train loss 0.011060737073421478, accuracy: 95.93%
Epoch 9: train loss 0.010459622368216515, accuracy: 97.86%
Epoch 7: train loss 0.011074027977883816, accuracy: 95.91%
Epoch 8: train loss 0.011041989549994469, accuracy: 96.01%
Epoch 9: train loss 0.010980455204844475, accuracy: 96.21%
Epoch 10: train loss 0.011089885607361794, accuracy: 95.86%
Epoch 10: train loss 0.010228380560874939, accuracy: 98.61%
Epoch 10: train loss 0.010459475219249725, accuracy: 97.85%
Epoch 10: train loss 0.00979275070130825, accuracy: 99.99%
Epoch 10: train loss 0.009991547092795372, accuracy: 99.36%
Epoch 10: train loss 0.011637486517429352, accuracy: 94.11%
Epoch 10: train loss 0.010142953135073185, accuracy: 98.88%
Acurácia do Cliente: 4 eh: 0.9731760286435406
Acurácia do Cliente: 2 eh: 0.7710441598937506
Acurácia do Cliente: 6 eh: 0.9159861809045227
Acurácia do Cliente: 1 eh: 0.9637146509385301
Acurácia do Cliente: 3 eh: 0.9853088943557049
Acurácia do Cliente: 7 eh: 0.6916500553709856
Acurácia do Cliente: 5 eh: 0.5821202918281146
