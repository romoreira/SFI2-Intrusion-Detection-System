INFO flwr 2023-10-26 00:36:18,537 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=3, round_timeout=None)
INFO flwr 2023-10-26 00:36:18,747 | app.py:175 | Flower ECE: gRPC server running (3 rounds), SSL is disabled
INFO flwr 2023-10-26 00:36:18,747 | server.py:89 | Initializing global parameters
INFO flwr 2023-10-26 00:36:18,747 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-10-26 00:36:30,651 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-10-26 00:36:30,651 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1804 [00:00<?, ?it/s]  0%|          | 1/1804 [00:00<18:31,  1.62it/s]  6%|▋         | 114/1804 [00:00<00:07, 212.78it/s] 10%|▉         | 179/1804 [00:00<00:05, 300.40it/s] 13%|█▎        | 242/1804 [00:00<00:04, 358.94it/s] 18%|█▊        | 328/1804 [00:01<00:03, 472.69it/s] 22%|██▏       | 396/1804 [00:01<00:02, 509.87it/s] 26%|██▌       | 461/1804 [00:01<00:02, 495.92it/s] 30%|██▉       | 539/1804 [00:01<00:02, 566.87it/s] 35%|███▌      | 640/1804 [00:01<00:01, 683.26it/s] 40%|███▉      | 717/1804 [00:01<00:01, 625.99it/s] 45%|████▌     | 817/1804 [00:01<00:01, 721.67it/s] 52%|█████▏    | 947/1804 [00:01<00:00, 876.52it/s] 59%|█████▉    | 1061/1804 [00:01<00:00, 948.91it/s] 66%|██████▌   | 1185/1804 [00:02<00:00, 1031.38it/s] 72%|███████▏  | 1295/1804 [00:02<00:00, 1051.12it/s] 78%|███████▊  | 1404/1804 [00:02<00:00, 843.46it/s]  83%|████████▎ | 1497/1804 [00:02<00:00, 765.95it/s] 88%|████████▊ | 1581/1804 [00:02<00:00, 689.85it/s] 92%|█████████▏| 1656/1804 [00:02<00:00, 683.62it/s] 96%|█████████▌| 1729/1804 [00:02<00:00, 646.52it/s]100%|██████████| 1804/1804 [00:02<00:00, 607.60it/s]

### Server-side evaluation loss 923.827376127243 / accuracy 78.87% DatasetID 3 ###

  0%|          | 0/1065 [00:00<?, ?it/s] 16%|█▌        | 167/1065 [00:00<00:00, 1665.36it/s] 31%|███▏      | 334/1065 [00:00<00:00, 1660.44it/s] 47%|████▋     | 503/1065 [00:00<00:00, 1671.96it/s] 63%|██████▎   | 672/1065 [00:00<00:00, 1675.72it/s] 79%|███████▉  | 841/1065 [00:00<00:00, 1678.84it/s] 95%|█████████▍| 1009/1065 [00:00<00:00, 1678.91it/s]100%|██████████| 1065/1065 [00:00<00:00, 1673.05it/s]

### Server-side evaluation loss 502.48028498888016 / accuracy 74.54% DatasetID 4 ###

  0%|          | 0/1791 [00:00<?, ?it/s]  9%|▉         | 169/1791 [00:00<00:00, 1679.60it/s] 19%|█▉        | 337/1791 [00:00<00:00, 1677.86it/s] 28%|██▊       | 506/1791 [00:00<00:00, 1679.76it/s] 38%|███▊      | 674/1791 [00:00<00:00, 1675.03it/s] 47%|████▋     | 843/1791 [00:00<00:00, 1679.45it/s] 57%|█████▋    | 1012/1791 [00:00<00:00, 1681.88it/s] 66%|██████▌   | 1181/1791 [00:00<00:00, 1682.85it/s] 75%|███████▌  | 1350/1791 [00:00<00:00, 1681.66it/s] 85%|████████▍ | 1519/1791 [00:00<00:00, 1673.14it/s] 94%|█████████▍| 1688/1791 [00:01<00:00, 1677.20it/s]100%|██████████| 1791/1791 [00:01<00:00, 1679.10it/s]
INFO flwr 2023-10-26 00:36:42,529 | server.py:94 | initial parameters (loss, other metrics): 1041.3187742829323, {'accuracy': 78.08549292586689}
INFO flwr 2023-10-26 00:36:42,529 | server.py:104 | FL starting
DEBUG flwr 2023-10-26 00:36:42,529 | server.py:222 | fit_round 1: strategy sampled 4 clients (out of 4)
Starting Client training for 10 epochs
Starting Client training for 10 epochs
Starting Client training for 20 epochs
Starting Client training for 10 epochs
Epoch 1: train loss 0.0111400056630373, accuracy: 97.52%
Epoch 1: train loss 0.010144341737031937, accuracy: 99.84%
Epoch 1: train loss 0.010915592312812805, accuracy: 96.85%
Epoch 2: train loss 0.010158013552427292, accuracy: 99.04%
Epoch 2: train loss 0.009830026887357235, accuracy: 99.99%
Epoch 1: train loss 0.012021797709167004, accuracy: 93.36%
Epoch 3: train loss 0.01009313203394413, accuracy: 99.17%
Epoch 3: train loss 0.009815258905291557, accuracy: 99.99%
Epoch 2: train loss 0.010659167543053627, accuracy: 97.17%
Epoch 4: train loss 0.010066663846373558, accuracy: 99.2%
Epoch 4: train loss 0.009809182956814766, accuracy: 99.99%
Epoch 3: train loss 0.010574519634246826, accuracy: 97.56%
Epoch 5: train loss 0.010051851160824299, accuracy: 99.23%
Epoch 5: train loss 0.00980598945170641, accuracy: 99.99%
Epoch 2: train loss 0.011044681072235107, accuracy: 96.11%
Epoch 6: train loss 0.01004103384912014, accuracy: 99.25%
Epoch 6: train loss 0.009803792461752892, accuracy: 99.99%
Epoch 4: train loss 0.010544202290475368, accuracy: 97.56%
Epoch 7: train loss 0.010036476887762547, accuracy: 99.26%
Epoch 7: train loss 0.00980236753821373, accuracy: 99.99%
Epoch 3: train loss 0.010895437560975552, accuracy: 96.51%
Epoch 5: train loss 0.010521584190428257, accuracy: 97.54%
Epoch 8: train loss 0.010030808858573437, accuracy: 99.27%
Epoch 8: train loss 0.009801863692700863, accuracy: 99.98%
Epoch 9: train loss 0.010027418844401836, accuracy: 99.27%
Epoch 9: train loss 0.009800598956644535, accuracy: 99.99%
Epoch 6: train loss 0.010511448606848717, accuracy: 97.56%
Epoch 4: train loss 0.010866758413612843, accuracy: 96.59%
Epoch 7: train loss 0.010500100441277027, accuracy: 97.65%
Epoch 8: train loss 0.010489107109606266, accuracy: 97.7%
Epoch 5: train loss 0.010859183967113495, accuracy: 96.57%
Epoch 9: train loss 0.010482016019523144, accuracy: 97.8%
Epoch 6: train loss 0.010860014706850052, accuracy: 96.57%
Epoch 7: train loss 0.010857188142836094, accuracy: 96.61%
Epoch 8: train loss 0.010838440619409084, accuracy: 96.67%
Epoch 9: train loss 0.01083290670067072, accuracy: 96.67%
Epoch 10: train loss 0.010835913009941578, accuracy: 96.67%
Epoch 11: train loss 0.010844998992979527, accuracy: 96.62%
Epoch 12: train loss 0.010837004519999027, accuracy: 96.67%
Epoch 13: train loss 0.010829003527760506, accuracy: 96.66%
