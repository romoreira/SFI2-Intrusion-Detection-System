INFO flwr 2023-10-31 01:11:23,496 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=3, round_timeout=None)
INFO flwr 2023-10-31 01:11:23,599 | app.py:175 | Flower ECE: gRPC server running (3 rounds), SSL is disabled
INFO flwr 2023-10-31 01:11:23,600 | server.py:89 | Initializing global parameters
INFO flwr 2023-10-31 01:11:23,600 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-10-31 01:11:27,352 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-10-31 01:11:27,352 | server.py:91 | Evaluating initial parameters
  0%|          | 0/2787 [00:00<?, ?it/s]  0%|          | 1/2787 [00:00<23:50,  1.95it/s]  5%|▌         | 151/2787 [00:00<00:08, 327.63it/s] 11%|█         | 304/2787 [00:00<00:04, 612.07it/s] 16%|█▌        | 450/2787 [00:00<00:02, 826.22it/s] 22%|██▏       | 600/2787 [00:00<00:02, 1003.80it/s] 27%|██▋       | 744/2787 [00:01<00:01, 1121.53it/s] 32%|███▏      | 891/2787 [00:01<00:01, 1217.56it/s] 37%|███▋      | 1032/2787 [00:01<00:01, 1139.33it/s] 42%|████▏     | 1160/2787 [00:01<00:01, 1108.28it/s] 47%|████▋     | 1309/2787 [00:01<00:01, 1207.94it/s] 52%|█████▏    | 1439/2787 [00:01<00:01, 1221.74it/s] 57%|█████▋    | 1576/2787 [00:01<00:00, 1261.85it/s] 62%|██████▏   | 1740/2787 [00:01<00:00, 1368.71it/s] 68%|██████▊   | 1906/2787 [00:01<00:00, 1451.21it/s] 74%|███████▍  | 2071/2787 [00:01<00:00, 1507.92it/s] 80%|████████  | 2238/2787 [00:02<00:00, 1553.32it/s] 86%|████████▌ | 2403/2787 [00:02<00:00, 1579.89it/s] 92%|█████████▏| 2569/2787 [00:02<00:00, 1603.55it/s] 98%|█████████▊| 2735/2787 [00:02<00:00, 1617.53it/s]100%|██████████| 2787/2787 [00:02<00:00, 1152.37it/s]

### Loss 1946.229314148426 and accuracy 59.15% using DatasetID: 1 ###

  0%|          | 0/4330 [00:00<?, ?it/s]  4%|▍         | 164/4330 [00:00<00:02, 1637.83it/s]  8%|▊         | 329/4330 [00:00<00:02, 1640.29it/s] 11%|█▏        | 494/4330 [00:00<00:02, 1641.88it/s] 15%|█▌        | 659/4330 [00:00<00:02, 1642.23it/s] 19%|█▉        | 824/4330 [00:00<00:02, 1642.34it/s] 23%|██▎       | 989/4330 [00:00<00:02, 1639.67it/s] 27%|██▋       | 1154/4330 [00:00<00:01, 1642.83it/s] 30%|███       | 1320/4330 [00:00<00:01, 1646.81it/s] 34%|███▍      | 1486/4330 [00:00<00:01, 1648.29it/s] 38%|███▊      | 1651/4330 [00:01<00:01, 1648.36it/s] 42%|████▏     | 1816/4330 [00:01<00:01, 1645.68it/s] 46%|████▌     | 1981/4330 [00:01<00:01, 1642.09it/s] 50%|████▉     | 2147/4330 [00:01<00:01, 1645.59it/s] 53%|█████▎    | 2312/4330 [00:01<00:01, 1646.36it/s] 57%|█████▋    | 2478/4330 [00:01<00:01, 1648.19it/s] 61%|██████    | 2643/4330 [00:01<00:01, 1647.87it/s] 65%|██████▍   | 2809/4330 [00:01<00:00, 1650.09it/s] 69%|██████▊   | 2975/4330 [00:01<00:00, 1647.97it/s] 73%|███████▎  | 3140/4330 [00:01<00:00, 1647.53it/s] 76%|███████▋  | 3305/4330 [00:02<00:00, 1642.62it/s] 80%|████████  | 3470/4330 [00:02<00:00, 1639.79it/s] 84%|████████▍ | 3635/4330 [00:02<00:00, 1641.25it/s] 88%|████████▊ | 3800/4330 [00:02<00:00, 1642.48it/s] 92%|█████████▏| 3965/4330 [00:02<00:00, 1641.40it/s] 95%|█████████▌| 4131/4330 [00:02<00:00, 1643.96it/s] 99%|█████████▉| 4296/4330 [00:02<00:00, 1643.60it/s]100%|██████████| 4330/4330 [00:02<00:00, 1644.28it/s]

### Loss 3456.244038403034 and accuracy 46.21% using DatasetID: 2 ###

  0%|          | 0/1804 [00:00<?, ?it/s]  9%|▉         | 165/1804 [00:00<00:00, 1641.96it/s] 18%|█▊        | 330/1804 [00:00<00:00, 1637.24it/s] 27%|██▋       | 494/1804 [00:00<00:00, 1638.01it/s] 37%|███▋      | 659/1804 [00:00<00:00, 1640.02it/s] 46%|████▌     | 824/1804 [00:00<00:00, 1641.59it/s] 55%|█████▍    | 989/1804 [00:00<00:00, 1641.51it/s] 64%|██████▍   | 1154/1804 [00:00<00:00, 1640.63it/s] 73%|███████▎  | 1319/1804 [00:00<00:00, 1638.87it/s] 82%|████████▏ | 1484/1804 [00:00<00:00, 1638.99it/s] 91%|█████████▏| 1649/1804 [00:01<00:00, 1641.10it/s]100%|██████████| 1804/1804 [00:01<00:00, 1640.59it/s]

### Loss 1159.0332248210907 and accuracy 78.53% using DatasetID: 3 ###

  0%|          | 0/1065 [00:00<?, ?it/s] 15%|█▌        | 165/1065 [00:00<00:00, 1642.22it/s] 31%|███       | 330/1065 [00:00<00:00, 1645.78it/s] 46%|████▋     | 495/1065 [00:00<00:00, 1640.20it/s] 62%|██████▏   | 662/1065 [00:00<00:00, 1648.07it/s] 78%|███████▊  | 827/1065 [00:00<00:00, 1647.56it/s] 93%|█████████▎| 993/1065 [00:00<00:00, 1649.05it/s]100%|██████████| 1065/1065 [00:00<00:00, 1647.73it/s]

### Loss 697.1527707278728 and accuracy 73.66% using DatasetID: 4 ###

  0%|          | 0/1791 [00:00<?, ?it/s]  9%|▉         | 166/1791 [00:00<00:00, 1655.31it/s] 19%|█▊        | 333/1791 [00:00<00:00, 1659.98it/s] 28%|██▊       | 500/1791 [00:00<00:00, 1663.47it/s] 37%|███▋      | 667/1791 [00:00<00:00, 1664.65it/s] 47%|████▋     | 834/1791 [00:00<00:00, 1665.54it/s] 56%|█████▌    | 1001/1791 [00:00<00:00, 1664.44it/s] 65%|██████▌   | 1168/1791 [00:00<00:00, 1663.95it/s] 75%|███████▍  | 1335/1791 [00:00<00:00, 1657.29it/s] 84%|████████▍ | 1501/1791 [00:00<00:00, 1656.20it/s] 93%|█████████▎| 1668/1791 [00:01<00:00, 1658.75it/s]100%|██████████| 1791/1791 [00:01<00:00, 1660.68it/s]

### Loss 1264.8307334184647 and accuracy 31.23% using DatasetID: 5 ###

  0%|          | 0/1194 [00:00<?, ?it/s] 14%|█▍        | 166/1194 [00:00<00:00, 1655.59it/s] 28%|██▊       | 332/1194 [00:00<00:00, 1654.60it/s] 42%|████▏     | 498/1194 [00:00<00:00, 1648.95it/s] 56%|█████▌    | 663/1194 [00:00<00:00, 1647.06it/s] 69%|██████▉   | 828/1194 [00:00<00:00, 1647.14it/s] 83%|████████▎ | 993/1194 [00:00<00:00, 1633.73it/s] 97%|█████████▋| 1157/1194 [00:00<00:00, 1635.73it/s]100%|██████████| 1194/1194 [00:00<00:00, 1641.23it/s]

### Loss 806.6586399674416 and accuracy 74.05% using DatasetID: 6 ###

  0%|          | 0/1411 [00:00<?, ?it/s] 12%|█▏        | 165/1411 [00:00<00:00, 1640.12it/s] 24%|██▎       | 332/1411 [00:00<00:00, 1652.99it/s] 35%|███▌      | 499/1411 [00:00<00:00, 1658.81it/s] 47%|████▋     | 665/1411 [00:00<00:00, 1657.31it/s] 59%|█████▉    | 831/1411 [00:00<00:00, 1656.74it/s] 71%|███████   | 997/1411 [00:00<00:00, 1649.02it/s] 82%|████████▏ | 1163/1411 [00:00<00:00, 1650.45it/s] 94%|█████████▍| 1329/1411 [00:00<00:00, 1648.61it/s]100%|██████████| 1411/1411 [00:00<00:00, 1650.32it/s]
INFO flwr 2023-10-31 01:12:00,753 | server.py:94 | initial parameters (loss, other metrics): 936.9802343249321, {'accuracy': 58.22649049018061}
INFO flwr 2023-10-31 01:12:00,753 | server.py:104 | FL starting
DEBUG flwr 2023-10-31 01:12:00,753 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
Starting Client training for 10 epochs
Starting Client training for 10 epochs
Starting Client training for 10 epochs
Starting Client training for 10 epochs
Starting Client training for 10 epochs
Starting Client training for 10 epochs
Starting Client training for 10 epochs
Epoch 1: train loss 0.010657950304448605, accuracy: 97.37%
Epoch 1: train loss 0.010126389563083649, accuracy: 98.96%
Epoch 1: train loss 0.012013235129415989, accuracy: 92.81%
Epoch 1: train loss 0.009905735962092876, accuracy: 99.66%
Epoch 1: train loss 0.010412151925265789, accuracy: 98.03%
Epoch 2: train loss 0.010198268108069897, accuracy: 98.71%
Epoch 2: train loss 0.010111270472407341, accuracy: 98.97%
Epoch 2: train loss 0.011778471060097218, accuracy: 93.65%
Epoch 1: train loss 0.011785860173404217, accuracy: 93.93%
Epoch 3: train loss 0.01019660010933876, accuracy: 98.71%
Epoch 3: train loss 0.010111269541084766, accuracy: 98.97%
Epoch 2: train loss 0.009795006364583969, accuracy: 99.99%
Epoch 2: train loss 0.009992524981498718, accuracy: 99.36%
Epoch 4: train loss 0.010196992196142673, accuracy: 98.7%
Epoch 3: train loss 0.011792338453233242, accuracy: 93.5%
Epoch 1: train loss 0.011500543914735317, accuracy: 94.54%
Epoch 4: train loss 0.010111270472407341, accuracy: 98.97%
Epoch 5: train loss 0.010196941904723644, accuracy: 98.7%
Epoch 3: train loss 0.009794137440621853, accuracy: 99.99%
Epoch 3: train loss 0.009982646442949772, accuracy: 99.4%
Epoch 4: train loss 0.011822447180747986, accuracy: 93.39%
Epoch 5: train loss 0.010111270472407341, accuracy: 98.97%
Epoch 2: train loss 0.011309203691780567, accuracy: 95.23%
Epoch 6: train loss 0.010196254588663578, accuracy: 98.7%
Epoch 6: train loss 0.010111269541084766, accuracy: 98.97%
Epoch 5: train loss 0.011742359958589077, accuracy: 93.73%
Epoch 4: train loss 0.009974269196391106, accuracy: 99.41%
Epoch 4: train loss 0.009793981909751892, accuracy: 99.99%
Epoch 7: train loss 0.01019785925745964, accuracy: 98.71%
Epoch 7: train loss 0.010111269541084766, accuracy: 98.97%
Epoch 8: train loss 0.010195337235927582, accuracy: 98.7%
Epoch 6: train loss 0.01173485442996025, accuracy: 93.79%
Epoch 3: train loss 0.010949160903692245, accuracy: 96.31%
Epoch 2: train loss 0.01127521600574255, accuracy: 95.19%
Epoch 5: train loss 0.009973258711397648, accuracy: 99.41%
Epoch 5: train loss 0.009794103913009167, accuracy: 99.99%
Epoch 9: train loss 0.010196254588663578, accuracy: 98.7%
Epoch 8: train loss 0.010111270472407341, accuracy: 98.97%
Epoch 7: train loss 0.011720261536538601, accuracy: 93.79%
Epoch 9: train loss 0.010111269541084766, accuracy: 98.97%
Epoch 6: train loss 0.009974030777812004, accuracy: 99.42%
Epoch 6: train loss 0.009794103913009167, accuracy: 99.99%
Epoch 8: train loss 0.011727558448910713, accuracy: 93.79%
Epoch 4: train loss 0.010717210359871387, accuracy: 97.02%
Epoch 7: train loss 0.009972456842660904, accuracy: 99.42%
Epoch 7: train loss 0.009793968871235847, accuracy: 99.99%
Epoch 9: train loss 0.0117396991699934, accuracy: 93.77%
Epoch 3: train loss 0.011186998337507248, accuracy: 95.51%
