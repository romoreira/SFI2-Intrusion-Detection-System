INFO flwr 2023-11-04 01:08:21,189 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=4, round_timeout=None)
INFO flwr 2023-11-04 01:08:21,197 | app.py:175 | Flower ECE: gRPC server running (4 rounds), SSL is disabled
INFO flwr 2023-11-04 01:08:21,197 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-04 01:08:21,197 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-04 01:08:34,876 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-04 01:08:34,876 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<12:09,  1.91it/s] 12%|█▏        | 165/1394 [00:00<00:03, 352.78it/s] 24%|██▎       | 331/1394 [00:00<00:01, 658.23it/s] 36%|███▌      | 496/1394 [00:00<00:00, 906.24it/s] 47%|████▋     | 661/1394 [00:00<00:00, 1101.21it/s] 59%|█████▉    | 827/1394 [00:01<00:00, 1252.02it/s] 71%|███████▏  | 994/1394 [00:01<00:00, 1367.14it/s] 83%|████████▎ | 1161/1394 [00:01<00:00, 1452.89it/s] 95%|█████████▌| 1329/1394 [00:01<00:00, 1518.06it/s]100%|██████████| 1394/1394 [00:01<00:00, 1020.73it/s]
INFO flwr 2023-11-04 01:08:44,676 | server.py:94 | initial parameters (loss, other metrics): 806.9572147130966, {'accuracy': 0.6803615079276087}
INFO flwr 2023-11-04 01:08:44,676 | server.py:104 | FL starting
DEBUG flwr 2023-11-04 01:08:44,676 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 01:18:07,699 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-04 01:18:07,708 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 806.9572147130966 / accuracy 0.6803615079276087
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 168/1394 [00:00<00:00, 1674.67it/s] 24%|██▍       | 337/1394 [00:00<00:00, 1678.00it/s] 36%|███▋      | 506/1394 [00:00<00:00, 1680.86it/s] 48%|████▊     | 675/1394 [00:00<00:00, 1683.05it/s] 61%|██████    | 844/1394 [00:00<00:00, 1684.34it/s] 73%|███████▎  | 1014/1394 [00:00<00:00, 1686.33it/s] 85%|████████▍ | 1183/1394 [00:00<00:00, 1682.33it/s] 97%|█████████▋| 1352/1394 [00:00<00:00, 1675.70it/s]100%|██████████| 1394/1394 [00:00<00:00, 1680.02it/s]
INFO flwr 2023-11-04 01:18:12,470 | server.py:125 | fit progress: (1, 692.5121522247791, {'accuracy': 0.8163306496826714}, 567.7943705409998)
DEBUG flwr 2023-11-04 01:18:12,470 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 01:18:14,907 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-04 01:18:14,907 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-04 01:18:14,907 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 01:27:53,045 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 692.5121522247791 / accuracy 0.8163306496826714
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 162/1394 [00:00<00:00, 1619.72it/s] 23%|██▎       | 325/1394 [00:00<00:00, 1621.87it/s] 35%|███▌      | 488/1394 [00:00<00:00, 1623.62it/s] 47%|████▋     | 651/1394 [00:00<00:00, 1623.49it/s] 58%|█████▊    | 814/1394 [00:00<00:00, 1625.42it/s] 70%|███████   | 978/1394 [00:00<00:00, 1627.13it/s] 82%|████████▏ | 1142/1394 [00:00<00:00, 1628.44it/s] 94%|█████████▎| 1305/1394 [00:00<00:00, 1627.15it/s]100%|██████████| 1394/1394 [00:00<00:00, 1625.94it/s]
INFO flwr 2023-11-04 01:27:57,765 | server.py:125 | fit progress: (2, 491.79672092199326, {'accuracy': 0.9604628736740598}, 1153.0888063629973)
DEBUG flwr 2023-11-04 01:27:57,765 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 01:28:00,235 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
DEBUG flwr 2023-11-04 01:28:00,235 | server.py:222 | fit_round 3: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 01:37:15,280 | server.py:236 | fit_round 3 received 7 results and 0 failures
Server-side evaluation loss 491.79672092199326 / accuracy 0.9604628736740598
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 170/1394 [00:00<00:00, 1699.52it/s] 24%|██▍       | 341/1394 [00:00<00:00, 1701.82it/s] 37%|███▋      | 512/1394 [00:00<00:00, 1703.19it/s] 49%|████▉     | 683/1394 [00:00<00:00, 1702.41it/s] 61%|██████▏   | 854/1394 [00:00<00:00, 1703.54it/s] 74%|███████▎  | 1025/1394 [00:00<00:00, 1704.36it/s] 86%|████████▌ | 1196/1394 [00:00<00:00, 1705.27it/s] 98%|█████████▊| 1367/1394 [00:00<00:00, 1705.36it/s]100%|██████████| 1394/1394 [00:00<00:00, 1703.94it/s]
INFO flwr 2023-11-04 01:37:19,780 | server.py:125 | fit progress: (3, 481.6396325826645, {'accuracy': 0.967684061806194}, 1715.1040358549799)
DEBUG flwr 2023-11-04 01:37:19,780 | server.py:173 | evaluate_round 3: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 01:37:22,181 | server.py:187 | evaluate_round 3 received 7 results and 0 failures
DEBUG flwr 2023-11-04 01:37:22,182 | server.py:222 | fit_round 4: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 01:46:36,866 | server.py:236 | fit_round 4 received 7 results and 0 failures
Server-side evaluation loss 481.6396325826645 / accuracy 0.967684061806194
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 169/1394 [00:00<00:00, 1689.78it/s] 24%|██▍       | 340/1394 [00:00<00:00, 1696.24it/s] 37%|███▋      | 510/1394 [00:00<00:00, 1697.68it/s] 49%|████▉     | 681/1394 [00:00<00:00, 1699.82it/s] 61%|██████    | 851/1394 [00:00<00:00, 1699.17it/s] 73%|███████▎  | 1021/1394 [00:00<00:00, 1698.57it/s] 86%|████████▌ | 1192/1394 [00:00<00:00, 1699.09it/s] 98%|█████████▊| 1363/1394 [00:00<00:00, 1699.92it/s]100%|██████████| 1394/1394 [00:00<00:00, 1698.71it/s]
INFO flwr 2023-11-04 01:46:41,460 | server.py:125 | fit progress: (4, 478.6593120098114, {'accuracy': 0.9698593886658743}, 2276.784056713979)
DEBUG flwr 2023-11-04 01:46:41,460 | server.py:173 | evaluate_round 4: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-04 01:46:43,907 | server.py:187 | evaluate_round 4 received 7 results and 0 failures
INFO flwr 2023-11-04 01:46:43,907 | server.py:153 | FL finished in 2279.2316031510127
INFO flwr 2023-11-04 01:46:43,908 | app.py:225 | app_fit: losses_distributed [(1, 690.7398794188503), (2, 636.4434761199298), (3, 697.0307422040847), (4, 759.3491687639536)]
INFO flwr 2023-11-04 01:46:43,908 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-04 01:46:43,908 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-04 01:46:43,908 | app.py:228 | app_fit: losses_centralized [(0, 806.9572147130966), (1, 692.5121522247791), (2, 491.79672092199326), (3, 481.6396325826645), (4, 478.6593120098114)]
INFO flwr 2023-11-04 01:46:43,908 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.6803615079276087), (1, 0.8163306496826714), (2, 0.9604628736740598), (3, 0.967684061806194), (4, 0.9698593886658743)]}
Server-side evaluation loss 478.6593120098114 / accuracy 0.9698593886658743
cy: 99.18%
Epoch 3: train loss 0.009904803708195686, accuracy: 99.59%
Epoch 5: train loss 0.011057755909860134, accuracy: 95.89%
Epoch 2: train loss 0.011538906022906303, accuracy: 94.41%
Epoch 4: train loss 0.01184870209544897, accuracy: 93.41%
Epoch 6: train loss 0.011249548755586147, accuracy: 95.2%
Epoch 6: train loss 0.010728990659117699, accuracy: 96.94%
Epoch 4: train loss 0.010027975775301456, accuracy: 99.23%
Epoch 4: train loss 0.00984366238117218, accuracy: 99.85%
Epoch 7: train loss 0.01127188466489315, accuracy: 95.29%
Epoch 5: train loss 0.011804291047155857, accuracy: 93.59%
Epoch 7: train loss 0.010424780659377575, accuracy: 97.99%
Epoch 8: train loss 0.011243816465139389, accuracy: 95.33%
Epoch 2: train loss 0.010965541936457157, accuracy: 96.23%
Epoch 3: train loss 0.011521323584020138, accuracy: 94.46%
Epoch 6: train loss 0.011642022989690304, accuracy: 94.09%
Epoch 5: train loss 0.010026403702795506, accuracy: 99.24%
Epoch 5: train loss 0.009793135337531567, accuracy: 99.99%
Epoch 8: train loss 0.010379096493124962, accuracy: 98.09%
Epoch 9: train loss 0.011231398209929466, accuracy: 95.3%
Epoch 9: train loss 0.010361195541918278, accuracy: 98.13%
Epoch 7: train loss 0.011628279462456703, accuracy: 94.13%
Epoch 6: train loss 0.010028849355876446, accuracy: 99.24%
Epoch 6: train loss 0.009792710654437542, accuracy: 99.99%
Epoch 4: train loss 0.011523517780005932, accuracy: 94.47%
Epoch 8: train loss 0.011612344533205032, accuracy: 94.17%
Epoch 7: train loss 0.010031625628471375, accuracy: 99.23%
Epoch 7: train loss 0.00979267805814743, accuracy: 99.99%
Epoch 3: train loss 0.010932011529803276, accuracy: 96.35%
Epoch 9: train loss 0.011608356609940529, accuracy: 94.17%
Epoch 8: train loss 0.010027125477790833, accuracy: 99.21%
Epoch 8: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 5: train loss 0.012034463696181774, accuracy: 92.86%
Epoch 9: train loss 0.010025647468864918, accuracy: 99.22%
Epoch 9: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 4: train loss 0.010905909352004528, accuracy: 96.44%
Epoch 6: train loss 0.011462567374110222, accuracy: 94.63%
Epoch 7: train loss 0.011446322314441204, accuracy: 94.72%
Epoch 5: train loss 0.01091049425303936, accuracy: 96.43%
Epoch 8: train loss 0.01143135316669941, accuracy: 94.7%
Epoch 6: train loss 0.010893559083342552, accuracy: 96.48%
Epoch 9: train loss 0.011438839137554169, accuracy: 94.73%
Epoch 7: train loss 0.010893221013247967, accuracy: 96.47%
Epoch 8: train loss 0.010892909951508045, accuracy: 96.49%
Epoch 9: train loss 0.0108841173350811, accuracy: 96.5%
Epoch 10: train loss 0.011614758521318436, accuracy: 94.17%
Epoch 10: train loss 0.01125413179397583, accuracy: 95.36%
Epoch 10: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 10: train loss 0.010026211850345135, accuracy: 99.24%
Epoch 10: train loss 0.011446085758507252, accuracy: 94.74%
Epoch 10: train loss 0.010896212421357632, accuracy: 96.47%
Epoch 10: train loss 0.010363606736063957, accuracy: 98.16%
Acurácia do Cliente: 6 eh: 0.9359296482412061
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.9608665425758561
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.5212413167172828
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.7906483232521546
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.6916057585825027
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9769325585490404
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9791760507258931
Starting Client training for 10 epochs
Epoch 1: train loss 0.011521034874022007, accuracy: 94.46%
Epoch 1: train loss 0.011716331355273724, accuracy: 93.69%
Epoch 1: train loss 0.019116122275590897, accuracy: 70.18%
Epoch 1: train loss 0.010806863196194172, accuracy: 96.7%
Epoch 1: train loss 0.010137301869690418, accuracy: 98.86%
Epoch 2: train loss 0.011249268427491188, accuracy: 95.29%
Epoch 2: train loss 0.010617534630000591, accuracy: 97.34%
Epoch 2: train loss 0.018601788207888603, accuracy: 71.8%
Epoch 1: train loss 0.011736301705241203, accuracy: 93.79%
Epoch 3: train loss 0.011148606427013874, accuracy: 95.61%
Epoch 3: train loss 0.010542543604969978, accuracy: 97.59%
Epoch 2: train loss 0.010173368267714977, accuracy: 98.75%
Epoch 2: train loss 0.009827646426856518, accuracy: 99.86%
Epoch 3: train loss 0.01675776205956936, accuracy: 77.64%
Epoch 1: train loss 0.01119664590805769, accuracy: 95.52%
Epoch 4: train loss 0.011145447380840778, accuracy: 95.73%
Epoch 4: train loss 0.010498302057385445, accuracy: 97.67%
Epoch 3: train loss 0.01011170819401741, accuracy: 98.94%
Epoch 3: train loss 0.009794540703296661, accuracy: 99.99%
Epoch 5: train loss 0.011111374013125896, accuracy: 95.79%
Epoch 4: train loss 0.01256579253822565, accuracy: 91.16%
Epoch 5: train loss 0.010483664460480213, accuracy: 97.82%
Epoch 2: train loss 0.011506917886435986, accuracy: 94.48%
Epoch 6: train loss 0.011042692698538303, accuracy: 95.98%
Epoch 6: train loss 0.010434548370540142, accuracy: 97.89%
Epoch 5: train loss 0.01201779954135418, accuracy: 92.85%
Epoch 4: train loss 0.010085360147058964, accuracy: 99.06%
Epoch 4: train loss 0.009792729280889034, accuracy: 99.99%
Epoch 7: train loss 0.010516461916267872, accuracy: 97.72%
Epoch 7: train loss 0.010424942709505558, accuracy: 97.9%
Epoch 6: train loss 0.011918297037482262, accuracy: 93.24%
Epoch 2: train loss 0.01093612052500248, accuracy: 96.34%
Epoch 3: train loss 0.01115089375525713, accuracy: 95.62%
Epoch 5: train loss 0.010067286901175976, accuracy: 99.08%
Epoch 8: train loss 0.010419963859021664, accuracy: 97.98%
Epoch 5: train loss 0.009792682714760303, accuracy: 99.99%
Epoch 8: train loss 0.010418563149869442, accuracy: 97.99%
Epoch 7: train loss 0.011869911104440689, accuracy: 93.37%
Epoch 9: train loss 0.01043042354285717, accuracy: 97.99%
Epoch 9: train loss 0.010410107672214508, accuracy: 98.01%
Epoch 6: train loss 0.010069699957966805, accuracy: 99.11%
Epoch 6: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 8: train loss 0.011826823465526104, accuracy: 93.5%
Epoch 4: train loss 0.010918780229985714, accuracy: 96.38%
Epoch 7: train loss 0.010077619925141335, accuracy: 99.1%
Epoch 7: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 3: train loss 0.010935838334262371, accuracy: 96.34%
Epoch 9: train loss 0.011692249216139317, accuracy: 93.91%
Epoch 8: train loss 0.010067413561046124, accuracy: 99.11%
Epoch 8: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 5: train loss 0.010907023213803768, accuracy: 96.4%
Epoch 9: train loss 0.010055065155029297, accuracy: 99.15%
Epoch 9: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 4: train loss 0.010921971872448921, accuracy: 96.38%
Epoch 6: train loss 0.010905125178396702, accuracy: 96.41%
Epoch 7: train loss 0.010901578702032566, accuracy: 96.42%
Epoch 5: train loss 0.010902952402830124, accuracy: 96.45%
Epoch 8: train loss 0.010899643413722515, accuracy: 96.41%
Epoch 6: train loss 0.010913083329796791, accuracy: 96.42%
Epoch 9: train loss 0.010899355635046959, accuracy: 96.43%
Epoch 7: train loss 0.010907355695962906, accuracy: 96.44%
Epoch 8: train loss 0.01090164389461279, accuracy: 96.45%
Epoch 9: train loss 0.010902722366154194, accuracy: 96.46%
Epoch 10: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 10: train loss 0.010897545143961906, accuracy: 96.44%
Epoch 10: train loss 0.010900143533945084, accuracy: 96.46%
Epoch 10: train loss 0.010060486383736134, accuracy: 99.14%
Epoch 10: train loss 0.010412110015749931, accuracy: 97.94%
Epoch 10: train loss 0.011658168397843838, accuracy: 94.03%
Epoch 10: train loss 0.010381904430687428, accuracy: 98.09%
Acurácia do Cliente: 7 eh: 0.44110741971207085
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9935553168635876
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.9802659128978225
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9836825732229852
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.9687380861608845
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.44416518309072506
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.7209943555023025
Starting Client training for 10 epochs
Epoch 1: train loss 0.011223021894693375, accuracy: 95.38%
Epoch 1: train loss 0.01092000026255846, accuracy: 96.39%
Epoch 1: train loss 0.01970391720533371, accuracy: 68.29%
Epoch 1: train loss 0.011082724668085575, accuracy: 95.88%
Epoch 1: train loss 0.00989884976297617, accuracy: 99.62%
Epoch 2: train loss 0.011175264604389668, accuracy: 95.45%
Epoch 2: train loss 0.01032645907253027, accuracy: 98.29%
Epoch 1: train loss 0.011308682151138783, accuracy: 95.1%
Epoch 2: train loss 0.018877062946558, accuracy: 70.88%
Epoch 3: train loss 0.010708780027925968, accuracy: 97.05%
Epoch 3: train loss 0.010315978899598122, accuracy: 98.31%
Epoch 2: train loss 0.009794257581233978, accuracy: 99.99%
Epoch 2: train loss 0.010327313095331192, accuracy: 98.27%
Epoch 3: train loss 0.015547593124210835, accuracy: 81.5%
Epoch 1: train loss 0.011524351313710213, accuracy: 94.48%
Epoch 4: train loss 0.010473880916833878, accuracy: 97.76%
Epoch 4: train loss 0.010287996381521225, accuracy: 98.38%
Epoch 3: train loss 0.009792700409889221, accuracy: 99.99%
Epoch 3: train loss 0.010186535306274891, accuracy: 98.72%
Epoch 5: train loss 0.010436049662530422, accuracy: 97.82%
Epoch 4: train loss 0.012463504448533058, accuracy: 91.37%
Epoch 5: train loss 0.010272812098264694, accuracy: 98.39%
Epoch 2: train loss 0.01091146469116211, accuracy: 96.37%
Epoch 6: train loss 0.010429183952510357, accuracy: 97.81%
Epoch 6: train loss 0.010275367647409439, accuracy: 98.4%
Epoch 4: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 4: train loss 0.010167429223656654, accuracy: 98.78%
Epoch 5: train loss 0.012100761756300926, accuracy: 92.58%
Epoch 7: train loss 0.010396918281912804, accuracy: 97.93%
Epoch 7: train loss 0.01025355700403452, accuracy: 98.47%
Epoch 2: train loss 0.010968255810439587, accuracy: 96.24%
Epoch 6: train loss 0.01199822686612606, accuracy: 92.96%
Epoch 8: train loss 0.010261479765176773, accuracy: 98.44%
Epoch 3: train loss 0.01075912918895483, accuracy: 96.92%
Epoch 5: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 5: train loss 0.01013963669538498, accuracy: 98.93%
Epoch 8: train loss 0.010253407061100006, accuracy: 98.49%
Epoch 9: train loss 0.010207491926848888, accuracy: 98.74%
Epoch 7: train loss 0.01194875780493021, accuracy: 93.07%
Epoch 9: train loss 0.01025354117155075, accuracy: 98.5%
Epoch 6: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 6: train loss 0.01011023111641407, accuracy: 98.99%
Epoch 8: train loss 0.011904655024409294, accuracy: 93.3%
Epoch 4: train loss 0.010734865441918373, accuracy: 96.98%
Epoch 7: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 7: train loss 0.010092037729918957, accuracy: 99.03%
Epoch 9: train loss 0.011809688061475754, accuracy: 93.5%
Epoch 3: train loss 0.010918261483311653, accuracy: 96.4%
Epoch 8: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 8: train loss 0.01008885633200407, accuracy: 99.05%
Epoch 5: train loss 0.010736030526459217, accuracy: 96.98%
Epoch 9: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 9: train loss 0.010077121667563915, accuracy: 99.11%
Epoch 4: train loss 0.010910474695265293, accuracy: 96.43%
Epoch 6: train loss 0.01073427777737379, accuracy: 96.98%
Epoch 7: train loss 0.01067130733281374, accuracy: 97.16%
Epoch 5: train loss 0.010903825983405113, accuracy: 96.45%
Epoch 8: train loss 0.010624234564602375, accuracy: 97.33%
Epoch 6: train loss 0.010900500230491161, accuracy: 96.45%
Epoch 9: train loss 0.01062463503330946, accuracy: 97.33%
Epoch 7: train loss 0.010906730778515339, accuracy: 96.45%
Epoch 8: train loss 0.010904424823820591, accuracy: 96.44%
Epoch 9: train loss 0.010891890153288841, accuracy: 96.48%
Epoch 10: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 10: train loss 0.01174433808773756, accuracy: 93.75%
Epoch 10: train loss 0.010894258506596088, accuracy: 96.47%
Epoch 10: train loss 0.01062301080673933, accuracy: 97.33%
Epoch 10: train loss 0.010240476578474045, accuracy: 98.5%
Epoch 10: train loss 0.010201247408986092, accuracy: 98.74%
Epoch 10: train loss 0.0100705586373806, accuracy: 99.12%
Acurácia do Cliente: 6 eh: 0.9880653266331658
Acurácia do Cliente: 5 eh: 0.43927810940063533
Acurácia do Cliente: 2 eh: 0.6324002829466876
Acurácia do Cliente: 3 eh: 0.998440802466997
Acurácia do Cliente: 4 eh: 0.9850325761577743
Acurácia do Cliente: 7 eh: 0.4372978959025471
Acurácia do Cliente: 1 eh: 0.9692763113632796
