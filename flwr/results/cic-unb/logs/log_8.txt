INFO flwr 2023-11-03 19:20:03,445 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-03 19:20:03,452 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-03 19:20:03,452 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-03 19:20:03,452 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-03 19:20:18,243 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-03 19:20:18,243 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:13,  2.07it/s] 11%|█         | 153/1394 [00:00<00:03, 347.92it/s] 22%|██▏       | 306/1394 [00:00<00:01, 637.52it/s] 33%|███▎      | 455/1394 [00:00<00:01, 858.41it/s] 43%|████▎     | 604/1394 [00:00<00:00, 1028.31it/s] 53%|█████▎    | 741/1394 [00:00<00:00, 1118.71it/s] 63%|██████▎   | 878/1394 [00:01<00:00, 1091.50it/s] 72%|███████▏  | 1004/1394 [00:01<00:00, 1122.93it/s] 83%|████████▎ | 1157/1394 [00:01<00:00, 1235.16it/s] 93%|█████████▎| 1290/1394 [00:01<00:00, 1232.92it/s]100%|██████████| 1394/1394 [00:01<00:00, 932.21it/s] 
INFO flwr 2023-11-03 19:20:27,247 | server.py:94 | initial parameters (loss, other metrics): 785.4552145302296, {'accuracy': 0.8278352133838667}
INFO flwr 2023-11-03 19:20:27,247 | server.py:104 | FL starting
DEBUG flwr 2023-11-03 19:20:27,247 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 19:29:53,638 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 19:29:53,646 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 785.4552145302296 / accuracy 0.8278352133838667
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 166/1394 [00:00<00:00, 1657.26it/s] 24%|██▍       | 333/1394 [00:00<00:00, 1659.66it/s] 36%|███▌      | 499/1394 [00:00<00:00, 1659.17it/s] 48%|████▊     | 666/1394 [00:00<00:00, 1660.09it/s] 60%|█████▉    | 833/1394 [00:00<00:00, 1661.61it/s] 72%|███████▏  | 1000/1394 [00:00<00:00, 1660.66it/s] 84%|████████▎ | 1167/1394 [00:00<00:00, 1660.13it/s] 96%|█████████▌| 1334/1394 [00:00<00:00, 1661.80it/s]100%|██████████| 1394/1394 [00:00<00:00, 1661.75it/s]
INFO flwr 2023-11-03 19:29:58,403 | server.py:125 | fit progress: (1, 686.2300761640072, {'accuracy': 0.8210401202036285}, 571.1561600299901)
DEBUG flwr 2023-11-03 19:29:58,403 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 19:30:00,899 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 19:30:00,899 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-03 19:30:00,899 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 19:39:24,104 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 686.2300761640072 / accuracy 0.8210401202036285
  0%|          | 0/1394 [00:00<?, ?it/s] 11%|█▏        | 160/1394 [00:00<00:00, 1596.97it/s] 23%|██▎       | 321/1394 [00:00<00:00, 1602.85it/s] 35%|███▍      | 483/1394 [00:00<00:00, 1607.11it/s] 46%|████▋     | 645/1394 [00:00<00:00, 1609.86it/s] 58%|█████▊    | 806/1394 [00:00<00:00, 1608.67it/s] 69%|██████▉   | 968/1394 [00:00<00:00, 1610.02it/s] 81%|████████  | 1130/1394 [00:00<00:00, 1611.24it/s] 93%|█████████▎| 1292/1394 [00:00<00:00, 1611.56it/s]100%|██████████| 1394/1394 [00:00<00:00, 1609.30it/s]
INFO flwr 2023-11-03 19:39:29,011 | server.py:125 | fit progress: (2, 681.2705511748791, {'accuracy': 0.8245610100692965}, 1141.7641987820098)
DEBUG flwr 2023-11-03 19:39:29,011 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 19:39:31,442 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-03 19:39:31,442 | server.py:153 | FL finished in 1144.1952631759923
INFO flwr 2023-11-03 19:39:31,443 | app.py:225 | app_fit: losses_distributed [(1, 713.2055581183864), (2, 824.8989088986042)]
INFO flwr 2023-11-03 19:39:31,443 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-03 19:39:31,443 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-03 19:39:31,443 | app.py:228 | app_fit: losses_centralized [(0, 785.4552145302296), (1, 686.2300761640072), (2, 681.2705511748791)]
INFO flwr 2023-11-03 19:39:31,443 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.8278352133838667), (1, 0.8210401202036285), (2, 0.8245610100692965)]}
Server-side evaluation loss 681.2705511748791 / accuracy 0.8245610100692965
rain loss 0.010293364524841309, accuracy: 98.39%
Epoch 4: train loss 0.010963162407279015, accuracy: 96.27%
Epoch 7: train loss 0.010291732847690582, accuracy: 98.4%
Epoch 5: train loss 0.010964139364659786, accuracy: 96.27%
Epoch 8: train loss 0.01029299944639206, accuracy: 98.4%
Epoch 9: train loss 0.010291372425854206, accuracy: 98.4%
Epoch 6: train loss 0.010931159369647503, accuracy: 96.38%
Epoch 7: train loss 0.010997239500284195, accuracy: 96.15%
Epoch 8: train loss 0.01096923928707838, accuracy: 96.23%
Epoch 9: train loss 0.01088656298816204, accuracy: 96.5%
Epoch 10: train loss 0.01012733019888401, accuracy: 98.95%
Epoch 10: train loss 0.009870276786386967, accuracy: 99.73%
Epoch 10: train loss 0.009955313988029957, accuracy: 99.47%
Epoch 10: train loss 0.011200048960745335, accuracy: 95.51%
Epoch 10: train loss 0.010290266945958138, accuracy: 98.4%
Epoch 10: train loss 0.009793028235435486, accuracy: 99.99%
Epoch 10: train loss 0.010857760906219482, accuracy: 96.58%
Acurácia do Cliente: 1 eh: 0.8244713058688973
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.5665559246954596
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.8114104595879557
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.8574546966494577
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.5536705414179495
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.7772660998108877
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.7786327470686767
Starting Client training for 10 epochs
Epoch 1: train loss 0.012555246241390705, accuracy: 91.21%
Epoch 1: train loss 0.015256764367222786, accuracy: 82.5%
Epoch 1: train loss 0.019788708537817, accuracy: 68.19%
Epoch 1: train loss 0.010569524019956589, accuracy: 97.53%
Epoch 1: train loss 0.01099118497222662, accuracy: 96.13%
Epoch 2: train loss 0.011392979882657528, accuracy: 94.87%
Epoch 2: train loss 0.014967783354222775, accuracy: 83.37%
Epoch 2: train loss 0.018978383392095566, accuracy: 70.57%
Epoch 1: train loss 0.014861511997878551, accuracy: 83.76%
Epoch 3: train loss 0.010999671183526516, accuracy: 96.06%
Epoch 3: train loss 0.01424345187842846, accuracy: 85.63%
Epoch 2: train loss 0.010103605687618256, accuracy: 98.99%
Epoch 2: train loss 0.00981845147907734, accuracy: 99.9%
Epoch 3: train loss 0.014518248848617077, accuracy: 84.77%
Epoch 4: train loss 0.010435597971081734, accuracy: 97.96%
Epoch 1: train loss 0.011252114549279213, accuracy: 95.35%
Epoch 4: train loss 0.013579603284597397, accuracy: 87.83%
Epoch 3: train loss 0.009798730723559856, accuracy: 99.97%
Epoch 3: train loss 0.010059299878776073, accuracy: 99.12%
Epoch 5: train loss 0.010377814061939716, accuracy: 98.14%
Epoch 5: train loss 0.012730787508189678, accuracy: 90.67%
Epoch 4: train loss 0.011877087876200676, accuracy: 93.32%
Epoch 2: train loss 0.014072571881115437, accuracy: 86.31%
Epoch 6: train loss 0.010366134345531464, accuracy: 98.18%
Epoch 6: train loss 0.011743105947971344, accuracy: 93.67%
Epoch 5: train loss 0.01173496339470148, accuracy: 93.79%
Epoch 4: train loss 0.00979745015501976, accuracy: 99.97%
Epoch 4: train loss 0.010064263828098774, accuracy: 99.1%
Epoch 7: train loss 0.01036712247878313, accuracy: 98.18%
Epoch 7: train loss 0.011519058607518673, accuracy: 94.33%
Epoch 6: train loss 0.011659258976578712, accuracy: 93.99%
Epoch 2: train loss 0.01104901172220707, accuracy: 96.0%
Epoch 3: train loss 0.01465620193630457, accuracy: 84.44%
Epoch 5: train loss 0.009793363511562347, accuracy: 99.99%
Epoch 8: train loss 0.011395715177059174, accuracy: 94.85%
Epoch 8: train loss 0.010352149605751038, accuracy: 98.22%
Epoch 5: train loss 0.010079752653837204, accuracy: 99.07%
Epoch 9: train loss 0.011247965507209301, accuracy: 95.27%
Epoch 7: train loss 0.011619958095252514, accuracy: 94.11%
Epoch 9: train loss 0.010349568910896778, accuracy: 98.2%
Epoch 6: train loss 0.00979321263730526, accuracy: 99.99%
Epoch 6: train loss 0.010087238624691963, accuracy: 99.06%
Epoch 8: train loss 0.011615891009569168, accuracy: 94.19%
Epoch 4: train loss 0.013890130445361137, accuracy: 86.86%
Epoch 7: train loss 0.009793111123144627, accuracy: 99.99%
Epoch 7: train loss 0.01011447049677372, accuracy: 98.96%
Epoch 9: train loss 0.011599333956837654, accuracy: 94.21%
Epoch 3: train loss 0.011027984321117401, accuracy: 96.06%
Epoch 8: train loss 0.009793071076273918, accuracy: 99.99%
Epoch 8: train loss 0.01011182926595211, accuracy: 98.98%
Epoch 5: train loss 0.012268530204892159, accuracy: 92.12%
Epoch 9: train loss 0.009793049655854702, accuracy: 99.99%
Epoch 9: train loss 0.010069845244288445, accuracy: 99.1%
Epoch 4: train loss 0.010970069095492363, accuracy: 96.27%
Epoch 6: train loss 0.011549935676157475, accuracy: 94.34%
Epoch 7: train loss 0.011388694867491722, accuracy: 94.92%
Epoch 5: train loss 0.010976339690387249, accuracy: 96.21%
Epoch 8: train loss 0.011160212568938732, accuracy: 95.61%
Epoch 6: train loss 0.010974072851240635, accuracy: 96.22%
Epoch 9: train loss 0.011299488134682178, accuracy: 95.18%
Epoch 7: train loss 0.010962250642478466, accuracy: 96.25%
Epoch 8: train loss 0.011061555705964565, accuracy: 95.91%
Epoch 9: train loss 0.010959719307720661, accuracy: 96.26%
Epoch 10: train loss 0.010928208939731121, accuracy: 96.36%
Epoch 10: train loss 0.009793047793209553, accuracy: 99.99%
Epoch 10: train loss 0.011586979031562805, accuracy: 94.26%
Epoch 10: train loss 0.011066507548093796, accuracy: 95.87%
Epoch 10: train loss 0.010353256948292255, accuracy: 98.21%
Epoch 10: train loss 0.01005555223673582, accuracy: 99.14%
Epoch 10: train loss 0.011002859100699425, accuracy: 96.14%
Acurácia do Cliente: 2 eh: 0.6362547097631043
Acurácia do Cliente: 3 eh: 0.873289213817955
Acurácia do Cliente: 5 eh: 0.4140049568890285
Acurácia do Cliente: 1 eh: 0.8264447982776794
Acurácia do Cliente: 6 eh: 0.8296168341708543
Acurácia do Cliente: 4 eh: 0.8193930856371426
Acurácia do Cliente: 7 eh: 0.436766334440753
