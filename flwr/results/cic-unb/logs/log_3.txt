INFO flwr 2023-11-06 01:45:30,858 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-06 01:45:30,867 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-06 01:45:30,867 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-06 01:45:30,867 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-06 01:45:43,658 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-06 01:45:43,658 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:40,  1.99it/s] 10%|█         | 142/1394 [00:00<00:03, 313.33it/s] 17%|█▋        | 241/1394 [00:00<00:02, 475.72it/s] 24%|██▍       | 338/1394 [00:00<00:01, 600.52it/s] 32%|███▏      | 450/1394 [00:00<00:01, 739.09it/s] 42%|████▏     | 589/1394 [00:01<00:00, 917.58it/s] 51%|█████     | 704/1394 [00:01<00:00, 982.95it/s] 61%|██████    | 850/1394 [00:01<00:00, 1118.07it/s] 73%|███████▎  | 1014/1394 [00:01<00:00, 1267.66it/s] 85%|████████▍ | 1179/1394 [00:01<00:00, 1379.13it/s] 96%|█████████▋| 1342/1394 [00:01<00:00, 1453.13it/s]100%|██████████| 1394/1394 [00:01<00:00, 906.59it/s] 
INFO flwr 2023-11-06 01:45:54,155 | server.py:94 | initial parameters (loss, other metrics): 1171.765109717846, {'accuracy': 0.4624700051579915}
INFO flwr 2023-11-06 01:45:54,155 | server.py:104 | FL starting
DEBUG flwr 2023-11-06 01:45:54,155 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 01:55:27,212 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 01:55:27,221 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1171.765109717846 / accuracy 0.4624700051579915
  0%|          | 0/1394 [00:00<?, ?it/s] 11%|█▏        | 159/1394 [00:00<00:00, 1581.08it/s] 23%|██▎       | 318/1394 [00:00<00:00, 1579.21it/s] 34%|███▍      | 477/1394 [00:00<00:00, 1583.07it/s] 46%|████▌     | 636/1394 [00:00<00:00, 1583.99it/s] 57%|█████▋    | 795/1394 [00:00<00:00, 1581.91it/s] 68%|██████▊   | 954/1394 [00:00<00:00, 1577.60it/s] 80%|███████▉  | 1112/1394 [00:00<00:00, 1571.96it/s] 91%|█████████ | 1271/1394 [00:00<00:00, 1577.03it/s]100%|██████████| 1394/1394 [00:00<00:00, 1579.38it/s]
INFO flwr 2023-11-06 01:55:32,419 | server.py:125 | fit progress: (1, 483.57950153946877, {'accuracy': 0.9662263685497073}, 578.2645600429969)
DEBUG flwr 2023-11-06 01:55:32,420 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 01:55:34,968 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 01:55:34,968 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-06 01:55:34,968 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:05:09,828 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 483.57950153946877 / accuracy 0.9662263685497073
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 164/1394 [00:00<00:00, 1636.35it/s] 24%|██▎       | 330/1394 [00:00<00:00, 1645.18it/s] 36%|███▌      | 496/1394 [00:00<00:00, 1650.94it/s] 47%|████▋     | 662/1394 [00:00<00:00, 1651.82it/s] 59%|█████▉    | 828/1394 [00:00<00:00, 1654.63it/s] 71%|███████▏  | 994/1394 [00:00<00:00, 1652.81it/s] 83%|████████▎ | 1160/1394 [00:00<00:00, 1654.00it/s] 95%|█████████▌| 1326/1394 [00:00<00:00, 1654.81it/s]100%|██████████| 1394/1394 [00:00<00:00, 1652.75it/s]
INFO flwr 2023-11-06 02:05:14,700 | server.py:125 | fit progress: (2, 481.17468053102493, {'accuracy': 0.9680653046578906}, 1160.5453345450223)
DEBUG flwr 2023-11-06 02:05:14,700 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:05:17,223 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-06 02:05:17,223 | server.py:153 | FL finished in 1163.068315159995
INFO flwr 2023-11-06 02:05:17,223 | app.py:225 | app_fit: losses_distributed [(1, 697.4169307186919), (2, 751.760015669365)]
INFO flwr 2023-11-06 02:05:17,223 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-06 02:05:17,223 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-06 02:05:17,223 | app.py:228 | app_fit: losses_centralized [(0, 1171.765109717846), (1, 483.57950153946877), (2, 481.17468053102493)]
INFO flwr 2023-11-06 02:05:17,223 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.4624700051579915), (1, 0.9662263685497073), (2, 0.9680653046578906)]}
Server-side evaluation loss 481.17468053102493 / accuracy 0.9680653046578906
in loss 0.010299745947122574, accuracy: 98.38%
Epoch 4: train loss 0.01095674280077219, accuracy: 96.28%
Epoch 7: train loss 0.01029611099511385, accuracy: 98.39%
Epoch 5: train loss 0.01098588015884161, accuracy: 96.17%
Epoch 8: train loss 0.0102987764403224, accuracy: 98.38%
Epoch 9: train loss 0.010295283049345016, accuracy: 98.38%
Epoch 6: train loss 0.01099017821252346, accuracy: 96.17%
Epoch 7: train loss 0.010948967188596725, accuracy: 96.3%
Epoch 8: train loss 0.010970997624099255, accuracy: 96.24%
Epoch 9: train loss 0.010934599675238132, accuracy: 96.32%
Epoch 10: train loss 0.009792754426598549, accuracy: 99.99%
Epoch 10: train loss 0.010298756882548332, accuracy: 98.38%
Epoch 10: train loss 0.009870857931673527, accuracy: 99.75%
Epoch 10: train loss 0.009956742636859417, accuracy: 99.47%
Epoch 10: train loss 0.011519670486450195, accuracy: 94.48%
Epoch 10: train loss 0.010942215099930763, accuracy: 96.33%
Epoch 10: train loss 0.010136904194951057, accuracy: 98.94%
Acurácia do Cliente: 6 eh: 0.9400649078726968
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9752260836422855
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.3464451827242525
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.6130135790833247
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9810412631331807
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.9655311609966136
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.7154220380823144
Starting Client training for 10 epochs
Epoch 1: train loss 0.011036726646125317, accuracy: 96.04%
Epoch 1: train loss 0.01090569794178009, accuracy: 96.39%
Epoch 1: train loss 0.022608017548918724, accuracy: 58.98%
Epoch 1: train loss 0.010706963017582893, accuracy: 97.07%
Epoch 1: train loss 0.00994144007563591, accuracy: 99.5%
Epoch 2: train loss 0.010493696667253971, accuracy: 97.79%
Epoch 2: train loss 0.010660060681402683, accuracy: 97.15%
Epoch 1: train loss 0.010977132245898247, accuracy: 96.2%
Epoch 2: train loss 0.019460404291749, accuracy: 69.13%
Epoch 3: train loss 0.01046607457101345, accuracy: 97.81%
Epoch 3: train loss 0.010608491487801075, accuracy: 97.33%
Epoch 2: train loss 0.009800913743674755, accuracy: 99.97%
Epoch 2: train loss 0.009987733326852322, accuracy: 99.37%
Epoch 3: train loss 0.0145639693364501, accuracy: 84.66%
Epoch 4: train loss 0.010460254736244678, accuracy: 97.91%
Epoch 1: train loss 0.011066164821386337, accuracy: 95.95%
Epoch 4: train loss 0.01050893310457468, accuracy: 97.66%
Epoch 3: train loss 0.009974991902709007, accuracy: 99.4%
Epoch 5: train loss 0.010436303913593292, accuracy: 97.96%
Epoch 3: train loss 0.009793145582079887, accuracy: 99.99%
Epoch 5: train loss 0.010379352606832981, accuracy: 98.04%
Epoch 4: train loss 0.012049379758536816, accuracy: 92.7%
Epoch 2: train loss 0.01080723199993372, accuracy: 96.75%
Epoch 6: train loss 0.010419475845992565, accuracy: 97.96%
Epoch 6: train loss 0.010369482450187206, accuracy: 98.14%
Epoch 4: train loss 0.009967696852982044, accuracy: 99.44%
Epoch 4: train loss 0.009792692959308624, accuracy: 99.99%
Epoch 5: train loss 0.011746627278625965, accuracy: 93.74%
Epoch 7: train loss 0.010414071381092072, accuracy: 97.94%
Epoch 7: train loss 0.010328997857868671, accuracy: 98.23%
Epoch 8: train loss 0.010412427596747875, accuracy: 97.99%
Epoch 6: train loss 0.011565866880118847, accuracy: 94.32%
Epoch 2: train loss 0.011046805419027805, accuracy: 95.98%
Epoch 5: train loss 0.009967020712792873, accuracy: 99.43%
Epoch 3: train loss 0.010784751735627651, accuracy: 96.77%
Epoch 5: train loss 0.009792680852115154, accuracy: 99.99%
Epoch 8: train loss 0.010313286446034908, accuracy: 98.3%
Epoch 9: train loss 0.010411842726171017, accuracy: 97.97%
Epoch 7: train loss 0.011555210687220097, accuracy: 94.36%
Epoch 9: train loss 0.01028827577829361, accuracy: 98.36%
Epoch 6: train loss 0.00996459648013115, accuracy: 99.43%
Epoch 6: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 8: train loss 0.01155045721679926, accuracy: 94.37%
Epoch 4: train loss 0.01076104212552309, accuracy: 96.83%
Epoch 7: train loss 0.009965498000383377, accuracy: 99.44%
Epoch 7: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 9: train loss 0.011537168174982071, accuracy: 94.41%
Epoch 3: train loss 0.010980228893458843, accuracy: 96.2%
Epoch 8: train loss 0.009967622347176075, accuracy: 99.43%
Epoch 8: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 5: train loss 0.010753035545349121, accuracy: 96.94%
Epoch 9: train loss 0.009972273372113705, accuracy: 99.4%
Epoch 9: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 6: train loss 0.010745815001428127, accuracy: 96.97%
Epoch 4: train loss 0.010934008285403252, accuracy: 96.36%
Epoch 7: train loss 0.010741335339844227, accuracy: 96.96%
Epoch 5: train loss 0.010942239314317703, accuracy: 96.31%
Epoch 8: train loss 0.010728197172284126, accuracy: 96.98%
Epoch 9: train loss 0.010709830559790134, accuracy: 97.05%
Epoch 6: train loss 0.010926256887614727, accuracy: 96.37%
Epoch 7: train loss 0.010946257971227169, accuracy: 96.29%
Epoch 8: train loss 0.010921449400484562, accuracy: 96.39%
Epoch 9: train loss 0.010913887992501259, accuracy: 96.42%
Epoch 10: train loss 0.00979266781359911, accuracy: 99.99%
Epoch 10: train loss 0.010398011654615402, accuracy: 97.99%
Epoch 10: train loss 0.009968506172299385, accuracy: 99.41%
Epoch 10: train loss 0.01153357233852148, accuracy: 94.42%
Epoch 10: train loss 0.010924519039690495, accuracy: 96.37%
Epoch 10: train loss 0.011172777973115444, accuracy: 95.58%
Epoch 10: train loss 0.010285137221217155, accuracy: 98.43%
Acurácia do Cliente: 1 eh: 0.9690296248121818
Acurácia do Cliente: 4 eh: 0.9863825790925632
Acurácia do Cliente: 2 eh: 0.6448441627809617
Acurácia do Cliente: 3 eh: 0.9959114375801255
Acurácia do Cliente: 6 eh: 0.9887458123953099
Acurácia do Cliente: 7 eh: 0.417718715393134
Acurácia do Cliente: 5 eh: 0.4410584005305966
