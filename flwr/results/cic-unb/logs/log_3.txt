INFO flwr 2023-11-03 21:49:42,736 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=4, round_timeout=None)
INFO flwr 2023-11-03 21:49:42,744 | app.py:175 | Flower ECE: gRPC server running (4 rounds), SSL is disabled
INFO flwr 2023-11-03 21:49:42,744 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-03 21:49:42,744 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-03 21:49:56,269 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-03 21:49:56,269 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:51,  1.96it/s] 11%|█         | 149/1394 [00:00<00:03, 324.47it/s] 22%|██▏       | 300/1394 [00:00<00:01, 605.76it/s] 32%|███▏      | 449/1394 [00:00<00:01, 829.29it/s] 41%|████▏     | 578/1394 [00:00<00:00, 852.65it/s] 50%|████▉     | 693/1394 [00:01<00:00, 872.35it/s] 61%|██████    | 845/1394 [00:01<00:00, 1036.61it/s] 69%|██████▉   | 967/1394 [00:01<00:00, 1041.01it/s] 80%|████████  | 1121/1394 [00:01<00:00, 1174.15it/s] 92%|█████████▏| 1286/1394 [00:01<00:00, 1305.21it/s]100%|██████████| 1394/1394 [00:01<00:00, 892.10it/s] 
INFO flwr 2023-11-03 21:50:05,630 | server.py:94 | initial parameters (loss, other metrics): 1067.582065820694, {'accuracy': 0.400215290080958}
INFO flwr 2023-11-03 21:50:05,630 | server.py:104 | FL starting
DEBUG flwr 2023-11-03 21:50:05,630 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 21:59:32,881 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 21:59:32,889 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1067.582065820694 / accuracy 0.400215290080958
  0%|          | 0/1394 [00:00<?, ?it/s] 11%|█▏        | 160/1394 [00:00<00:00, 1598.95it/s] 23%|██▎       | 325/1394 [00:00<00:00, 1628.90it/s] 35%|███▌      | 489/1394 [00:00<00:00, 1633.50it/s] 47%|████▋     | 654/1394 [00:00<00:00, 1639.25it/s] 59%|█████▊    | 818/1394 [00:00<00:00, 1637.48it/s] 70%|███████   | 982/1394 [00:00<00:00, 1635.41it/s] 82%|████████▏ | 1146/1394 [00:00<00:00, 1636.85it/s] 94%|█████████▍| 1312/1394 [00:00<00:00, 1643.83it/s]100%|██████████| 1394/1394 [00:00<00:00, 1638.10it/s]
INFO flwr 2023-11-03 21:59:37,985 | server.py:125 | fit progress: (1, 693.2426309883595, {'accuracy': 0.8156578681796776}, 572.3542695859796)
DEBUG flwr 2023-11-03 21:59:37,985 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 21:59:40,433 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 21:59:40,433 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-03 21:59:40,433 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 22:09:08,389 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 693.2426309883595 / accuracy 0.8156578681796776
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 162/1394 [00:00<00:00, 1614.28it/s] 24%|██▎       | 328/1394 [00:00<00:00, 1637.84it/s] 35%|███▌      | 492/1394 [00:00<00:00, 1638.57it/s] 47%|████▋     | 658/1394 [00:00<00:00, 1645.02it/s] 59%|█████▉    | 823/1394 [00:00<00:00, 1644.73it/s] 71%|███████   | 988/1394 [00:00<00:00, 1646.48it/s] 83%|████████▎ | 1154/1394 [00:00<00:00, 1647.91it/s] 95%|█████████▍| 1320/1394 [00:00<00:00, 1650.05it/s]100%|██████████| 1394/1394 [00:00<00:00, 1645.13it/s]
INFO flwr 2023-11-03 22:09:13,157 | server.py:125 | fit progress: (2, 479.85463443398476, {'accuracy': 0.9690520508622816}, 1147.526408487989)
DEBUG flwr 2023-11-03 22:09:13,157 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 22:09:15,616 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
DEBUG flwr 2023-11-03 22:09:15,616 | server.py:222 | fit_round 3: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 22:18:40,619 | server.py:236 | fit_round 3 received 7 results and 0 failures
Server-side evaluation loss 479.85463443398476 / accuracy 0.9690520508622816
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 166/1394 [00:00<00:00, 1656.15it/s] 24%|██▍       | 332/1394 [00:00<00:00, 1658.08it/s] 36%|███▌      | 499/1394 [00:00<00:00, 1663.23it/s] 48%|████▊     | 666/1394 [00:00<00:00, 1663.82it/s] 60%|█████▉    | 833/1394 [00:00<00:00, 1663.29it/s] 72%|███████▏  | 1000/1394 [00:00<00:00, 1660.81it/s] 84%|████████▎ | 1167/1394 [00:00<00:00, 1658.40it/s] 96%|█████████▌| 1334/1394 [00:00<00:00, 1659.32it/s]100%|██████████| 1394/1394 [00:00<00:00, 1660.28it/s]
INFO flwr 2023-11-03 22:18:45,124 | server.py:125 | fit progress: (3, 479.86645436286926, {'accuracy': 0.9690071987620821}, 1719.4936366739566)
DEBUG flwr 2023-11-03 22:18:45,124 | server.py:173 | evaluate_round 3: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 22:18:47,597 | server.py:187 | evaluate_round 3 received 7 results and 0 failures
DEBUG flwr 2023-11-03 22:18:47,597 | server.py:222 | fit_round 4: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 22:28:14,293 | server.py:236 | fit_round 4 received 7 results and 0 failures
Server-side evaluation loss 479.86645436286926 / accuracy 0.9690071987620821
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 165/1394 [00:00<00:00, 1643.24it/s] 24%|██▎       | 331/1394 [00:00<00:00, 1647.43it/s] 36%|███▌      | 496/1394 [00:00<00:00, 1644.84it/s] 47%|████▋     | 661/1394 [00:00<00:00, 1644.86it/s] 59%|█████▉    | 826/1394 [00:00<00:00, 1642.76it/s] 71%|███████   | 991/1394 [00:00<00:00, 1642.80it/s] 83%|████████▎ | 1156/1394 [00:00<00:00, 1644.51it/s] 95%|█████████▍| 1322/1394 [00:00<00:00, 1648.38it/s]100%|██████████| 1394/1394 [00:00<00:00, 1645.25it/s]
INFO flwr 2023-11-03 22:28:18,877 | server.py:125 | fit progress: (4, 481.82841968536377, {'accuracy': 0.9673476710546971}, 2293.246253616002)
DEBUG flwr 2023-11-03 22:28:18,877 | server.py:173 | evaluate_round 4: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 22:28:21,376 | server.py:187 | evaluate_round 4 received 7 results and 0 failures
INFO flwr 2023-11-03 22:28:21,376 | server.py:153 | FL finished in 2295.745687655988
INFO flwr 2023-11-03 22:28:21,376 | app.py:225 | app_fit: losses_distributed [(1, 697.6438943715972), (2, 719.5336018301829), (3, 745.4363041655723), (4, 745.1560988923219)]
INFO flwr 2023-11-03 22:28:21,376 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-03 22:28:21,376 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-03 22:28:21,376 | app.py:228 | app_fit: losses_centralized [(0, 1067.582065820694), (1, 693.2426309883595), (2, 479.85463443398476), (3, 479.86645436286926), (4, 481.82841968536377)]
INFO flwr 2023-11-03 22:28:21,376 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.400215290080958), (1, 0.8156578681796776), (2, 0.9690520508622816), (3, 0.9690071987620821), (4, 0.9673476710546971)]}
Server-side evaluation loss 481.82841968536377 / accuracy 0.9673476710546971
99.99%
Epoch 5: train loss 0.010424922220408916, accuracy: 97.99%
Epoch 5: train loss 0.010414192453026772, accuracy: 97.96%
Epoch 2: train loss 0.010788070037961006, accuracy: 96.82%
Epoch 4: train loss 0.011552384123206139, accuracy: 94.38%
Epoch 6: train loss 0.010410245507955551, accuracy: 98.0%
Epoch 6: train loss 0.010381064377725124, accuracy: 98.13%
Epoch 4: train loss 0.010349765419960022, accuracy: 98.22%
Epoch 4: train loss 0.009792696684598923, accuracy: 99.99%
Epoch 7: train loss 0.010420139878988266, accuracy: 97.96%
Epoch 5: train loss 0.011545847170054913, accuracy: 94.4%
Epoch 7: train loss 0.010238026268780231, accuracy: 98.57%
Epoch 5: train loss 0.01031830906867981, accuracy: 98.28%
Epoch 8: train loss 0.010416154749691486, accuracy: 98.0%
Epoch 3: train loss 0.0107829999178648, accuracy: 96.83%
Epoch 8: train loss 0.010225322097539902, accuracy: 98.59%
Epoch 2: train loss 0.010994832031428814, accuracy: 96.16%
Epoch 5: train loss 0.009792563505470753, accuracy: 99.99%
Epoch 6: train loss 0.011540262028574944, accuracy: 94.4%
Epoch 9: train loss 0.010391086339950562, accuracy: 98.02%
Epoch 9: train loss 0.010221635922789574, accuracy: 98.6%
Epoch 6: train loss 0.010301807895302773, accuracy: 98.37%
Epoch 7: train loss 0.011536974459886551, accuracy: 94.42%
Epoch 6: train loss 0.00979254674166441, accuracy: 99.99%
Epoch 4: train loss 0.010771981440484524, accuracy: 96.87%
Epoch 8: train loss 0.011535492725670338, accuracy: 94.42%
Epoch 7: train loss 0.01030701119452715, accuracy: 98.34%
Epoch 7: train loss 0.00979254674166441, accuracy: 99.99%
Epoch 3: train loss 0.010961312800645828, accuracy: 96.25%
Epoch 9: train loss 0.01153397373855114, accuracy: 94.44%
Epoch 8: train loss 0.010293140076100826, accuracy: 98.4%
Epoch 8: train loss 0.00979254674166441, accuracy: 99.99%
Epoch 5: train loss 0.010721498169004917, accuracy: 97.02%
Epoch 9: train loss 0.010291075333952904, accuracy: 98.43%
Epoch 9: train loss 0.00979254674166441, accuracy: 99.99%
Epoch 6: train loss 0.010663194581866264, accuracy: 97.14%
Epoch 4: train loss 0.010945328511297703, accuracy: 96.33%
Epoch 7: train loss 0.010654228739440441, accuracy: 97.19%
Epoch 5: train loss 0.010937275364995003, accuracy: 96.34%
Epoch 8: train loss 0.01065659150481224, accuracy: 97.25%
Epoch 9: train loss 0.01064974069595337, accuracy: 97.27%
Epoch 6: train loss 0.01092921756207943, accuracy: 96.37%
Epoch 7: train loss 0.010926630347967148, accuracy: 96.38%
Epoch 8: train loss 0.010913732461631298, accuracy: 96.4%
Epoch 9: train loss 0.010943369008600712, accuracy: 96.3%
Epoch 10: train loss 0.011001179926097393, accuracy: 96.14%
Epoch 10: train loss 0.011528866365551949, accuracy: 94.44%
Epoch 10: train loss 0.010648303665220737, accuracy: 97.25%
Epoch 10: train loss 0.010217777453362942, accuracy: 98.64%
Epoch 10: train loss 0.00979254674166441, accuracy: 99.99%
Epoch 10: train loss 0.010247847065329552, accuracy: 98.54%
Epoch 10: train loss 0.010283227078616619, accuracy: 98.42%
Acurácia do Cliente: 4 eh: 0.987967365146446
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.9666038525963149
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9949759190603236
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.9693211634634792
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.6575478916140953
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.5676633444075304
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.5727650364785143
Starting Client training for 10 epochs
Epoch 1: train loss 0.011108576320111752, accuracy: 95.77%
Epoch 1: train loss 0.010765946470201015, accuracy: 96.83%
Epoch 1: train loss 0.020449867472052574, accuracy: 65.84%
Epoch 1: train loss 0.011144274845719337, accuracy: 95.69%
Epoch 1: train loss 0.009946849197149277, accuracy: 99.47%
Epoch 2: train loss 0.010534439235925674, accuracy: 97.55%
Epoch 2: train loss 0.010561161674559116, accuracy: 97.47%
Epoch 2: train loss 0.019603382796049118, accuracy: 68.6%
Epoch 1: train loss 0.011146643199026585, accuracy: 95.67%
Epoch 3: train loss 0.010443923063576221, accuracy: 97.91%
Epoch 3: train loss 0.010522283613681793, accuracy: 97.59%
Epoch 2: train loss 0.010226394049823284, accuracy: 98.62%
Epoch 2: train loss 0.009795274585485458, accuracy: 99.98%
Epoch 1: train loss 0.011121605522930622, accuracy: 95.76%
Epoch 4: train loss 0.010433097369968891, accuracy: 97.9%
Epoch 3: train loss 0.01757640950381756, accuracy: 74.97%
Epoch 4: train loss 0.010464628227055073, accuracy: 97.8%
Epoch 3: train loss 0.01008144486695528, accuracy: 99.05%
Epoch 5: train loss 0.010432358831167221, accuracy: 97.95%
Epoch 3: train loss 0.009793941862881184, accuracy: 99.98%
Epoch 5: train loss 0.01027720421552658, accuracy: 98.37%
Epoch 2: train loss 0.010806781239807606, accuracy: 96.75%
Epoch 4: train loss 0.013585835695266724, accuracy: 87.87%
Epoch 6: train loss 0.010417669080197811, accuracy: 97.93%
Epoch 6: train loss 0.010241503827273846, accuracy: 98.53%
Epoch 4: train loss 0.010066749528050423, accuracy: 99.11%
Epoch 4: train loss 0.009793519042432308, accuracy: 99.98%
Epoch 7: train loss 0.01042463444173336, accuracy: 97.98%
Epoch 5: train loss 0.011894029565155506, accuracy: 93.28%
Epoch 7: train loss 0.010224159806966782, accuracy: 98.59%
Epoch 8: train loss 0.01040438748896122, accuracy: 97.95%
Epoch 2: train loss 0.010950851254165173, accuracy: 96.29%
Epoch 3: train loss 0.010777538642287254, accuracy: 96.79%
Epoch 5: train loss 0.010060899890959263, accuracy: 99.12%
Epoch 6: train loss 0.011707661673426628, accuracy: 93.87%
Epoch 8: train loss 0.010210350155830383, accuracy: 98.63%
Epoch 5: train loss 0.009793873876333237, accuracy: 99.98%
Epoch 9: train loss 0.010413382202386856, accuracy: 97.97%
Epoch 9: train loss 0.010206369683146477, accuracy: 98.67%
Epoch 7: train loss 0.011676118709146976, accuracy: 93.97%
Epoch 6: train loss 0.010052504017949104, accuracy: 99.14%
Epoch 6: train loss 0.00979459285736084, accuracy: 99.98%
Epoch 4: train loss 0.010744976811110973, accuracy: 96.94%
Epoch 8: train loss 0.011647031642496586, accuracy: 94.07%
Epoch 7: train loss 0.010042788460850716, accuracy: 99.18%
Epoch 7: train loss 0.009795795194804668, accuracy: 99.98%
Epoch 3: train loss 0.0109205711632967, accuracy: 96.39%
Epoch 9: train loss 0.01163187250494957, accuracy: 94.12%
Epoch 8: train loss 0.010041436180472374, accuracy: 99.2%
Epoch 8: train loss 0.009794351644814014, accuracy: 99.98%
Epoch 5: train loss 0.010714503936469555, accuracy: 97.05%
Epoch 9: train loss 0.01004645973443985, accuracy: 99.18%
Epoch 9: train loss 0.009795434772968292, accuracy: 99.98%
Epoch 6: train loss 0.010654221288859844, accuracy: 97.23%
Epoch 4: train loss 0.010919366031885147, accuracy: 96.4%
Epoch 7: train loss 0.010628930293023586, accuracy: 97.31%
Epoch 5: train loss 0.010923138819634914, accuracy: 96.39%
Epoch 8: train loss 0.010627660900354385, accuracy: 97.31%
Epoch 9: train loss 0.010630744509398937, accuracy: 97.32%
Epoch 6: train loss 0.010892796330153942, accuracy: 96.48%
Epoch 7: train loss 0.010913537815213203, accuracy: 96.42%
Epoch 8: train loss 0.010897273197770119, accuracy: 96.45%
Epoch 9: train loss 0.010893082246184349, accuracy: 96.49%
Epoch 10: train loss 0.0100476685911417, accuracy: 99.18%
Epoch 10: train loss 0.010419296100735664, accuracy: 97.98%
Epoch 10: train loss 0.01089148223400116, accuracy: 96.48%
Epoch 10: train loss 0.010627730749547482, accuracy: 97.31%
Epoch 10: train loss 0.011619866825640202, accuracy: 94.14%
Epoch 10: train loss 0.00979447178542614, accuracy: 99.98%
Epoch 10: train loss 0.010190480388700962, accuracy: 98.72%
Acurácia do Cliente: 6 eh: 0.9905255443886097
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.4470625196355639
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9886130187239538
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.42724252491694353
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.969679980265076
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.9990991303142649
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.6538522614080928
Starting Client training for 10 epochs
Epoch 1: train loss 0.010416296310722828, accuracy: 97.94%
Epoch 1: train loss 0.010325650684535503, accuracy: 98.23%
Epoch 1: train loss 0.026210512965917587, accuracy: 47.68%
Epoch 1: train loss 0.009822613559663296, accuracy: 99.88%
Epoch 1: train loss 0.013308573514223099, accuracy: 88.74%
Epoch 2: train loss 0.010310783982276917, accuracy: 98.27%
Epoch 2: train loss 0.010252181440591812, accuracy: 98.47%
Epoch 1: train loss 0.010753228329122066, accuracy: 96.89%
Epoch 2: train loss 0.02603384293615818, accuracy: 48.13%
Epoch 3: train loss 0.01026084553450346, accuracy: 98.45%
Epoch 3: train loss 0.010241556912660599, accuracy: 98.54%
Epoch 2: train loss 0.00979605596512556, accuracy: 99.98%
Epoch 2: train loss 0.012305233627557755, accuracy: 91.95%
Epoch 4: train loss 0.01024756208062172, accuracy: 98.47%
Epoch 1: train loss 0.011258559301495552, accuracy: 95.32%
Epoch 3: train loss 0.025869525969028473, accuracy: 48.5%
Epoch 4: train loss 0.010214329697191715, accuracy: 98.56%
Epoch 3: train loss 0.00979488156735897, accuracy: 99.98%
Epoch 3: train loss 0.012242712080478668, accuracy: 92.15%
Epoch 5: train loss 0.010244257748126984, accuracy: 98.5%
Epoch 5: train loss 0.010212224908173084, accuracy: 98.6%
Epoch 2: train loss 0.010642411187291145, accuracy: 97.24%
Epoch 4: train loss 0.024749241769313812, accuracy: 52.17%
Epoch 6: train loss 0.010248830541968346, accuracy: 98.5%
Epoch 6: train loss 0.010204165242612362, accuracy: 98.61%
Epoch 4: train loss 0.009794002398848534, accuracy: 99.98%
Epoch 4: train loss 0.012178490869700909, accuracy: 92.37%
Epoch 5: train loss 0.021643543615937233, accuracy: 62.04%
Epoch 7: train loss 0.010237568989396095, accuracy: 98.58%
Epoch 7: train loss 0.010190089233219624, accuracy: 98.67%
Epoch 5: train loss 0.009794231504201889, accuracy: 99.98%
Epoch 3: train loss 0.010640357621014118, accuracy: 97.3%
Epoch 8: train loss 0.010238059796392918, accuracy: 98.62%
Epoch 6: train loss 0.019950363785028458, accuracy: 67.4%
Epoch 2: train loss 0.010965601541101933, accuracy: 96.25%
Epoch 5: train loss 0.012066034600138664, accuracy: 92.74%
Epoch 8: train loss 0.010189024731516838, accuracy: 98.67%
Epoch 9: train loss 0.01022028736770153, accuracy: 98.66%
Epoch 7: train loss 0.0188284981995821, accuracy: 71.21%
Epoch 9: train loss 0.010179071687161922, accuracy: 98.7%
Epoch 6: train loss 0.009795073419809341, accuracy: 99.98%
Epoch 6: train loss 0.01212112046778202, accuracy: 92.51%
Epoch 4: train loss 0.010633409023284912, accuracy: 97.31%
Epoch 8: train loss 0.013167962431907654, accuracy: 89.15%
Epoch 7: train loss 0.009793871082365513, accuracy: 99.98%
Epoch 7: train loss 0.012115496210753918, accuracy: 92.55%
Epoch 9: train loss 0.01196233183145523, accuracy: 93.06%
Epoch 3: train loss 0.010935486294329166, accuracy: 96.35%
Epoch 8: train loss 0.009794111363589764, accuracy: 99.98%
Epoch 8: train loss 0.012113264761865139, accuracy: 92.58%
Epoch 5: train loss 0.010634402744472027, accuracy: 97.31%
Epoch 9: train loss 0.00979447178542614, accuracy: 99.99%
Epoch 9: train loss 0.012053475715219975, accuracy: 92.77%
Epoch 4: train loss 0.010930552147328854, accuracy: 96.36%
Epoch 6: train loss 0.010629947297275066, accuracy: 97.31%
Epoch 7: train loss 0.010631230659782887, accuracy: 97.3%
Epoch 5: train loss 0.010901442728936672, accuracy: 96.45%
Epoch 8: train loss 0.010630701668560505, accuracy: 97.32%
Epoch 9: train loss 0.01063265185803175, accuracy: 97.31%
Epoch 6: train loss 0.01090594194829464, accuracy: 96.43%
Epoch 7: train loss 0.010890373028814793, accuracy: 96.49%
Epoch 8: train loss 0.010898664593696594, accuracy: 96.47%
Epoch 9: train loss 0.010888192802667618, accuracy: 96.49%
Epoch 10: train loss 0.009793871082365513, accuracy: 99.98%
Epoch 10: train loss 0.010628610849380493, accuracy: 97.31%
Epoch 10: train loss 0.011923843994736671, accuracy: 93.19%
Epoch 10: train loss 0.010895416140556335, accuracy: 96.47%
Epoch 10: train loss 0.010210399515926838, accuracy: 98.67%
Epoch 10: train loss 0.010177924297749996, accuracy: 98.7%
Epoch 10: train loss 0.012012009508907795, accuracy: 92.89%
Acurácia do Cliente: 2 eh: 0.6543575233503197
Acurácia do Cliente: 4 eh: 0.9886130187239538
Acurácia do Cliente: 6 eh: 0.990002093802345
Acurácia do Cliente: 3 eh: 0.9978517722878625
Acurácia do Cliente: 7 eh: 0.42223698781838315
Acurácia do Cliente: 5 eh: 0.4470625196355639
Acurácia do Cliente: 1 eh: 0.9697696844654751
