INFO flwr 2023-10-09 18:40:57,192 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=3, round_timeout=None)
INFO flwr 2023-10-09 18:40:57,215 | app.py:175 | Flower ECE: gRPC server running (3 rounds), SSL is disabled
INFO flwr 2023-10-09 18:40:57,215 | server.py:89 | Initializing global parameters
INFO flwr 2023-10-09 18:40:57,215 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-10-09 18:40:58,663 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-10-09 18:40:58,663 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1804 [00:00<?, ?it/s]  0%|          | 1/1804 [00:00<18:26,  1.63it/s]  5%|▌         | 91/1804 [00:00<00:10, 171.18it/s] 10%|▉         | 180/1804 [00:00<00:05, 323.09it/s] 15%|█▍        | 270/1804 [00:00<00:03, 455.99it/s] 20%|█▉        | 360/1804 [00:01<00:02, 565.21it/s] 25%|██▌       | 451/1804 [00:01<00:02, 655.31it/s] 30%|███       | 542/1804 [00:01<00:01, 723.03it/s] 35%|███▍      | 631/1804 [00:01<00:01, 768.90it/s] 40%|███▉      | 719/1804 [00:01<00:01, 797.09it/s] 45%|████▍     | 808/1804 [00:01<00:01, 823.40it/s] 50%|████▉     | 898/1804 [00:01<00:01, 843.48it/s] 55%|█████▍    | 990/1804 [00:01<00:00, 863.43it/s] 60%|█████▉    | 1080/1804 [00:01<00:00, 873.96it/s] 65%|██████▍   | 1170/1804 [00:01<00:00, 880.75it/s] 70%|██████▉   | 1261/1804 [00:02<00:00, 889.08it/s] 75%|███████▍  | 1352/1804 [00:02<00:00, 892.79it/s] 80%|███████▉  | 1442/1804 [00:02<00:00, 894.39it/s] 85%|████████▍ | 1532/1804 [00:02<00:00, 892.73it/s] 90%|████████▉ | 1623/1804 [00:02<00:00, 896.25it/s] 95%|█████████▌| 1714/1804 [00:02<00:00, 900.11it/s]100%|██████████| 1804/1804 [00:02<00:00, 685.85it/s]

### Server-side evaluation loss 1314.0884308815002 / accuracy 29.94% DatasetID 3 ###

  0%|          | 0/1065 [00:00<?, ?it/s]  8%|▊         | 89/1065 [00:00<00:01, 888.56it/s] 17%|█▋        | 178/1065 [00:00<00:00, 889.07it/s] 25%|██▌       | 268/1065 [00:00<00:00, 893.43it/s] 34%|███▎      | 358/1065 [00:00<00:00, 892.36it/s] 42%|████▏     | 449/1065 [00:00<00:00, 896.63it/s] 51%|█████     | 540/1065 [00:00<00:00, 897.98it/s] 59%|█████▉    | 631/1065 [00:00<00:00, 901.43it/s] 68%|██████▊   | 722/1065 [00:00<00:00, 901.75it/s] 76%|███████▋  | 813/1065 [00:00<00:00, 898.93it/s] 85%|████████▍ | 904/1065 [00:01<00:00, 901.50it/s] 93%|█████████▎| 995/1065 [00:01<00:00, 900.34it/s]100%|██████████| 1065/1065 [00:01<00:00, 897.72it/s]

### Server-side evaluation loss 816.2353565692902 / accuracy 34.92% DatasetID 4 ###

  0%|          | 0/1791 [00:00<?, ?it/s]  5%|▌         | 91/1791 [00:00<00:01, 900.29it/s] 10%|█         | 182/1791 [00:00<00:01, 905.21it/s] 15%|█▌        | 273/1791 [00:00<00:01, 897.69it/s] 20%|██        | 364/1791 [00:00<00:01, 902.47it/s] 25%|██▌       | 455/1791 [00:00<00:01, 900.48it/s] 31%|███       | 547/1791 [00:00<00:01, 903.39it/s] 36%|███▌      | 638/1791 [00:00<00:01, 903.96it/s] 41%|████      | 730/1791 [00:00<00:01, 906.73it/s] 46%|████▌     | 821/1791 [00:00<00:01, 903.46it/s] 51%|█████     | 912/1791 [00:01<00:00, 884.88it/s] 56%|█████▌    | 1001/1791 [00:01<00:00, 883.75it/s] 61%|██████    | 1091/1791 [00:01<00:00, 887.92it/s] 66%|██████▌   | 1183/1791 [00:01<00:00, 895.79it/s] 71%|███████   | 1274/1791 [00:01<00:00, 898.29it/s] 76%|███████▌  | 1365/1791 [00:01<00:00, 899.50it/s] 81%|████████▏ | 1456/1791 [00:01<00:00, 900.01it/s] 86%|████████▋ | 1547/1791 [00:01<00:00, 899.77it/s] 92%|█████████▏| 1639/1791 [00:01<00:00, 903.26it/s] 97%|█████████▋| 1730/1791 [00:01<00:00, 902.72it/s]100%|██████████| 1791/1791 [00:01<00:00, 899.30it/s]
INFO flwr 2023-10-09 18:41:12,551 | server.py:94 | initial parameters (loss, other metrics): 1561.506001651287, {'accuracy': 41.89298703602361}
INFO flwr 2023-10-09 18:41:12,552 | server.py:104 | FL starting
Epoch 1: train loss 0.011008594185113907, accuracy: 97.95%
Epoch 1: train loss 0.010296257212758064, accuracy: 99.29%
Epoch 2: train loss 0.01031182985752821, accuracy: 98.62%
Epoch 2: train loss 0.009891760535538197, accuracy: 99.79%
Epoch 3: train loss 0.010254057124257088, accuracy: 98.68%
Epoch 3: train loss 0.0098679568618536, accuracy: 99.83%
Epoch 4: train loss 0.010233989916741848, accuracy: 98.7%
Epoch 4: train loss 0.009859379380941391, accuracy: 99.84%
Epoch 5: train loss 0.010188899002969265, accuracy: 98.83%
Epoch 5: train loss 0.009844683110713959, accuracy: 99.86%
Epoch 6: train loss 0.01013986300677061, accuracy: 98.96%
Epoch 6: train loss 0.009840239770710468, accuracy: 99.87%
Epoch 7: train loss 0.010134628042578697, accuracy: 98.98%
Epoch 7: train loss 0.009837491437792778, accuracy: 99.88%
Epoch 8: train loss 0.010134146548807621, accuracy: 99.01%
Epoch 8: train loss 0.009834335185587406, accuracy: 99.89%
Epoch 9: train loss 0.01011668611317873, accuracy: 99.01%
Epoch 9: train loss 0.00983158964663744, accuracy: 99.87%
Epoch 10: train loss 0.009832424111664295, accuracy: 99.89%
Epoch 10: train loss 0.010107667185366154, accuracy: 99.02%
Acurácia do Cliente: 5 eh: 0.48359339546898455
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.999844077545434
Starting Client training for 10 epochs
Epoch 1: train loss 0.010575183667242527, accuracy: 98.54%
Epoch 1: train loss 0.010035677812993526, accuracy: 99.38%
Epoch 2: train loss 0.010189891792833805, accuracy: 99.05%
Epoch 2: train loss 0.009969469159841537, accuracy: 99.49%
Epoch 3: train loss 0.010152650065720081, accuracy: 99.03%
Epoch 3: train loss 0.009944267570972443, accuracy: 99.53%
Epoch 4: train loss 0.010137788951396942, accuracy: 99.04%
Epoch 4: train loss 0.009929963387548923, accuracy: 99.57%
Epoch 5: train loss 0.01012963056564331, accuracy: 99.06%
Epoch 5: train loss 0.009919085539877415, accuracy: 99.6%
Epoch 6: train loss 0.010085051879286766, accuracy: 99.16%
Epoch 6: train loss 0.009911226108670235, accuracy: 99.61%
Epoch 7: train loss 0.0100797014310956, accuracy: 99.16%
Epoch 7: train loss 0.00991553533822298, accuracy: 99.61%
Epoch 8: train loss 0.010070476680994034, accuracy: 99.17%
Epoch 8: train loss 0.009908927604556084, accuracy: 99.64%
Epoch 9: train loss 0.010076399892568588, accuracy: 99.19%
Epoch 9: train loss 0.009903868660330772, accuracy: 99.66%
Epoch 10: train loss 0.010065881535410881, accuracy: 99.19%
Epoch 10: train loss 0.00990119855850935, accuracy: 99.66%
Acurácia do Cliente: 3 eh: 0.9983541518684708
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.8183055817363075
Starting Client training for 10 epochs
Epoch 1: train loss 0.010342572815716267, accuracy: 98.98%
Epoch 1: train loss 0.010110965929925442, accuracy: 99.07%
Epoch 2: train loss 0.010130169801414013, accuracy: 99.21%
Epoch 2: train loss 0.010023930110037327, accuracy: 99.3%
Epoch 3: train loss 0.01009946409612894, accuracy: 99.19%
Epoch 3: train loss 0.01001268345862627, accuracy: 99.35%
Epoch 4: train loss 0.010086667723953724, accuracy: 99.19%
Epoch 4: train loss 0.00999166164547205, accuracy: 99.39%
Epoch 5: train loss 0.010079357773065567, accuracy: 99.2%
Epoch 5: train loss 0.009983736090362072, accuracy: 99.42%
Epoch 6: train loss 0.010076784528791904, accuracy: 99.22%
Epoch 6: train loss 0.009967298246920109, accuracy: 99.4%
Epoch 7: train loss 0.010068157687783241, accuracy: 99.2%
Epoch 7: train loss 0.009975030086934566, accuracy: 99.41%
Epoch 8: train loss 0.010062731802463531, accuracy: 99.2%
Epoch 8: train loss 0.00997831393033266, accuracy: 99.45%
Epoch 9: train loss 0.01006239652633667, accuracy: 99.19%
Epoch 9: train loss 0.009962044656276703, accuracy: 99.43%
Epoch 10: train loss 0.010055871680378914, accuracy: 99.21%
Epoch 10: train loss 0.009958256036043167, accuracy: 99.48%
Acurácia do Cliente: 3 eh: 0.9997747786767381
Acurácia do Cliente: 5 eh: 0.8570880022340909
