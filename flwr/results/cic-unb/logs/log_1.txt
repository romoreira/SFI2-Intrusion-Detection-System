INFO flwr 2023-11-03 20:30:03,779 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=4, round_timeout=None)
INFO flwr 2023-11-03 20:30:03,787 | app.py:175 | Flower ECE: gRPC server running (4 rounds), SSL is disabled
INFO flwr 2023-11-03 20:30:03,787 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-03 20:30:03,787 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-03 20:30:16,502 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-03 20:30:16,502 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<11:41,  1.99it/s] 10%|█         | 145/1394 [00:00<00:03, 319.82it/s] 21%|██        | 294/1394 [00:00<00:01, 599.97it/s] 31%|███▏      | 439/1394 [00:00<00:01, 816.09it/s] 42%|████▏     | 579/1394 [00:00<00:00, 971.68it/s] 51%|█████     | 710/1394 [00:01<00:00, 985.71it/s] 60%|█████▉    | 831/1394 [00:01<00:00, 986.43it/s] 69%|██████▉   | 968/1394 [00:01<00:00, 1086.86it/s] 79%|███████▊  | 1096/1394 [00:01<00:00, 1136.43it/s] 89%|████████▊ | 1237/1394 [00:01<00:00, 1212.79it/s]100%|██████████| 1394/1394 [00:01<00:00, 897.11it/s] 
INFO flwr 2023-11-03 20:30:26,294 | server.py:94 | initial parameters (loss, other metrics): 1114.7186789512634, {'accuracy': 0.4106882554775627}
INFO flwr 2023-11-03 20:30:26,294 | server.py:104 | FL starting
DEBUG flwr 2023-11-03 20:30:26,294 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:39:49,784 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 20:39:49,792 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1114.7186789512634 / accuracy 0.4106882554775627
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 164/1394 [00:00<00:00, 1637.70it/s] 24%|██▎       | 328/1394 [00:00<00:00, 1638.67it/s] 35%|███▌      | 492/1394 [00:00<00:00, 1637.62it/s] 47%|████▋     | 657/1394 [00:00<00:00, 1640.34it/s] 59%|█████▉    | 822/1394 [00:00<00:00, 1636.78it/s] 71%|███████   | 987/1394 [00:00<00:00, 1639.31it/s] 83%|████████▎ | 1152/1394 [00:00<00:00, 1640.48it/s] 94%|█████████▍| 1317/1394 [00:00<00:00, 1638.79it/s]100%|██████████| 1394/1394 [00:00<00:00, 1638.46it/s]
INFO flwr 2023-11-03 20:39:54,688 | server.py:125 | fit progress: (1, 693.2825317084789, {'accuracy': 0.8157924244802763}, 568.3944213189825)
DEBUG flwr 2023-11-03 20:39:54,688 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:39:57,097 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-03 20:39:57,097 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-03 20:39:57,097 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:49:22,467 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 693.2825317084789 / accuracy 0.8157924244802763
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 168/1394 [00:00<00:00, 1671.16it/s] 24%|██▍       | 337/1394 [00:00<00:00, 1680.27it/s] 36%|███▋      | 506/1394 [00:00<00:00, 1680.99it/s] 48%|████▊     | 676/1394 [00:00<00:00, 1684.43it/s] 61%|██████    | 845/1394 [00:00<00:00, 1679.76it/s] 73%|███████▎  | 1015/1394 [00:00<00:00, 1685.98it/s] 85%|████████▌ | 1187/1394 [00:00<00:00, 1694.62it/s] 97%|█████████▋| 1358/1394 [00:00<00:00, 1698.70it/s]100%|██████████| 1394/1394 [00:00<00:00, 1690.06it/s]
INFO flwr 2023-11-03 20:49:27,302 | server.py:125 | fit progress: (2, 478.98790937662125, {'accuracy': 0.9696575542149761}, 1141.008349323005)
DEBUG flwr 2023-11-03 20:49:27,302 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:49:29,663 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
DEBUG flwr 2023-11-03 20:49:29,663 | server.py:222 | fit_round 3: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:59:03,210 | server.py:236 | fit_round 3 received 7 results and 0 failures
Server-side evaluation loss 478.98790937662125 / accuracy 0.9696575542149761
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 169/1394 [00:00<00:00, 1684.33it/s] 24%|██▍       | 340/1394 [00:00<00:00, 1697.48it/s] 37%|███▋      | 511/1394 [00:00<00:00, 1700.53it/s] 49%|████▉     | 682/1394 [00:00<00:00, 1700.22it/s] 61%|██████    | 853/1394 [00:00<00:00, 1699.71it/s] 73%|███████▎  | 1024/1394 [00:00<00:00, 1701.33it/s] 86%|████████▌ | 1195/1394 [00:00<00:00, 1700.58it/s] 98%|█████████▊| 1366/1394 [00:00<00:00, 1698.51it/s]100%|██████████| 1394/1394 [00:00<00:00, 1698.69it/s]
INFO flwr 2023-11-03 20:59:07,826 | server.py:125 | fit progress: (3, 480.318084448576, {'accuracy': 0.9687156601107847}, 1721.5317972170014)
DEBUG flwr 2023-11-03 20:59:07,826 | server.py:173 | evaluate_round 3: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 20:59:11,200 | server.py:187 | evaluate_round 3 received 7 results and 0 failures
DEBUG flwr 2023-11-03 20:59:11,200 | server.py:222 | fit_round 4: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 21:08:42,315 | server.py:236 | fit_round 4 received 7 results and 0 failures
Server-side evaluation loss 480.318084448576 / accuracy 0.9687156601107847
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 170/1394 [00:00<00:00, 1692.33it/s] 24%|██▍       | 340/1394 [00:00<00:00, 1690.48it/s] 37%|███▋      | 511/1394 [00:00<00:00, 1695.01it/s] 49%|████▉     | 681/1394 [00:00<00:00, 1693.93it/s] 61%|██████    | 852/1394 [00:00<00:00, 1696.41it/s] 73%|███████▎  | 1022/1394 [00:00<00:00, 1695.86it/s] 86%|████████▌ | 1193/1394 [00:00<00:00, 1697.68it/s] 98%|█████████▊| 1363/1394 [00:00<00:00, 1697.64it/s]100%|██████████| 1394/1394 [00:00<00:00, 1695.88it/s]
INFO flwr 2023-11-03 21:08:46,859 | server.py:125 | fit progress: (4, 481.6319079697132, {'accuracy': 0.967684061806194}, 2300.5650595859915)
DEBUG flwr 2023-11-03 21:08:46,859 | server.py:173 | evaluate_round 4: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-03 21:08:49,246 | server.py:187 | evaluate_round 4 received 7 results and 0 failures
INFO flwr 2023-11-03 21:08:49,246 | server.py:153 | FL finished in 2302.9522188720002
INFO flwr 2023-11-03 21:08:49,246 | app.py:225 | app_fit: losses_distributed [(1, 655.7524392980083), (2, 736.0997058675457), (3, 754.8568134476474), (4, 755.083790089152)]
INFO flwr 2023-11-03 21:08:49,246 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-03 21:08:49,246 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-03 21:08:49,246 | app.py:228 | app_fit: losses_centralized [(0, 1114.7186789512634), (1, 693.2825317084789), (2, 478.98790937662125), (3, 480.318084448576), (4, 481.6319079697132)]
INFO flwr 2023-11-03 21:08:49,246 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.4106882554775627), (1, 0.8157924244802763), (2, 0.9696575542149761), (3, 0.9687156601107847), (4, 0.967684061806194)]}
Server-side evaluation loss 481.6319079697132 / accuracy 0.967684061806194
, accuracy: 98.95%
Epoch 5: train loss 0.010439980775117874, accuracy: 97.9%
Epoch 4: train loss 0.015695953741669655, accuracy: 80.98%
Epoch 5: train loss 0.010155284777283669, accuracy: 98.84%
Epoch 2: train loss 0.012445046566426754, accuracy: 91.54%
Epoch 6: train loss 0.010239086113870144, accuracy: 98.58%
Epoch 6: train loss 0.010151115246117115, accuracy: 98.84%
Epoch 4: train loss 0.009794481098651886, accuracy: 99.98%
Epoch 5: train loss 0.011822414584457874, accuracy: 93.48%
Epoch 4: train loss 0.010032989084720612, accuracy: 99.24%
Epoch 7: train loss 0.010215912945568562, accuracy: 98.64%
Epoch 7: train loss 0.010144035331904888, accuracy: 98.87%
Epoch 6: train loss 0.011674543842673302, accuracy: 93.96%
Epoch 3: train loss 0.010604625567793846, accuracy: 97.41%
Epoch 5: train loss 0.009795508347451687, accuracy: 99.98%
Epoch 2: train loss 0.010975022800266743, accuracy: 96.22%
Epoch 8: train loss 0.010202620178461075, accuracy: 98.67%
Epoch 5: train loss 0.010030273348093033, accuracy: 99.24%
Epoch 8: train loss 0.0101420097053051, accuracy: 98.87%
Epoch 9: train loss 0.010203900747001171, accuracy: 98.68%
Epoch 7: train loss 0.011643906123936176, accuracy: 94.09%
Epoch 9: train loss 0.010141577571630478, accuracy: 98.88%
Epoch 6: train loss 0.00979451835155487, accuracy: 99.98%
Epoch 6: train loss 0.010022212751209736, accuracy: 99.27%
Epoch 8: train loss 0.01162315346300602, accuracy: 94.15%
Epoch 4: train loss 0.010593793354928493, accuracy: 97.43%
Epoch 7: train loss 0.009794695302844048, accuracy: 99.98%
Epoch 7: train loss 0.01001656986773014, accuracy: 99.27%
Epoch 9: train loss 0.011601711623370647, accuracy: 94.16%
Epoch 3: train loss 0.01094183512032032, accuracy: 96.32%
Epoch 8: train loss 0.00979405827820301, accuracy: 99.98%
Epoch 8: train loss 0.009999464266002178, accuracy: 99.31%
Epoch 5: train loss 0.010583530180156231, accuracy: 97.45%
Epoch 9: train loss 0.009793940000236034, accuracy: 99.98%
Epoch 9: train loss 0.010010303929448128, accuracy: 99.26%
Epoch 6: train loss 0.010586968623101711, accuracy: 97.45%
Epoch 4: train loss 0.010934542864561081, accuracy: 96.34%
Epoch 7: train loss 0.010529853403568268, accuracy: 97.62%
Epoch 5: train loss 0.010914815589785576, accuracy: 96.4%
Epoch 8: train loss 0.010506421327590942, accuracy: 97.71%
Epoch 9: train loss 0.010512424632906914, accuracy: 97.68%
Epoch 6: train loss 0.01093568280339241, accuracy: 96.35%
Epoch 7: train loss 0.010919461958110332, accuracy: 96.41%
Epoch 8: train loss 0.010915159247815609, accuracy: 96.41%
Epoch 9: train loss 0.010906381532549858, accuracy: 96.43%
Epoch 10: train loss 0.01159023679792881, accuracy: 94.23%
Epoch 10: train loss 0.010021359659731388, accuracy: 99.27%
Epoch 10: train loss 0.009793282486498356, accuracy: 99.98%
Epoch 10: train loss 0.010135550983250141, accuracy: 98.89%
Epoch 10: train loss 0.01019756868481636, accuracy: 98.69%
Epoch 10: train loss 0.010905141942203045, accuracy: 96.44%
Epoch 10: train loss 0.010510938242077827, accuracy: 97.7%
Acurácia do Cliente: 4 eh: 0.987556494688032
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.637698315312324
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.969455719764078
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.6034139700492198
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.9715242881072027
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.4474418604651163
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.997020200270261
Starting Client training for 10 epochs
Epoch 1: train loss 0.010339116677641869, accuracy: 98.2%
Epoch 1: train loss 0.01034561451524496, accuracy: 98.23%
Epoch 1: train loss 0.020082328468561172, accuracy: 67.03%
Epoch 1: train loss 0.009823660366237164, accuracy: 99.89%
Epoch 1: train loss 0.010587519034743309, accuracy: 97.49%
Epoch 2: train loss 0.010204034857451916, accuracy: 98.68%
Epoch 2: train loss 0.010243293829262257, accuracy: 98.53%
Epoch 2: train loss 0.01930820755660534, accuracy: 69.52%
Epoch 1: train loss 0.010753702372312546, accuracy: 96.93%
Epoch 3: train loss 0.010225050151348114, accuracy: 98.6%
Epoch 3: train loss 0.010182229802012444, accuracy: 98.73%
Epoch 2: train loss 0.010006684809923172, accuracy: 99.31%
Epoch 2: train loss 0.009797743521630764, accuracy: 99.97%
Epoch 3: train loss 0.016520904377102852, accuracy: 78.35%
Epoch 1: train loss 0.011073530651628971, accuracy: 95.92%
Epoch 4: train loss 0.010209289379417896, accuracy: 98.66%
Epoch 4: train loss 0.010176182724535465, accuracy: 98.76%
Epoch 3: train loss 0.009989511221647263, accuracy: 99.37%
Epoch 3: train loss 0.009795241989195347, accuracy: 99.97%
Epoch 5: train loss 0.010170498862862587, accuracy: 98.77%
Epoch 5: train loss 0.010206480510532856, accuracy: 98.65%
Epoch 4: train loss 0.01342224795371294, accuracy: 88.34%
Epoch 2: train loss 0.010604669339954853, accuracy: 97.39%
Epoch 6: train loss 0.01020861603319645, accuracy: 98.66%
Epoch 6: train loss 0.010164144448935986, accuracy: 98.8%
Epoch 4: train loss 0.009795375168323517, accuracy: 99.98%
Epoch 4: train loss 0.00998595915734768, accuracy: 99.37%
Epoch 5: train loss 0.012755751609802246, accuracy: 90.51%
Epoch 7: train loss 0.010206473991274834, accuracy: 98.66%
Epoch 7: train loss 0.010157481767237186, accuracy: 98.8%
Epoch 6: train loss 0.012682122178375721, accuracy: 90.79%
Epoch 2: train loss 0.01100908499211073, accuracy: 96.08%
Epoch 8: train loss 0.010205992497503757, accuracy: 98.66%
Epoch 5: train loss 0.009794417768716812, accuracy: 99.98%
Epoch 3: train loss 0.0105978362262249, accuracy: 97.41%
Epoch 5: train loss 0.009980572387576103, accuracy: 99.4%
Epoch 8: train loss 0.010159552097320557, accuracy: 98.82%
Epoch 9: train loss 0.010205988772213459, accuracy: 98.67%
Epoch 7: train loss 0.012187338434159756, accuracy: 92.35%
Epoch 9: train loss 0.010158522054553032, accuracy: 98.83%
Epoch 6: train loss 0.00979433860629797, accuracy: 99.98%
Epoch 6: train loss 0.009983555413782597, accuracy: 99.39%
Epoch 8: train loss 0.011966883204877377, accuracy: 93.06%
Epoch 4: train loss 0.010595410130918026, accuracy: 97.42%
Epoch 7: train loss 0.009793994016945362, accuracy: 99.98%
Epoch 7: train loss 0.009981280192732811, accuracy: 99.37%
Epoch 9: train loss 0.01181106735020876, accuracy: 93.53%
Epoch 3: train loss 0.011020728386938572, accuracy: 96.06%
Epoch 8: train loss 0.009793721139431, accuracy: 99.99%
Epoch 8: train loss 0.009982261806726456, accuracy: 99.38%
Epoch 5: train loss 0.010579017922282219, accuracy: 97.47%
Epoch 9: train loss 0.009793497622013092, accuracy: 99.99%
Epoch 9: train loss 0.009976629167795181, accuracy: 99.39%
Epoch 4: train loss 0.010967670939862728, accuracy: 96.25%
Epoch 6: train loss 0.010575718246400356, accuracy: 97.49%
Epoch 7: train loss 0.01057118084281683, accuracy: 97.5%
Epoch 5: train loss 0.01085709035396576, accuracy: 96.6%
Epoch 8: train loss 0.01056185644119978, accuracy: 97.53%
Epoch 6: train loss 0.01077626459300518, accuracy: 96.86%
Epoch 9: train loss 0.010525310412049294, accuracy: 97.64%
Epoch 7: train loss 0.01081203855574131, accuracy: 96.75%
Epoch 8: train loss 0.01083914004266262, accuracy: 96.66%
Epoch 9: train loss 0.010816010646522045, accuracy: 96.71%
Epoch 10: train loss 0.010793534107506275, accuracy: 96.8%
Epoch 10: train loss 0.009793173521757126, accuracy: 99.99%
Epoch 10: train loss 0.009992758743464947, accuracy: 99.35%
Epoch 10: train loss 0.010157722048461437, accuracy: 98.84%
Epoch 10: train loss 0.010204434394836426, accuracy: 98.67%
Epoch 10: train loss 0.011668604798614979, accuracy: 93.95%
Epoch 10: train loss 0.010494952090084553, accuracy: 97.74%
Acurácia do Cliente: 3 eh: 0.9968123072658605
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.4317607973421927
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.6376261350348631
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.9891122278056952
Starting Client training for 10 epochs
Acurácia do Cliente: 5 eh: 0.4524383006946626
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.9882021482655398
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.9695229979143773
Starting Client training for 10 epochs
Epoch 1: train loss 0.01026135217398405, accuracy: 98.5%
Epoch 1: train loss 0.010214271023869514, accuracy: 98.64%
Epoch 1: train loss 0.02738199755549431, accuracy: 43.69%
Epoch 1: train loss 0.009833268821239471, accuracy: 99.84%
Epoch 1: train loss 0.010889478027820587, accuracy: 96.47%
Epoch 2: train loss 0.010232910513877869, accuracy: 98.56%
Epoch 2: train loss 0.010193033143877983, accuracy: 98.7%
Epoch 1: train loss 0.010774552822113037, accuracy: 96.86%
Epoch 2: train loss 0.02542160265147686, accuracy: 49.89%
Epoch 3: train loss 0.010216162540018559, accuracy: 98.64%
Epoch 3: train loss 0.010186534374952316, accuracy: 98.75%
Epoch 2: train loss 0.009798149578273296, accuracy: 99.97%
Epoch 2: train loss 0.010025870986282825, accuracy: 99.26%
Epoch 4: train loss 0.010214588604867458, accuracy: 98.64%
Epoch 4: train loss 0.010177424177527428, accuracy: 98.76%
Epoch 1: train loss 0.01132759265601635, accuracy: 95.09%
Epoch 3: train loss 0.02113386243581772, accuracy: 63.53%
Epoch 3: train loss 0.009793872945010662, accuracy: 99.99%
Epoch 5: train loss 0.010210908949375153, accuracy: 98.64%
Epoch 3: train loss 0.009998259134590626, accuracy: 99.33%
Epoch 5: train loss 0.01016200240701437, accuracy: 98.83%
Epoch 2: train loss 0.010736288502812386, accuracy: 96.95%
Epoch 4: train loss 0.014295840635895729, accuracy: 85.49%
Epoch 6: train loss 0.010211560875177383, accuracy: 98.65%
Epoch 6: train loss 0.010156573727726936, accuracy: 98.82%
Epoch 4: train loss 0.009793202392756939, accuracy: 99.99%
Epoch 4: train loss 0.009982620365917683, accuracy: 99.38%
Epoch 5: train loss 0.013155893422663212, accuracy: 89.2%
Epoch 7: train loss 0.010207392275333405, accuracy: 98.66%
Epoch 7: train loss 0.010150748305022717, accuracy: 98.84%
Epoch 2: train loss 0.010954851284623146, accuracy: 96.29%
Epoch 8: train loss 0.010208013467490673, accuracy: 98.66%
Epoch 3: train loss 0.010653771460056305, accuracy: 97.22%
Epoch 6: train loss 0.01291841734200716, accuracy: 89.97%
Epoch 8: train loss 0.01015081349760294, accuracy: 98.84%
Epoch 5: train loss 0.009793019853532314, accuracy: 99.99%
Epoch 5: train loss 0.00998222641646862, accuracy: 99.38%
Epoch 9: train loss 0.010208306834101677, accuracy: 98.67%
Epoch 9: train loss 0.01014993991702795, accuracy: 98.84%
Epoch 7: train loss 0.012813486158847809, accuracy: 90.37%
Epoch 6: train loss 0.009792950004339218, accuracy: 99.99%
Epoch 6: train loss 0.009992078877985477, accuracy: 99.36%
Epoch 8: train loss 0.012778415344655514, accuracy: 90.52%
Epoch 4: train loss 0.010602659545838833, accuracy: 97.41%
Epoch 7: train loss 0.009967208839952946, accuracy: 99.43%
Epoch 7: train loss 0.009792929515242577, accuracy: 99.99%
Epoch 9: train loss 0.01270325481891632, accuracy: 90.63%
Epoch 3: train loss 0.010944602079689503, accuracy: 96.3%
Epoch 8: train loss 0.009964924305677414, accuracy: 99.44%
Epoch 8: train loss 0.00979292206466198, accuracy: 99.99%
Epoch 5: train loss 0.010600016452372074, accuracy: 97.4%
Epoch 9: train loss 0.00997244007885456, accuracy: 99.41%
Epoch 9: train loss 0.009792912751436234, accuracy: 99.99%
Epoch 4: train loss 0.011103813536465168, accuracy: 95.8%
Epoch 6: train loss 0.010600878857076168, accuracy: 97.4%
Epoch 7: train loss 0.010600374080240726, accuracy: 97.42%
Epoch 5: train loss 0.011214254423975945, accuracy: 95.43%
Epoch 8: train loss 0.010599750094115734, accuracy: 97.41%
Epoch 9: train loss 0.010598122142255306, accuracy: 97.41%
Epoch 6: train loss 0.011090109124779701, accuracy: 95.86%
Epoch 7: train loss 0.010897583328187466, accuracy: 96.45%
Epoch 8: train loss 0.010889369994401932, accuracy: 96.49%
Epoch 9: train loss 0.01086100097745657, accuracy: 96.58%
Epoch 10: train loss 0.009982858784496784, accuracy: 99.37%
Epoch 10: train loss 0.010598717257380486, accuracy: 97.41%
Epoch 10: train loss 0.010831956751644611, accuracy: 96.66%
Epoch 10: train loss 0.012579865753650665, accuracy: 91.07%
Epoch 10: train loss 0.010206320323050022, accuracy: 98.66%
Epoch 10: train loss 0.010148601606488228, accuracy: 98.85%
Epoch 10: train loss 0.009792910888791084, accuracy: 99.99%
Acurácia do Cliente: 2 eh: 0.6372363615365737
Acurácia do Cliente: 7 eh: 0.43171650055370986
Acurácia do Cliente: 6 eh: 0.9890598827470687
Acurácia do Cliente: 3 eh: 0.997539932781262
Acurácia do Cliente: 4 eh: 0.9881434524857663
Acurácia do Cliente: 1 eh: 0.9694781458141778
Acurácia do Cliente: 5 eh: 0.4524033930254477
