INFO flwr 2023-11-06 02:47:59,538 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-11-06 02:47:59,547 | app.py:175 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-11-06 02:47:59,547 | server.py:89 | Initializing global parameters
INFO flwr 2023-11-06 02:47:59,547 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-11-06 02:48:13,687 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-11-06 02:48:13,687 | server.py:91 | Evaluating initial parameters
  0%|          | 0/1394 [00:00<?, ?it/s]  0%|          | 1/1394 [00:00<12:53,  1.80it/s] 12%|█▏        | 165/1394 [00:00<00:03, 336.73it/s] 24%|██▎       | 331/1394 [00:00<00:01, 635.49it/s] 36%|███▌      | 496/1394 [00:00<00:01, 882.15it/s] 47%|████▋     | 661/1394 [00:00<00:00, 1079.69it/s] 59%|█████▉    | 825/1394 [00:01<00:00, 1230.06it/s] 71%|███████   | 991/1394 [00:01<00:00, 1347.31it/s] 83%|████████▎ | 1153/1394 [00:01<00:00, 1423.25it/s] 95%|█████████▍| 1318/1394 [00:01<00:00, 1487.78it/s]100%|██████████| 1394/1394 [00:01<00:00, 992.85it/s] 
INFO flwr 2023-11-06 02:48:23,008 | server.py:94 | initial parameters (loss, other metrics): 1474.7886834740639, {'accuracy': 0.24069879572110964}
INFO flwr 2023-11-06 02:48:23,008 | server.py:104 | FL starting
DEBUG flwr 2023-11-06 02:48:23,008 | server.py:222 | fit_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:57:56,043 | server.py:236 | fit_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 02:57:56,051 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
Server-side evaluation loss 1474.7886834740639 / accuracy 0.24069879572110964
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 166/1394 [00:00<00:00, 1658.50it/s] 24%|██▍       | 332/1394 [00:00<00:00, 1649.59it/s] 36%|███▌      | 497/1394 [00:00<00:00, 1646.45it/s] 48%|████▊     | 663/1394 [00:00<00:00, 1651.44it/s] 60%|█████▉    | 830/1394 [00:00<00:00, 1654.59it/s] 71%|███████▏  | 996/1394 [00:00<00:00, 1655.38it/s] 83%|████████▎ | 1162/1394 [00:00<00:00, 1643.47it/s] 95%|█████████▌| 1328/1394 [00:00<00:00, 1645.63it/s]100%|██████████| 1394/1394 [00:00<00:00, 1648.78it/s]
INFO flwr 2023-11-06 02:58:00,991 | server.py:125 | fit progress: (1, 705.5730924904346, {'accuracy': 0.8067771523401583}, 577.983325101959)
DEBUG flwr 2023-11-06 02:58:00,992 | server.py:173 | evaluate_round 1: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 02:58:03,401 | server.py:187 | evaluate_round 1 received 7 results and 0 failures
WARNING flwr 2023-11-06 02:58:03,401 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided
DEBUG flwr 2023-11-06 02:58:03,401 | server.py:222 | fit_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 03:07:34,527 | server.py:236 | fit_round 2 received 7 results and 0 failures
Server-side evaluation loss 705.5730924904346 / accuracy 0.8067771523401583
  0%|          | 0/1394 [00:00<?, ?it/s] 12%|█▏        | 162/1394 [00:00<00:00, 1616.58it/s] 23%|██▎       | 326/1394 [00:00<00:00, 1628.70it/s] 35%|███▌      | 489/1394 [00:00<00:00, 1628.95it/s] 47%|████▋     | 653/1394 [00:00<00:00, 1632.72it/s] 59%|█████▉    | 819/1394 [00:00<00:00, 1640.17it/s] 71%|███████   | 984/1394 [00:00<00:00, 1636.22it/s] 82%|████████▏ | 1149/1394 [00:00<00:00, 1640.68it/s] 94%|█████████▍| 1314/1394 [00:00<00:00, 1640.00it/s]100%|██████████| 1394/1394 [00:00<00:00, 1636.36it/s]
INFO flwr 2023-11-06 03:07:39,281 | server.py:125 | fit progress: (2, 690.456359565258, {'accuracy': 0.8179901773900563}, 1156.2726496299729)
DEBUG flwr 2023-11-06 03:07:39,281 | server.py:173 | evaluate_round 2: strategy sampled 7 clients (out of 7)
DEBUG flwr 2023-11-06 03:07:41,771 | server.py:187 | evaluate_round 2 received 7 results and 0 failures
INFO flwr 2023-11-06 03:07:41,772 | server.py:153 | FL finished in 1158.7635115039884
INFO flwr 2023-11-06 03:07:41,772 | app.py:225 | app_fit: losses_distributed [(1, 655.9221493197173), (2, 696.2628491108225)]
INFO flwr 2023-11-06 03:07:41,772 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-11-06 03:07:41,772 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-11-06 03:07:41,772 | app.py:228 | app_fit: losses_centralized [(0, 1474.7886834740639), (1, 705.5730924904346), (2, 690.456359565258)]
INFO flwr 2023-11-06 03:07:41,772 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 0.24069879572110964), (1, 0.8067771523401583), (2, 0.8179901773900563)]}
Server-side evaluation loss 690.456359565258 / accuracy 0.8179901773900563
in loss 0.011154385283589363, accuracy: 95.64%
Epoch 6: train loss 0.01040399819612503, accuracy: 98.02%
Epoch 7: train loss 0.010401571169495583, accuracy: 98.07%
Epoch 5: train loss 0.011025048792362213, accuracy: 96.06%
Epoch 8: train loss 0.010376730933785439, accuracy: 98.14%
Epoch 9: train loss 0.010362843051552773, accuracy: 98.18%
Epoch 6: train loss 0.011009328067302704, accuracy: 96.1%
Epoch 7: train loss 0.01089332066476345, accuracy: 96.46%
Epoch 8: train loss 0.010876464657485485, accuracy: 96.53%
Epoch 9: train loss 0.010834285989403725, accuracy: 96.7%
Epoch 10: train loss 0.010910885408520699, accuracy: 96.41%
Epoch 10: train loss 0.011501380242407322, accuracy: 94.53%
Epoch 10: train loss 0.010125630535185337, accuracy: 98.96%
Epoch 10: train loss 0.01008600927889347, accuracy: 98.98%
Epoch 10: train loss 0.009792945347726345, accuracy: 99.99%
Epoch 10: train loss 0.010360676795244217, accuracy: 98.17%
Epoch 10: train loss 0.009955772198736668, accuracy: 99.47%
Acurácia do Cliente: 5 eh: 0.562990889098335
Starting Client training for 10 epochs
Acurácia do Cliente: 6 eh: 0.7604690117252931
Starting Client training for 10 epochs
Acurácia do Cliente: 1 eh: 0.8071583951918548
Starting Client training for 10 epochs
Acurácia do Cliente: 4 eh: 0.8060104478487997
Starting Client training for 10 epochs
Acurácia do Cliente: 2 eh: 0.873280304889492
Starting Client training for 10 epochs
Acurácia do Cliente: 7 eh: 0.627109634551495
Starting Client training for 10 epochs
Acurácia do Cliente: 3 eh: 0.8354873358511486
Starting Client training for 10 epochs
Epoch 1: train loss 0.01574694737792015, accuracy: 80.9%
Epoch 1: train loss 0.01347579900175333, accuracy: 88.21%
Epoch 1: train loss 0.02035381644964218, accuracy: 66.21%
Epoch 1: train loss 0.011913130059838295, accuracy: 93.19%
Epoch 1: train loss 0.010397490113973618, accuracy: 98.09%
Epoch 2: train loss 0.015388043597340584, accuracy: 82.1%
Epoch 2: train loss 0.010959199629724026, accuracy: 96.26%
Epoch 2: train loss 0.019144894555211067, accuracy: 70.04%
Epoch 1: train loss 0.015431405045092106, accuracy: 81.98%
Epoch 3: train loss 0.01053206343203783, accuracy: 97.7%
Epoch 3: train loss 0.015147313475608826, accuracy: 82.8%
Epoch 2: train loss 0.01031783688813448, accuracy: 98.31%
Epoch 2: train loss 0.009793083183467388, accuracy: 99.99%
Epoch 3: train loss 0.018335843458771706, accuracy: 72.6%
Epoch 4: train loss 0.010325741954147816, accuracy: 98.37%
Epoch 4: train loss 0.014771167188882828, accuracy: 84.05%
Epoch 1: train loss 0.01113222073763609, accuracy: 95.71%
Epoch 3: train loss 0.009793051518499851, accuracy: 99.99%
Epoch 3: train loss 0.010232152417302132, accuracy: 98.59%
Epoch 5: train loss 0.010241488926112652, accuracy: 98.61%
Epoch 5: train loss 0.013921847566962242, accuracy: 86.7%
Epoch 4: train loss 0.018118949607014656, accuracy: 73.28%
Epoch 2: train loss 0.015038354322314262, accuracy: 83.24%
Epoch 6: train loss 0.010190737433731556, accuracy: 98.76%
Epoch 6: train loss 0.012012484483420849, accuracy: 92.8%
Epoch 4: train loss 0.01026363205164671, accuracy: 98.48%
Epoch 4: train loss 0.009792917408049107, accuracy: 99.99%
Epoch 5: train loss 0.017829924821853638, accuracy: 74.29%
Epoch 7: train loss 0.010180849581956863, accuracy: 98.78%
Epoch 7: train loss 0.011067671701312065, accuracy: 95.88%
Epoch 8: train loss 0.010178408585488796, accuracy: 98.78%
Epoch 6: train loss 0.017530912533402443, accuracy: 75.36%
Epoch 5: train loss 0.010184683836996555, accuracy: 98.72%
Epoch 2: train loss 0.010951565578579903, accuracy: 96.26%
Epoch 8: train loss 0.011068698950111866, accuracy: 96.0%
Epoch 5: train loss 0.009793033823370934, accuracy: 99.99%
Epoch 3: train loss 0.014709342271089554, accuracy: 84.24%
Epoch 9: train loss 0.01016281172633171, accuracy: 98.83%
Epoch 9: train loss 0.011040478013455868, accuracy: 96.0%
Epoch 7: train loss 0.015031946823000908, accuracy: 83.11%
Epoch 6: train loss 0.010063654743134975, accuracy: 99.1%
Epoch 6: train loss 0.009793030098080635, accuracy: 99.99%
Epoch 8: train loss 0.0119595006108284, accuracy: 93.06%
Epoch 4: train loss 0.014366928488016129, accuracy: 85.35%
Epoch 7: train loss 0.010053322650492191, accuracy: 99.16%
Epoch 7: train loss 0.00979302916675806, accuracy: 99.99%
Epoch 9: train loss 0.011688954196870327, accuracy: 93.96%
Epoch 3: train loss 0.010907871648669243, accuracy: 96.4%
Epoch 8: train loss 0.010042238980531693, accuracy: 99.19%
Epoch 8: train loss 0.00979302916675806, accuracy: 99.99%
Epoch 5: train loss 0.014017903245985508, accuracy: 86.47%
Epoch 9: train loss 0.010044575668871403, accuracy: 99.19%
Epoch 9: train loss 0.00979290809482336, accuracy: 99.99%
Epoch 4: train loss 0.010975331999361515, accuracy: 96.2%
Epoch 6: train loss 0.01391671597957611, accuracy: 86.84%
Epoch 7: train loss 0.013554878532886505, accuracy: 87.92%
Epoch 5: train loss 0.010956192389130592, accuracy: 96.28%
Epoch 8: train loss 0.012815346010029316, accuracy: 90.37%
Epoch 6: train loss 0.01084146834909916, accuracy: 96.61%
Epoch 9: train loss 0.011726751923561096, accuracy: 93.79%
Epoch 7: train loss 0.010872364975512028, accuracy: 96.51%
Epoch 8: train loss 0.010896539315581322, accuracy: 96.46%
Epoch 9: train loss 0.010839768685400486, accuracy: 96.63%
Epoch 10: train loss 0.010827059857547283, accuracy: 96.66%
Epoch 10: train loss 0.012180943973362446, accuracy: 92.32%
Epoch 10: train loss 0.011641981080174446, accuracy: 94.08%
Epoch 10: train loss 0.00979302916675806, accuracy: 99.99%
Epoch 10: train loss 0.01086482871323824, accuracy: 96.55%
Epoch 10: train loss 0.010038717649877071, accuracy: 99.18%
Epoch 10: train loss 0.010163857601583004, accuracy: 98.85%
Acurácia do Cliente: 4 eh: 0.815519164172096
Acurácia do Cliente: 5 eh: 0.533005201242713
Acurácia do Cliente: 6 eh: 0.7851235343383585
Acurácia do Cliente: 7 eh: 0.6757918050941307
Acurácia do Cliente: 2 eh: 0.8008979226516146
Acurácia do Cliente: 1 eh: 0.8184386983920522
Acurácia do Cliente: 3 eh: 0.8522920203735145
