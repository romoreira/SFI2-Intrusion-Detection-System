{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC4F0BAbFV2S"
      },
      "source": [
        "PyTorchViz examples\n",
        "=========="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aBnFXZfNFV2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52b3b50-7741-49d1-cc60-0d0c4f972126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/szagoruyko/pytorchviz.git@master\n",
            "  Cloning https://github.com/szagoruyko/pytorchviz.git (to revision master) to /tmp/pip-req-build-ydf41hkl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/szagoruyko/pytorchviz.git /tmp/pip-req-build-ydf41hkl\n",
            "  Resolved https://github.com/szagoruyko/pytorchviz.git to commit 0adcd83af8aa7ab36d6afd139cabbd9df598edb7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz==0.0.2) (2.1.0+cu118)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz==0.0.2) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz==0.0.2) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz==0.0.2) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz==0.0.2) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4973 sha256=1bbc8fb0fcb3d6f14ddfe8d442f343f886fbe6353b852a2f9037ab572238fd2e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-da1j7bku/wheels/97/11/17/d09e895f9883bd50923ce86b249a31790356a1b88b280983d8\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "%pip install -U git+https://github.com/szagoruyko/pytorchviz.git@master\n",
        "from torchviz import make_dot, make_dot_from_trace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden_layer = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.input_layer(x))\n",
        "        x = self.dropout(x)  # Aplicar o dropout após a ativação\n",
        "        x = self.output_layer(x)\n",
        "        # Aplicar a função Softmax na camada de saída\n",
        "        x = nn.functional.softmax(x, dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1mooR-lhHbxI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_loaders(X_train, X_test, y_train, y_test):\n",
        "    #print(\"\\n\")\n",
        "    #print(\"Shape X_train: \"+str(X_train.shape))\n",
        "    #print(\"Shape X_test: \" + str(X_test.shape))\n",
        "    #print(\"Shape y_train: \" + str(y_train.shape))\n",
        "    #print(\"Shape Y_test: \" + str(y_test.shape))\n",
        "    #exit()\n",
        "\n",
        "    # Crie conjuntos de dados para treinamento e teste\n",
        "    train_dataset = CustomDataset(X_train, y_train)\n",
        "    test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "    # Crie os data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "H2X8If8WfK4x"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_sample = self.X[idx]\n",
        "        y_sample = self.y[idx]\n",
        "        return x_sample, y_sample\n",
        "\n",
        "def remove_spaces(column_name):\n",
        "    return column_name.strip()\n",
        "\n",
        "def load_dataset(dataset_id):\n",
        "\n",
        "\n",
        "    if dataset_id == 1:\n",
        "        # Caminho para o diretório do conjunto de dados\n",
        "        data_dir = \"../dataset/cic-unb-ids/Tuesday-WorkingHours.pcap_ISCX.csv\"\n",
        "    elif dataset_id == 2:\n",
        "        # Caminho para o diretório do conjunto de dados\n",
        "        data_dir = \"../dataset/cic-unb-ids/Wednesday-workingHours.pcap_ISCX.csv\"\n",
        "    elif dataset_id == 3:\n",
        "        # Caminho para o diretório do conjunto de dados\n",
        "        data_dir = \"../dataset/cic-unb-ids/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\"\n",
        "    elif dataset_id == 4:\n",
        "        # Caminho para o diretório do conjunto de dados\n",
        "        data_dir = \"./Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\"\n",
        "        #data_dir = \"\"\n",
        "    elif dataset_id == 5:\n",
        "        # Caminho para o diretório do conjunto de dados\n",
        "        data_dir = \"../dataset/cic-unb-ids/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\"\n",
        "    elif dataset_id == 6:\n",
        "        # Caminho para o diretório do conjunto de dados\n",
        "        #data_dir = \"../dataset/cic-unb-ids/Friday-WorkingHours-Morning.pcap_ISCX.csv\"\n",
        "        data_dir = \"\"\n",
        "    elif dataset_id == 7:\n",
        "        # Caminho para o diretório do conjunto de dados\n",
        "        #data_dir = \"../dataset/cic-unb-ids/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\"\n",
        "        data_dir = \"\"\n",
        "\n",
        "\n",
        "    df = pd.read_csv(data_dir)\n",
        "    #df = column_remover(df)\n",
        "    df.columns = df.columns.map(remove_spaces)\n",
        "\n",
        "    df['Label'] = df['Label'].apply(lambda x: 'MALIGNANT' if x != 'BENIGN' else x)\n",
        "\n",
        "    # Separar as colunas de recursos (features) e rótulos (labels)\n",
        "    X = df.drop('Label', axis=1)  # Substitua 'label' pelo nome da coluna de rótulos\n",
        "    y = df['Label']\n",
        "\n",
        "    # Dividir os dados em conjuntos de treinamento e teste\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
        "    X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    X_train = X_train.fillna(0)\n",
        "    X_test = X_test.fillna(0)\n",
        "\n",
        "\n",
        "    # Crie um objeto LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Ajuste o LabelEncoder aos seus dados de classe (y_train)\n",
        "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "    y_test_encoded = label_encoder.fit_transform(y_test)\n",
        "\n",
        "    # Crie um tensor PyTorch a partir dos valores codificados\n",
        "    y_train = torch.tensor(y_train_encoded, dtype=torch.int64)\n",
        "    y_test = torch.tensor(y_test_encoded, dtype=torch.int64)\n",
        "\n",
        "\n",
        "    # Padronizar os recursos (opcional, mas geralmente recomendado)\n",
        "    scaler = RobustScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "    # Converter os dados para tensores PyTorch\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "    #y_train = torch.tensor(y_train.values, dtype=torch.int64)\n",
        "    #y_test = torch.tensor(y_test.values, dtype=torch.int64)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "459e8x2YfAYa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = load_dataset(4)\n",
        "train_loader, val_loader = create_loaders(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "Z4GXaXQfed1O"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "r3QwoCzWFV2b",
        "outputId": "72a82516-6953-47de-ab36-d0c1fa2a3d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./cic_unb_server_model_aggregated.pth\n",
            "LSTMModel(\n",
            "  (input_layer): Linear(in_features=78, out_features=16, bias=True)\n",
            "  (hidden_layer): Linear(in_features=16, out_features=16, bias=True)\n",
            "  (output_layer): Linear(in_features=16, out_features=2, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output_graph.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model_path = './cic_unb_server_model_aggregated.pth'\n",
        "print(model_path)\n",
        "\n",
        "model = LSTMModel(input_size=78, hidden_size=16, num_layers=5, output_size=2)\n",
        "print(model)\n",
        "model.eval()\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "\n",
        "data, targets = next(iter(val_loader))\n",
        "\n",
        "# Certifique-se de que os dados estão na mesma device que o seu modelo\n",
        "\n",
        "\n",
        "# Agora você pode passar os dados para o seu modelo\n",
        "output = model(data)\n",
        "\n",
        "# E então você pode visualizar o gráfico\n",
        "dot = make_dot(output, params=dict(model.named_parameters()))\n",
        "dot.render(filename='output_graph', format='pdf')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXHR-7kqFV2c"
      },
      "source": [
        "Specify `show_attrs=True` and `show_saved=True` to see what autograd saves for the backward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5fM9N8O7FV2d",
        "outputId": "3db35081-444c-49d9-ffc2-109185a5f261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output_graph_2.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "dot2 = make_dot(output, params=dict(model.named_parameters()), show_attrs=True, show_saved=True)\n",
        "dot2.render(filename='output_graph_2', format='pdf')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6+"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}